{
  "topics": {
    "data": {
      "0": {
        "name": "0_students_learning_student_education",
        "keywords": [
          [
            "students",
            0.03388562523599357
          ],
          [
            "learning",
            0.025624614864380547
          ],
          [
            "student",
            0.01813894305646108
          ],
          [
            "education",
            0.017931887045059165
          ],
          [
            "AI",
            0.014150068493994342
          ],
          [
            "educational",
            0.01385274224070147
          ],
          [
            "programming",
            0.01112907146074355
          ],
          [
            "course",
            0.010955580267853654
          ],
          [
            "study",
            0.010601008769921576
          ],
          [
            "teaching",
            0.00928287096121176
          ]
        ],
        "count": 2039
      },
      "1": {
        "name": "1_media_social_news_social media",
        "keywords": [
          [
            "media",
            0.023175300683027037
          ],
          [
            "social",
            0.021221303462812428
          ],
          [
            "news",
            0.020116248655314327
          ],
          [
            "social media",
            0.017927783818016206
          ],
          [
            "content",
            0.0170215614117544
          ],
          [
            "online",
            0.015054388087701947
          ],
          [
            "users",
            0.014897401975114338
          ],
          [
            "Twitter",
            0.013793072024177898
          ],
          [
            "misinformation",
            0.012535337497249091
          ],
          [
            "political",
            0.012090924078628265
          ]
        ],
        "count": 1453
      },
      "2": {
        "name": "2_fairness_bias_fair_Fairness",
        "keywords": [
          [
            "fairness",
            0.04745558497717849
          ],
          [
            "bias",
            0.01498106152835404
          ],
          [
            "fair",
            0.014840715532271025
          ],
          [
            "Fairness",
            0.014012289931111565
          ],
          [
            "learning",
            0.013696796912963228
          ],
          [
            "decision",
            0.013123787017651494
          ],
          [
            "algorithmic",
            0.012895705270857578
          ],
          [
            "data",
            0.011832414432435025
          ],
          [
            "model",
            0.011573864404502643
          ],
          [
            "algorithms",
            0.010649633041249168
          ]
        ],
        "count": 1215
      },
      "3": {
        "name": "3_AI_systems_risks_ethical",
        "keywords": [
          [
            "AI",
            0.06448982917829704
          ],
          [
            "systems",
            0.02023275245047315
          ],
          [
            "risks",
            0.013848205723629029
          ],
          [
            "ethical",
            0.0135115778641109
          ],
          [
            "governance",
            0.012739362351837659
          ],
          [
            "risk",
            0.011743513702709348
          ],
          [
            "human",
            0.011415465815568928
          ],
          [
            "ethics",
            0.011294768746142289
          ],
          [
            "intelligence",
            0.01104111396088142
          ],
          [
            "safety",
            0.010804074608609571
          ]
        ],
        "count": 1029
      },
      "4": {
        "name": "4_LLMs_language_models_LLM",
        "keywords": [
          [
            "LLMs",
            0.03224723193144935
          ],
          [
            "language",
            0.021242787913103724
          ],
          [
            "models",
            0.020231445474544845
          ],
          [
            "LLM",
            0.018265138478096396
          ],
          [
            "Language",
            0.015126793229981715
          ],
          [
            "human",
            0.014535501537437514
          ],
          [
            "language models",
            0.013836444646044286
          ],
          [
            "Large",
            0.013691770370650821
          ],
          [
            "bias",
            0.01325351497711516
          ],
          [
            "Models",
            0.012526809009194315
          ]
        ],
        "count": 1010
      },
      "5": {
        "name": "5_urban_data_traffic_mobility",
        "keywords": [
          [
            "urban",
            0.025499323950515265
          ],
          [
            "data",
            0.01908504678787946
          ],
          [
            "traffic",
            0.01753905421533733
          ],
          [
            "mobility",
            0.01744791648641795
          ],
          [
            "cities",
            0.011115580809216935
          ],
          [
            "transportation",
            0.010899832076694035
          ],
          [
            "spatial",
            0.010643933566773085
          ],
          [
            "vehicle",
            0.010426717506315372
          ],
          [
            "road",
            0.01023769718409955
          ],
          [
            "vehicles",
            0.009738352114312577
          ]
        ],
        "count": 739
      },
      "6": {
        "name": "6_healthcare_health_clinical_data",
        "keywords": [
          [
            "healthcare",
            0.01925096253804795
          ],
          [
            "health",
            0.01906376437594288
          ],
          [
            "clinical",
            0.01778782768124925
          ],
          [
            "data",
            0.01701728103658824
          ],
          [
            "medical",
            0.01542455895882576
          ],
          [
            "patient",
            0.01475692999623282
          ],
          [
            "patients",
            0.014051059172842235
          ],
          [
            "AI",
            0.011811072292582539
          ],
          [
            "learning",
            0.01160437554163068
          ],
          [
            "model",
            0.01128876814341734
          ]
        ],
        "count": 739
      },
      "7": {
        "name": "7_privacy_security_data_cyber",
        "keywords": [
          [
            "privacy",
            0.028945847691180394
          ],
          [
            "security",
            0.024475819298288223
          ],
          [
            "data",
            0.02258839774153624
          ],
          [
            "cyber",
            0.01852782947885776
          ],
          [
            "cybersecurity",
            0.012751497773399486
          ],
          [
            "online",
            0.012066230848454432
          ],
          [
            "information",
            0.011121121662832308
          ],
          [
            "research",
            0.010673583431101476
          ],
          [
            "Privacy",
            0.010485173690313486
          ],
          [
            "users",
            0.01025489464478591
          ]
        ],
        "count": 566
      },
      "8": {
        "name": "8_blockchain_Blockchain_digital_decentralized",
        "keywords": [
          [
            "blockchain",
            0.04412958745979309
          ],
          [
            "Blockchain",
            0.02272429650995014
          ],
          [
            "digital",
            0.014431013553474387
          ],
          [
            "decentralized",
            0.01402347912419458
          ],
          [
            "technology",
            0.013213644793422921
          ],
          [
            "transactions",
            0.011583724154161285
          ],
          [
            "Bitcoin",
            0.011499953361687581
          ],
          [
            "contracts",
            0.010817895512172038
          ],
          [
            "NFT",
            0.010658449314771858
          ],
          [
            "data",
            0.010476918450484561
          ]
        ],
        "count": 496
      },
      "9": {
        "name": "9_AI_generative_models_image",
        "keywords": [
          [
            "AI",
            0.029644398597670554
          ],
          [
            "generative",
            0.024451614569888324
          ],
          [
            "models",
            0.02143032383044
          ],
          [
            "image",
            0.02022231243225381
          ],
          [
            "images",
            0.020040894178416282
          ],
          [
            "Generative",
            0.015790502501650906
          ],
          [
            "generated",
            0.011357294582385234
          ],
          [
            "art",
            0.010144105282409867
          ],
          [
            "human",
            0.010091313711048572
          ],
          [
            "text",
            0.009682703686777953
          ]
        ],
        "count": 464
      },
      "10": {
        "name": "10_energy_carbon_data_environmental",
        "keywords": [
          [
            "energy",
            0.03038125380294275
          ],
          [
            "carbon",
            0.02898453992915915
          ],
          [
            "data",
            0.018973217679336934
          ],
          [
            "environmental",
            0.018460868680936438
          ],
          [
            "computing",
            0.016220497709390522
          ],
          [
            "emissions",
            0.014600335739941165
          ],
          [
            "research",
            0.012636451960525387
          ],
          [
            "footprint",
            0.012581973641237712
          ],
          [
            "digital",
            0.01227182400992767
          ],
          [
            "consumption",
            0.011590825399119823
          ]
        ],
        "count": 225
      },
      "11": {
        "name": "11_health_LLMs_mental_mental health",
        "keywords": [
          [
            "health",
            0.027669232012228217
          ],
          [
            "LLMs",
            0.024731786632949088
          ],
          [
            "mental",
            0.021912316728793846
          ],
          [
            "mental health",
            0.02108140687768447
          ],
          [
            "medical",
            0.01944992883599468
          ],
          [
            "models",
            0.013216295162956597
          ],
          [
            "language",
            0.013179088552766815
          ],
          [
            "LLM",
            0.013134481291884404
          ],
          [
            "patient",
            0.013129243718560885
          ],
          [
            "clinical",
            0.013100944876328294
          ]
        ],
        "count": 222
      },
      "12": {
        "name": "12_pandemic_model_spread_data",
        "keywords": [
          [
            "pandemic",
            0.023367738595249578
          ],
          [
            "model",
            0.017488405444782452
          ],
          [
            "spread",
            0.01706826930171943
          ],
          [
            "data",
            0.01667541862761512
          ],
          [
            "disease",
            0.015888949184668447
          ],
          [
            "cases",
            0.013704361183242164
          ],
          [
            "transmission",
            0.013608606169435478
          ],
          [
            "models",
            0.012376572158663867
          ],
          [
            "infection",
            0.012337377836901505
          ],
          [
            "health",
            0.01178178093568375
          ]
        ],
        "count": 193
      },
      "13": {
        "name": "13_research_scientific_software_papers",
        "keywords": [
          [
            "research",
            0.02762723819954464
          ],
          [
            "scientific",
            0.021035002164757424
          ],
          [
            "software",
            0.020672446659464806
          ],
          [
            "papers",
            0.01817913527504037
          ],
          [
            "citations",
            0.014625357144652655
          ],
          [
            "researchers",
            0.014546072434784146
          ],
          [
            "citation",
            0.0144766765343148
          ],
          [
            "science",
            0.014207440724523613
          ],
          [
            "academic",
            0.013981907063065574
          ],
          [
            "publications",
            0.013062812036642179
          ]
        ],
        "count": 191
      },
      "14": {
        "name": "14_contact_tracing_contact tracing_privacy",
        "keywords": [
          [
            "contact",
            0.07414312879765299
          ],
          [
            "tracing",
            0.07036551017767567
          ],
          [
            "contact tracing",
            0.06691663374583698
          ],
          [
            "privacy",
            0.03338655416338556
          ],
          [
            "apps",
            0.023227892744659178
          ],
          [
            "Contact",
            0.02272141769965587
          ],
          [
            "app",
            0.02255112470394087
          ],
          [
            "Tracing",
            0.017526320233167202
          ],
          [
            "Bluetooth",
            0.015412346322844266
          ],
          [
            "pandemic",
            0.01534841953974575
          ]
        ],
        "count": 161
      },
      "15": {
        "name": "15_VR_virtual_Reality_reality",
        "keywords": [
          [
            "VR",
            0.05267480522909429
          ],
          [
            "virtual",
            0.029858619703596937
          ],
          [
            "Reality",
            0.029710770802647148
          ],
          [
            "reality",
            0.02721267436690405
          ],
          [
            "Metaverse",
            0.023463539872317293
          ],
          [
            "immersive",
            0.020086461403644288
          ],
          [
            "Virtual",
            0.019103927879291733
          ],
          [
            "AR",
            0.01796459277752112
          ],
          [
            "metaverse",
            0.016828976826830343
          ],
          [
            "virtual reality",
            0.014992172044554846
          ]
        ],
        "count": 157
      },
      "16": {
        "name": "16_energy_electricity_consumption_data",
        "keywords": [
          [
            "energy",
            0.049307417556588705
          ],
          [
            "electricity",
            0.020340330095694685
          ],
          [
            "consumption",
            0.01815438008364296
          ],
          [
            "data",
            0.01790044702930027
          ],
          [
            "demand",
            0.014924116952909044
          ],
          [
            "grid",
            0.014801983416942544
          ],
          [
            "The",
            0.014789801072394665
          ],
          [
            "water",
            0.014481843573131122
          ],
          [
            "power",
            0.012763109168981643
          ],
          [
            "Energy",
            0.012614345421589141
          ]
        ],
        "count": 152
      },
      "17": {
        "name": "17_privacy_data_DP_synthetic",
        "keywords": [
          [
            "privacy",
            0.0644540101863996
          ],
          [
            "data",
            0.03766190061592236
          ],
          [
            "DP",
            0.034676737376083046
          ],
          [
            "synthetic",
            0.0244971443078865
          ],
          [
            "differential privacy",
            0.02189379054707494
          ],
          [
            "Census",
            0.021858997613914986
          ],
          [
            "synthetic data",
            0.02126485041178085
          ],
          [
            "differential",
            0.020365276068981388
          ],
          [
            "private",
            0.019605728364831442
          ],
          [
            "Privacy",
            0.017692398979237352
          ]
        ],
        "count": 132
      },
      "18": {
        "name": "18_XAI_explanations_AI_explainability",
        "keywords": [
          [
            "XAI",
            0.056989402951353366
          ],
          [
            "explanations",
            0.04093249322370585
          ],
          [
            "AI",
            0.034510055985525166
          ],
          [
            "explainability",
            0.025392860084735812
          ],
          [
            "explanation",
            0.02329183832556541
          ],
          [
            "systems",
            0.018246538689757605
          ],
          [
            "Explainable",
            0.017185870021466123
          ],
          [
            "explainable",
            0.0169391335446668
          ],
          [
            "decision",
            0.016730228985814152
          ],
          [
            "human",
            0.013813969073903965
          ]
        ],
        "count": 132
      }
    },
    "correlations": [
      [
        1.0,
        -0.7441869420880088,
        -0.7279575822219451,
        -0.7099373220989033,
        -0.7098839456760513,
        -0.7501819829372622,
        -0.7290307065960031,
        -0.739083832103669,
        -0.7572697884947106,
        -0.697996226595412,
        -0.7470971270779752,
        -0.7245776059454201,
        -0.7285912967861101,
        -0.7265581141190599,
        -0.7186858776086947,
        -0.7390182407013097,
        -0.7609191943926403,
        -0.7407451163421616,
        -0.737054805746008
      ],
      [
        -0.7441869420880088,
        1.0,
        -0.7211877877670143,
        -0.7353258221329635,
        -0.7162219946208378,
        -0.7402632774165716,
        -0.7338476358496078,
        -0.731885910302382,
        -0.7574320833060291,
        -0.7212594005967612,
        -0.7438600154453405,
        -0.7113436262351929,
        -0.5840310574087155,
        -0.7256309979089826,
        -0.6287191961996066,
        -0.7540132069780829,
        -0.7561104116675295,
        -0.7285532935355528,
        -0.7463903823838502
      ],
      [
        -0.7279575822219451,
        -0.7211877877670143,
        1.0,
        -0.6947440579967711,
        -0.7040853506218152,
        -0.7162899427000438,
        -0.5212701707647756,
        -0.7095111166154446,
        -0.7616134422573171,
        -0.6966099431499004,
        -0.7231147374165112,
        -0.7287246154860414,
        -0.7465853080932534,
        -0.7314105684440875,
        -0.749590121842145,
        -0.7578318117913279,
        -0.7542344591022012,
        -0.6869775686632846,
        -0.6518000829045965
      ],
      [
        -0.7099373220989033,
        -0.7353258221329635,
        -0.6947440579967711,
        1.0,
        -0.671192378976603,
        -0.7438154761866447,
        -0.7037755062093551,
        -0.7129195077023969,
        -0.7542733844756284,
        -0.40102255743827564,
        -0.7260337678366022,
        -0.6930929417954452,
        -0.7553189409060392,
        -0.7177485653223294,
        -0.751993445941023,
        -0.7495912807877063,
        -0.7420991041466782,
        -0.7066931129509907,
        -0.41053593392754495
      ],
      [
        -0.7098839456760513,
        -0.7162219946208378,
        -0.7040853506218152,
        -0.671192378976603,
        1.0,
        -0.7404935855007853,
        -0.726379939929354,
        -0.7320598226234905,
        -0.7632887633284331,
        -0.5270602081599312,
        -0.7344691073555792,
        0.09664569128269743,
        -0.7543786582807906,
        -0.7310393741743373,
        -0.7491998177697621,
        -0.7582136038808907,
        -0.7547762187048721,
        -0.7250825610151637,
        -0.7116876117881846
      ],
      [
        -0.7501819829372622,
        -0.7402632774165716,
        -0.7162899427000438,
        -0.7438154761866447,
        -0.7404935855007853,
        1.0,
        -0.5095415602842084,
        -0.5038395065243918,
        -0.7553964800969901,
        -0.7389853526436118,
        -0.44385108368417114,
        -0.7381341432946611,
        -0.7279002435782995,
        -0.7475482562568679,
        -0.7404507231722532,
        -0.7557511394977261,
        -0.7445947489316656,
        -0.5244677080062349,
        -0.7448528784704811
      ],
      [
        -0.7290307065960031,
        -0.7338476358496078,
        -0.5212701707647756,
        -0.7037755062093551,
        -0.726379939929354,
        -0.5095415602842084,
        1.0,
        -0.4971022054382565,
        -0.7491148782145635,
        -0.7122534257125384,
        -0.47155251225028183,
        -0.6117196133452323,
        -0.7224629666318816,
        -0.7334640741467098,
        -0.731360971838463,
        -0.7556405299180927,
        -0.7493609193207751,
        -0.5082221016600472,
        -0.7186923713982696
      ],
      [
        -0.739083832103669,
        -0.731885910302382,
        -0.7095111166154446,
        -0.7129195077023969,
        -0.7320598226234905,
        -0.5038395065243918,
        -0.4971022054382565,
        1.0,
        -0.7292257437276402,
        -0.7245649136493568,
        -0.43877677351565747,
        -0.7321980412026489,
        -0.7287056384103243,
        -0.7257257077945356,
        -0.6950085782340483,
        -0.7430036942648702,
        -0.7402724158242859,
        -0.1544492955076553,
        -0.7371938424818825
      ],
      [
        -0.7572697884947106,
        -0.7574320833060291,
        -0.7616134422573171,
        -0.7542733844756284,
        -0.7632887633284331,
        -0.7553964800969901,
        -0.7491148782145635,
        -0.7292257437276402,
        1.0,
        -0.7620495316080658,
        -0.7425027384174113,
        -0.7609552040667443,
        -0.7519631016040627,
        -0.7548189224572779,
        -0.7490440685463438,
        -0.7394690363253482,
        -0.7450194999033187,
        -0.7372007258631952,
        -0.7619514178689777
      ],
      [
        -0.697996226595412,
        -0.7212594005967612,
        -0.6966099431499004,
        -0.40102255743827564,
        -0.5270602081599312,
        -0.7389853526436118,
        -0.7122534257125384,
        -0.7245649136493568,
        -0.7620495316080658,
        1.0,
        -0.7311258719200037,
        -0.6830663809681989,
        -0.7529647433127964,
        -0.7328863697330485,
        -0.7503185715728816,
        -0.7532808667126918,
        -0.7541013796755693,
        -0.7146192859936654,
        -0.5381199331935154
      ],
      [
        -0.7470971270779752,
        -0.7438600154453405,
        -0.7231147374165112,
        -0.7260337678366022,
        -0.7344691073555792,
        -0.44385108368417114,
        -0.47155251225028183,
        -0.43877677351565747,
        -0.7425027384174113,
        -0.7311258719200037,
        1.0,
        -0.7377699276219258,
        -0.7387679778889547,
        -0.7450932141445916,
        -0.7439511026450295,
        -0.7530964142107217,
        -0.3177272383818145,
        -0.47538001345147773,
        -0.7388641478229381
      ],
      [
        -0.7245776059454201,
        -0.7113436262351929,
        -0.7287246154860414,
        -0.6930929417954452,
        0.09664569128269743,
        -0.7381341432946611,
        -0.6117196133452323,
        -0.7321980412026489,
        -0.7609552040667443,
        -0.6830663809681989,
        -0.7377699276219258,
        1.0,
        -0.7275996821393944,
        -0.7382028880798956,
        -0.737518358493887,
        -0.7549185143374444,
        -0.7533720234001854,
        -0.7239636442915218,
        -0.7239947190913005
      ],
      [
        -0.7285912967861101,
        -0.5840310574087155,
        -0.7465853080932534,
        -0.7553189409060392,
        -0.7543786582807906,
        -0.7279002435782995,
        -0.7224629666318816,
        -0.7287056384103243,
        -0.7519631016040627,
        -0.7529647433127964,
        -0.7387679778889547,
        -0.7275996821393944,
        1.0,
        -0.7463960574189634,
        -0.0023425399232430144,
        -0.7552539502154905,
        -0.7571338104848548,
        -0.724299225775519,
        -0.7569484204456068
      ],
      [
        -0.7265581141190599,
        -0.7256309979089826,
        -0.7314105684440875,
        -0.7177485653223294,
        -0.7310393741743373,
        -0.7475482562568679,
        -0.7334640741467098,
        -0.7257257077945356,
        -0.7548189224572779,
        -0.7328863697330485,
        -0.7450932141445916,
        -0.7382028880798956,
        -0.7463960574189634,
        1.0,
        -0.7491751972049825,
        -0.7467221773305888,
        -0.7540958371053557,
        -0.7393165477398542,
        -0.7435047956011565
      ],
      [
        -0.7186858776086947,
        -0.6287191961996066,
        -0.749590121842145,
        -0.751993445941023,
        -0.7491998177697621,
        -0.7404507231722532,
        -0.731360971838463,
        -0.6950085782340483,
        -0.7490440685463438,
        -0.7503185715728816,
        -0.7439511026450295,
        -0.737518358493887,
        -0.0023425399232430144,
        -0.7491751972049825,
        1.0,
        -0.7580319446327872,
        -0.759675702851428,
        -0.67425815886198,
        -0.757175452192479
      ],
      [
        -0.7390182407013097,
        -0.7540132069780829,
        -0.7578318117913279,
        -0.7495912807877063,
        -0.7582136038808907,
        -0.7557511394977261,
        -0.7556405299180927,
        -0.7430036942648702,
        -0.7394690363253482,
        -0.7532808667126918,
        -0.7530964142107217,
        -0.7549185143374444,
        -0.7552539502154905,
        -0.7467221773305888,
        -0.7580319446327872,
        1.0,
        -0.7546422276889574,
        -0.7452315358057192,
        -0.7576203417463738
      ],
      [
        -0.7609191943926403,
        -0.7561104116675295,
        -0.7542344591022012,
        -0.7420991041466782,
        -0.7547762187048721,
        -0.7445947489316656,
        -0.7493609193207751,
        -0.7402724158242859,
        -0.7450194999033187,
        -0.7541013796755693,
        -0.3177272383818145,
        -0.7533720234001854,
        -0.7571338104848548,
        -0.7540958371053557,
        -0.759675702851428,
        -0.7546422276889574,
        1.0,
        -0.7410600958353534,
        -0.7499927495967713
      ],
      [
        -0.7407451163421616,
        -0.7285532935355528,
        -0.6869775686632846,
        -0.7066931129509907,
        -0.7250825610151637,
        -0.5244677080062349,
        -0.5082221016600472,
        -0.1544492955076553,
        -0.7372007258631952,
        -0.7146192859936654,
        -0.47538001345147773,
        -0.7239636442915218,
        -0.724299225775519,
        -0.7393165477398542,
        -0.67425815886198,
        -0.7452315358057192,
        -0.7410600958353534,
        1.0,
        -0.7349070623033465
      ],
      [
        -0.737054805746008,
        -0.7463903823838502,
        -0.6518000829045965,
        -0.41053593392754495,
        -0.7116876117881846,
        -0.7448528784704811,
        -0.7186923713982696,
        -0.7371938424818825,
        -0.7619514178689777,
        -0.5381199331935154,
        -0.7388641478229381,
        -0.7239947190913005,
        -0.7569484204456068,
        -0.7435047956011565,
        -0.757175452192479,
        -0.7576203417463738,
        -0.7499927495967713,
        -0.7349070623033465,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        51,
        19,
        14,
        19,
        2,
        4,
        3,
        2,
        4,
        2,
        0,
        1,
        0,
        6,
        1,
        1,
        3,
        10,
        2
      ],
      "2020-02": [
        37,
        8,
        13,
        14,
        1,
        4,
        6,
        2,
        7,
        1,
        0,
        0,
        3,
        0,
        2,
        3,
        3,
        10,
        5
      ],
      "2020-03": [
        40,
        10,
        11,
        8,
        1,
        5,
        5,
        6,
        3,
        4,
        0,
        1,
        13,
        6,
        2,
        3,
        1,
        14,
        3
      ],
      "2020-04": [
        54,
        16,
        17,
        9,
        3,
        5,
        5,
        3,
        4,
        4,
        0,
        9,
        33,
        10,
        9,
        2,
        2,
        13,
        1
      ],
      "2020-05": [
        87,
        19,
        12,
        9,
        5,
        8,
        4,
        4,
        4,
        2,
        0,
        5,
        46,
        6,
        24,
        2,
        6,
        17,
        3
      ],
      "2020-06": [
        84,
        8,
        26,
        17,
        1,
        5,
        3,
        7,
        7,
        5,
        2,
        7,
        41,
        7,
        13,
        4,
        9,
        22,
        7
      ],
      "2020-07": [
        74,
        18,
        18,
        21,
        3,
        4,
        5,
        8,
        7,
        7,
        2,
        9,
        35,
        11,
        10,
        2,
        11,
        26,
        5
      ],
      "2020-08": [
        77,
        11,
        17,
        24,
        0,
        4,
        4,
        6,
        2,
        2,
        1,
        4,
        40,
        4,
        8,
        1,
        5,
        11,
        2
      ],
      "2020-09": [
        61,
        9,
        18,
        18,
        4,
        2,
        6,
        6,
        8,
        3,
        5,
        4,
        25,
        9,
        9,
        2,
        7,
        25,
        3
      ],
      "2020-10": [
        69,
        15,
        24,
        16,
        3,
        5,
        5,
        6,
        3,
        3,
        1,
        3,
        21,
        9,
        10,
        3,
        4,
        13,
        0
      ],
      "2020-11": [
        62,
        14,
        15,
        13,
        1,
        2,
        8,
        4,
        3,
        3,
        1,
        5,
        34,
        4,
        4,
        4,
        3,
        13,
        5
      ],
      "2020-12": [
        45,
        11,
        15,
        15,
        2,
        4,
        1,
        3,
        1,
        5,
        1,
        5,
        17,
        8,
        14,
        1,
        3,
        13,
        7
      ],
      "2021-01": [
        68,
        26,
        16,
        22,
        2,
        7,
        7,
        5,
        6,
        2,
        2,
        2,
        20,
        9,
        7,
        7,
        1,
        13,
        3
      ],
      "2021-02": [
        57,
        17,
        21,
        13,
        1,
        7,
        7,
        2,
        10,
        4,
        1,
        3,
        12,
        8,
        5,
        3,
        5,
        4,
        3
      ],
      "2021-03": [
        53,
        14,
        15,
        13,
        3,
        3,
        1,
        4,
        7,
        3,
        0,
        1,
        19,
        9,
        6,
        1,
        1,
        13,
        6
      ],
      "2021-04": [
        56,
        18,
        14,
        17,
        0,
        7,
        3,
        3,
        3,
        3,
        0,
        1,
        22,
        9,
        5,
        2,
        1,
        6,
        3
      ],
      "2021-05": [
        56,
        14,
        27,
        23,
        1,
        6,
        2,
        4,
        4,
        6,
        1,
        1,
        25,
        7,
        5,
        4,
        5,
        11,
        0
      ],
      "2021-06": [
        50,
        14,
        31,
        20,
        3,
        6,
        3,
        5,
        4,
        6,
        1,
        4,
        26,
        7,
        2,
        3,
        1,
        17,
        9
      ],
      "2021-07": [
        55,
        20,
        19,
        14,
        1,
        4,
        7,
        5,
        9,
        5,
        0,
        2,
        15,
        7,
        3,
        2,
        1,
        10,
        9
      ],
      "2021-08": [
        80,
        16,
        15,
        12,
        2,
        3,
        3,
        4,
        1,
        1,
        2,
        3,
        35,
        9,
        3,
        4,
        2,
        20,
        8
      ],
      "2021-09": [
        41,
        20,
        23,
        17,
        4,
        3,
        1,
        1,
        5,
        5,
        0,
        1,
        22,
        2,
        1,
        1,
        1,
        17,
        7
      ],
      "2021-10": [
        51,
        13,
        33,
        19,
        4,
        7,
        1,
        2,
        0,
        1,
        2,
        4,
        18,
        6,
        1,
        3,
        3,
        16,
        5
      ],
      "2021-11": [
        34,
        14,
        15,
        24,
        2,
        5,
        1,
        1,
        2,
        5,
        1,
        2,
        27,
        4,
        3,
        3,
        5,
        16,
        3
      ],
      "2021-12": [
        38,
        11,
        17,
        17,
        2,
        4,
        0,
        4,
        6,
        4,
        1,
        2,
        14,
        2,
        5,
        2,
        2,
        9,
        4
      ],
      "2022-01": [
        51,
        7,
        17,
        18,
        0,
        6,
        2,
        3,
        5,
        5,
        3,
        1,
        18,
        4,
        2,
        4,
        0,
        19,
        0
      ],
      "2022-02": [
        61,
        14,
        29,
        18,
        2,
        3,
        1,
        4,
        2,
        5,
        0,
        3,
        19,
        2,
        5,
        4,
        2,
        7,
        1
      ],
      "2022-03": [
        56,
        16,
        15,
        8,
        3,
        5,
        6,
        5,
        8,
        3,
        1,
        0,
        13,
        4,
        1,
        3,
        2,
        9,
        4
      ],
      "2022-04": [
        56,
        9,
        17,
        17,
        2,
        2,
        3,
        0,
        6,
        4,
        0,
        0,
        16,
        3,
        0,
        3,
        3,
        12,
        4
      ],
      "2022-05": [
        50,
        13,
        34,
        25,
        10,
        4,
        1,
        5,
        4,
        11,
        3,
        2,
        13,
        12,
        0,
        2,
        5,
        13,
        5
      ],
      "2022-06": [
        53,
        13,
        32,
        28,
        10,
        0,
        3,
        1,
        2,
        3,
        2,
        4,
        14,
        8,
        6,
        4,
        4,
        16,
        3
      ],
      "2022-07": [
        55,
        16,
        32,
        13,
        3,
        7,
        6,
        3,
        5,
        5,
        2,
        7,
        10,
        6,
        2,
        2,
        5,
        16,
        4
      ],
      "2022-08": [
        49,
        12,
        30,
        18,
        4,
        3,
        3,
        4,
        1,
        3,
        0,
        3,
        9,
        5,
        2,
        2,
        4,
        21,
        5
      ],
      "2022-09": [
        38,
        7,
        30,
        15,
        7,
        5,
        3,
        4,
        6,
        7,
        2,
        2,
        14,
        7,
        1,
        4,
        3,
        9,
        3
      ],
      "2022-10": [
        58,
        18,
        27,
        15,
        1,
        4,
        3,
        7,
        4,
        9,
        0,
        4,
        13,
        6,
        2,
        6,
        8,
        11,
        2
      ],
      "2022-11": [
        51,
        16,
        28,
        22,
        6,
        5,
        3,
        0,
        7,
        6,
        1,
        5,
        15,
        5,
        2,
        4,
        3,
        17,
        6
      ],
      "2022-12": [
        80,
        12,
        19,
        14,
        4,
        2,
        1,
        6,
        4,
        6,
        2,
        1,
        10,
        2,
        3,
        2,
        5,
        15,
        5
      ],
      "2023-01": [
        57,
        21,
        22,
        18,
        10,
        7,
        2,
        4,
        7,
        7,
        2,
        1,
        8,
        4,
        1,
        6,
        7,
        12,
        1
      ],
      "2023-02": [
        38,
        22,
        26,
        19,
        9,
        3,
        4,
        7,
        3,
        8,
        2,
        1,
        5,
        4,
        1,
        3,
        3,
        19,
        7
      ],
      "2023-03": [
        60,
        12,
        43,
        38,
        16,
        3,
        5,
        4,
        7,
        11,
        1,
        3,
        9,
        10,
        3,
        7,
        5,
        13,
        6
      ],
      "2023-04": [
        53,
        21,
        28,
        27,
        24,
        6,
        4,
        3,
        2,
        13,
        2,
        5,
        9,
        3,
        1,
        4,
        6,
        11,
        3
      ],
      "2023-05": [
        71,
        27,
        55,
        54,
        26,
        3,
        5,
        5,
        6,
        19,
        4,
        2,
        6,
        8,
        3,
        4,
        5,
        28,
        5
      ],
      "2023-06": [
        67,
        14,
        41,
        40,
        29,
        4,
        10,
        5,
        9,
        13,
        4,
        4,
        8,
        9,
        1,
        4,
        4,
        23,
        7
      ],
      "2023-07": [
        60,
        13,
        31,
        42,
        31,
        4,
        2,
        5,
        5,
        15,
        0,
        3,
        6,
        8,
        0,
        6,
        3,
        16,
        4
      ],
      "2023-08": [
        60,
        15,
        30,
        24,
        28,
        4,
        0,
        12,
        7,
        14,
        1,
        2,
        8,
        6,
        2,
        2,
        2,
        18,
        8
      ],
      "2023-09": [
        65,
        11,
        28,
        29,
        31,
        9,
        5,
        7,
        1,
        17,
        4,
        4,
        9,
        7,
        1,
        1,
        5,
        15,
        5
      ],
      "2023-10": [
        73,
        23,
        23,
        29,
        44,
        4,
        1,
        7,
        5,
        19,
        3,
        2,
        7,
        6,
        3,
        5,
        3,
        17,
        3
      ],
      "2023-11": [
        73,
        11,
        28,
        36,
        35,
        5,
        5,
        1,
        1,
        20,
        1,
        5,
        7,
        7,
        1,
        4,
        2,
        15,
        4
      ],
      "2023-12": [
        80,
        24,
        33,
        31,
        38,
        1,
        5,
        3,
        8,
        16,
        2,
        3,
        6,
        3,
        1,
        4,
        2,
        27,
        4
      ],
      "2024-01": [
        78,
        26,
        25,
        46,
        42,
        4,
        2,
        2,
        5,
        24,
        0,
        4,
        8,
        9,
        1,
        3,
        7,
        13,
        6
      ],
      "2024-02": [
        103,
        24,
        35,
        58,
        69,
        6,
        2,
        3,
        5,
        19,
        1,
        6,
        14,
        8,
        2,
        2,
        8,
        21,
        4
      ],
      "2024-03": [
        97,
        21,
        29,
        46,
        59,
        6,
        3,
        5,
        3,
        38,
        2,
        2,
        7,
        6,
        5,
        4,
        11,
        18,
        10
      ],
      "2024-04": [
        71,
        15,
        33,
        47,
        40,
        8,
        1,
        4,
        8,
        21,
        1,
        6,
        6,
        5,
        3,
        1,
        3,
        15,
        7
      ],
      "2024-05": [
        74,
        22,
        27,
        52,
        54,
        9,
        4,
        3,
        6,
        26,
        2,
        2,
        9,
        8,
        2,
        4,
        6,
        28,
        9
      ],
      "2024-06": [
        88,
        13,
        34,
        45,
        65,
        6,
        1,
        1,
        6,
        16,
        1,
        5,
        9,
        2,
        6,
        1,
        3,
        17,
        4
      ],
      "2024-07": [
        91,
        23,
        29,
        57,
        65,
        3,
        3,
        7,
        7,
        28,
        1,
        8,
        7,
        6,
        2,
        6,
        9,
        17,
        5
      ],
      "2024-08": [
        71,
        18,
        14,
        49,
        48,
        6,
        0,
        2,
        3,
        16,
        0,
        3,
        9,
        9,
        2,
        2,
        4,
        14,
        6
      ],
      "2024-09": [
        74,
        18,
        23,
        49,
        47,
        6,
        6,
        3,
        3,
        13,
        3,
        5,
        3,
        4,
        4,
        3,
        3,
        21,
        5
      ],
      "2024-10": [
        86,
        26,
        29,
        71,
        88,
        4,
        5,
        12,
        9,
        28,
        6,
        5,
        7,
        11,
        1,
        4,
        6,
        24,
        6
      ],
      "2024-11": [
        68,
        16,
        19,
        61,
        59,
        9,
        2,
        5,
        1,
        21,
        0,
        9,
        5,
        6,
        3,
        7,
        7,
        16,
        2
      ],
      "2024-12": [
        88,
        15,
        25,
        51,
        55,
        9,
        3,
        8,
        8,
        32,
        6,
        11,
        10,
        8,
        0,
        3,
        9,
        12,
        6
      ],
      "2025-01": [
        89,
        26,
        18,
        78,
        62,
        7,
        2,
        8,
        4,
        19,
        0,
        10,
        6,
        7,
        3,
        3,
        6,
        15,
        7
      ],
      "2025-02": [
        109,
        21,
        21,
        83,
        98,
        6,
        4,
        5,
        3,
        22,
        3,
        9,
        7,
        10,
        3,
        3,
        6,
        26,
        2
      ],
      "2025-03": [
        74,
        18,
        11,
        90,
        87,
        6,
        3,
        4,
        7,
        35,
        1,
        6,
        15,
        7,
        4,
        5,
        6,
        19,
        3
      ],
      "2025-04": [
        67,
        19,
        15,
        88,
        81,
        5,
        5,
        9,
        6,
        30,
        1,
        9,
        6,
        3,
        1,
        4,
        9,
        17,
        9
      ],
      "2025-05": [
        107,
        25,
        22,
        95,
        120,
        6,
        4,
        2,
        3,
        34,
        4,
        2,
        8,
        5,
        0,
        6,
        3,
        25,
        9
      ],
      "2025-06": [
        96,
        11,
        22,
        60,
        110,
        10,
        3,
        2,
        3,
        19,
        6,
        6,
        6,
        8,
        2,
        1,
        5,
        19,
        7
      ],
      "2025-07": [
        96,
        17,
        14,
        79,
        77,
        7,
        4,
        6,
        4,
        24,
        1,
        7,
        4,
        6,
        3,
        6,
        4,
        16,
        3
      ],
      "2025-08": [
        84,
        11,
        20,
        95,
        96,
        4,
        3,
        6,
        0,
        32,
        7,
        9,
        3,
        6,
        3,
        4,
        9,
        21,
        4
      ],
      "2025-09": [
        49,
        11,
        12,
        34,
        51,
        2,
        0,
        3,
        1,
        14,
        0,
        4,
        3,
        1,
        0,
        1,
        5,
        11,
        5
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Desirable Characteristics for AI Teaching Assistants in Programming Education",
          "year": "2024-05",
          "abstract": "Providing timely and personalized feedback to large numbers of students is a\nlong-standing challenge in programming courses. Relying on human teaching\nassistants (TAs) has been extensively studied, revealing a number of potential\nshortcomings. These include inequitable access for students with low confidence\nwhen needing support, as well as situations where TAs provide direct solutions\nwithout helping students to develop their own problem-solving skills. With the\nadvent of powerful large language models (LLMs), digital teaching assistants\nconfigured for programming contexts have emerged as an appealing and scalable\nway to provide instant, equitable, round-the-clock support. Although digital\nTAs can provide a variety of help for programming tasks, from high-level\nproblem solving advice to direct solution generation, the effectiveness of such\ntools depends on their ability to promote meaningful learning experiences. If\nstudents find the guardrails implemented in digital TAs too constraining, or if\nother expectations are not met, they may seek assistance in ways that do not\nhelp them learn. Thus, it is essential to identify the features that students\nbelieve make digital teaching assistants valuable. We deployed an LLM-powered\ndigital assistant in an introductory programming course and collected student\nfeedback ($n=813$) on the characteristics of the tool they perceived to be most\nimportant. Our results highlight that students value such tools for their\nability to provide instant, engaging support, particularly during peak times\nsuch as before assessment deadlines. They also expressed a strong preference\nfor features that enable them to retain autonomy in their learning journey,\nsuch as scaffolding that helps to guide them through problem-solving steps\nrather than simply being shown direct solutions.",
          "arxiv_id": "2405.14178v1"
        },
        {
          "title": "Students' Perceptions and Preferences of Generative Artificial Intelligence Feedback for Programming",
          "year": "2023-12",
          "abstract": "The rapid evolution of artificial intelligence (AI), specifically large\nlanguage models (LLMs), has opened opportunities for various educational\napplications. This paper explored the feasibility of utilizing ChatGPT, one of\nthe most popular LLMs, for automating feedback for Java programming assignments\nin an introductory computer science (CS1) class. Specifically, this study\nfocused on three questions: 1) To what extent do students view LLM-generated\nfeedback as formative? 2) How do students see the comparative affordances of\nfeedback prompts that include their code, vs. those that exclude it? 3) What\nenhancements do students suggest for improving AI-generated feedback? To\naddress these questions, we generated automated feedback using the ChatGPT API\nfor four lab assignments in the CS1 class. The survey results revealed that\nstudents perceived the feedback as aligning well with formative feedback\nguidelines established by Shute. Additionally, students showed a clear\npreference for feedback generated by including the students' code as part of\nthe LLM prompt, and our thematic study indicated that the preference was mainly\nattributed to the specificity, clarity, and corrective nature of the feedback.\nMoreover, this study found that students generally expected specific and\ncorrective feedback with sufficient code examples, but had diverged opinions on\nthe tone of the feedback. This study demonstrated that ChatGPT could generate\nJava programming assignment feedback that students perceived as formative. It\nalso offered insights into the specific improvements that would make the\nChatGPT-generated feedback useful for students.",
          "arxiv_id": "2312.11567v1"
        },
        {
          "title": "Exploring Student Behaviors and Motivations using AI TAs with Optional Guardrails",
          "year": "2025-04",
          "abstract": "AI-powered chatbots and digital teaching assistants (AI TAs) are gaining\npopularity in programming education, offering students timely and personalized\nfeedback. Despite their potential benefits, concerns about student\nover-reliance and academic misconduct have prompted the introduction of\n\"guardrails\" into AI TAs - features that provide scaffolded support rather than\ndirect solutions. However, overly restrictive guardrails may lead students to\nbypass these tools and use unconstrained AI models, where interactions are not\nobservable, thus limiting our understanding of students' help-seeking\nbehaviors. To investigate this, we designed and deployed a novel AI TA tool\nwith optional guardrails in one lab of a large introductory programming course.\nAs students completed three code writing and debugging tasks, they had the\noption to receive guardrailed help or use a \"See Solution\" feature which\ndisabled the guardrails and generated a verbatim response from the underlying\nmodel. We investigate students' motivations and use of this feature and examine\nthe association between usage and their course performance. We found that 50%\nof the 885 students used the \"See Solution\" feature for at least one problem\nand 14% used it for all three problems. Additionally, low-performing students\nwere more likely to use this feature and use it close to the deadline as they\nstarted assignments later. The predominant factors that motivated students to\ndisable the guardrails were assistance in solving problems, time pressure, lack\nof self-regulation, and curiosity. Our work provides insights into students'\nsolution-seeking motivations and behaviors, which has implications for the\ndesign of AI TAs that balance pedagogical goals with student preferences.",
          "arxiv_id": "2504.11146v1"
        }
      ],
      "1": [
        {
          "title": "Understanding misinformation in India: The case for a meaningful regulatory approach for social media platforms",
          "year": "2022-06",
          "abstract": "For research, this paper has included numerous literature that are covering a\nvariety of information on the topics of misinformation, social media and fake\nnews, regulation of misinformation and social media platforms, all presented\nfor India. Studies including thematic analysis of misinformation, brief history\non social media and its amplification of misinformation, current and past\npolicy interventions by the Indian government, history of self-regulations in\nindustries, and an analysis of regulatory approaches in the Indian context.\nThis paper aims at introducing a coherent reading into the context of\nmisinformation in the country and the subsequent social and business\ndisruptions that will follow. Utilizing lessons from history around industry\nregulations, existing policy research and framework analysis to convince the\nreader of the nature of policy intervention that will bode well for all\nstakeholders involved. The literature sources have been mentioned in their\nrespective sections for reference. The research utilized the PASTEL framework\nto analyse data collected from other research efforts covering the topic of\nmisinformation and regulation across academic whitepapers and news media blogs\nand articles, all available freely on the public domain. Relevant secondary\ndata, in terms of information, previous analysis in other research efforts, and\nliterature work included in respective sections in the paper have been\nreproduced, shared and/or indicated wherever necessary.",
          "arxiv_id": "2207.01508v1"
        },
        {
          "title": "Racism is a Virus: Anti-Asian Hate and Counterspeech in Social Media during the COVID-19 Crisis",
          "year": "2020-05",
          "abstract": "The spread of COVID-19 has sparked racism and hate on social media targeted\ntowards Asian communities. However, little is known about how racial hate\nspreads during a pandemic and the role of counterspeech in mitigating this\nspread. In this work, we study the evolution and spread of anti-Asian hate\nspeech through the lens of Twitter. We create COVID-HATE, the largest dataset\nof anti-Asian hate and counterspeech spanning 14 months, containing over 206\nmillion tweets, and a social network with over 127 million nodes. By creating a\nnovel hand-labeled dataset of 3,355 tweets, we train a text classifier to\nidentify hate and counterspeech tweets that achieves an average macro-F1 score\nof 0.832. Using this dataset, we conduct longitudinal analysis of tweets and\nusers. Analysis of the social network reveals that hateful and counterspeech\nusers interact and engage extensively with one another, instead of living in\nisolated polarized communities. We find that nodes were highly likely to become\nhateful after being exposed to hateful content. Notably, counterspeech messages\nmay discourage users from turning hateful, potentially suggesting a solution to\ncurb hate on web and social media platforms. Data and code is at\nhttp://claws.cc.gatech.edu/covid.",
          "arxiv_id": "2005.12423v2"
        },
        {
          "title": "Sensing the Pulse of the Pandemic: Geovisualizing the Demographic Disparities of Public Sentiment toward COVID-19 through Social Media",
          "year": "2023-03",
          "abstract": "Social media offers a unique lens to observe large-scale, spatial-temporal\npatterns of users reactions toward critical events. However, social media use\nvaries across demographics, with younger users being more prevalent compared to\nolder populations. This difference introduces biases in data\nrepresentativeness, and analysis based on social media without proper\nadjustment will lead to overlooking the voices of digitally marginalized\ncommunities and inaccurate estimations. This study explores solutions to\npinpoint and alleviate the demographic biases in social media analysis through\na case study estimating the public sentiment about COVID-19 using Twitter data.\nWe analyzed the pandemic-related Twitter data in the U.S. during 2020-2021 to\n(1) elucidate the uneven social media usage among demographic groups and the\ndisparities of their sentiments toward COVID-19, (2) construct an adjusted\npublic sentiment measurement based on social media, the Sentiment Adjusted by\nDemographics (SAD) index, to evaluate the spatiotemporal varying public\nsentiment toward COVID-19. The results show higher proportions of female and\nadolescent Twitter users expressing negative emotions to COVID-19. The SAD\nindex unveils that the public sentiment toward COVID-19 was most negative in\nJanuary and February 2020 and most positive in April 2020. Vermont and Wyoming\nwere the most positive and negative states toward COVID-19.",
          "arxiv_id": "2304.06120v2"
        }
      ],
      "2": [
        {
          "title": "Metrics and methods for a systematic comparison of fairness-aware machine learning algorithms",
          "year": "2020-10",
          "abstract": "Understanding and removing bias from the decisions made by machine learning\nmodels is essential to avoid discrimination against unprivileged groups.\nDespite recent progress in algorithmic fairness, there is still no clear answer\nas to which bias-mitigation approaches are most effective. Evaluation\nstrategies are typically use-case specific, rely on data with unclear bias, and\nemploy a fixed policy to convert model outputs to decision outcomes. To address\nthese problems, we performed a systematic comparison of a number of popular\nfairness algorithms applicable to supervised classification. Our study is the\nmost comprehensive of its kind. It utilizes three real and four synthetic\ndatasets, and two different ways of converting model outputs to decisions. It\nconsiders fairness, predictive-performance, calibration quality, and speed of\n28 different modelling pipelines, corresponding to both fairness-unaware and\nfairness-aware algorithms. We found that fairness-unaware algorithms typically\nfail to produce adequately fair models and that the simplest algorithms are not\nnecessarily the fairest ones. We also found that fairness-aware algorithms can\ninduce fairness without material drops in predictive power. Finally, we found\nthat dataset idiosyncracies (e.g., degree of intrinsic unfairness, nature of\ncorrelations) do affect the performance of fairness-aware approaches. Our\nresults allow the practitioner to narrow down the approach(es) they would like\nto adopt without having to know in advance their fairness requirements.",
          "arxiv_id": "2010.03986v1"
        },
        {
          "title": "Algorithmic Fairness Verification with Graphical Models",
          "year": "2021-09",
          "abstract": "In recent years, machine learning (ML) algorithms have been deployed in\nsafety-critical and high-stake decision-making, where the fairness of\nalgorithms is of paramount importance. Fairness in ML centers on detecting bias\ntowards certain demographic populations induced by an ML classifier and\nproposes algorithmic solutions to mitigate the bias with respect to different\nfairness definitions. To this end, several fairness verifiers have been\nproposed that compute the bias in the prediction of an ML\nclassifier--essentially beyond a finite dataset--given the probability\ndistribution of input features. In the context of verifying linear classifiers,\nexisting fairness verifiers are limited by accuracy due to imprecise modeling\nof correlations among features and scalability due to restrictive formulations\nof the classifiers as SSAT/SMT formulas or by sampling.\n  In this paper, we propose an efficient fairness verifier, called FVGM, that\nencodes the correlations among features as a Bayesian network. In contrast to\nexisting verifiers, FVGM proposes a stochastic subset-sum based approach for\nverifying linear classifiers. Experimentally, we show that FVGM leads to an\naccurate and scalable assessment for more diverse families of\nfairness-enhancing algorithms, fairness attacks, and group/causal fairness\nmetrics than the state-of-the-art fairness verifiers. We also demonstrate that\nFVGM facilitates the computation of fairness influence functions as a stepping\nstone to detect the source of bias induced by subsets of features.",
          "arxiv_id": "2109.09447v2"
        },
        {
          "title": "Accurate Fairness: Improving Individual Fairness without Trading Accuracy",
          "year": "2022-05",
          "abstract": "Accuracy and individual fairness are both crucial for trustworthy machine\nlearning, but these two aspects are often incompatible with each other so that\nenhancing one aspect may sacrifice the other inevitably with side effects of\ntrue bias or false fairness. We propose in this paper a new fairness criterion,\naccurate fairness, to align individual fairness with accuracy. Informally, it\nrequires the treatments of an individual and the individual's similar\ncounterparts to conform to a uniform target, i.e., the ground truth of the\nindividual. We prove that accurate fairness also implies typical group fairness\ncriteria over a union of similar sub-populations. We then present a Siamese\nfairness in-processing approach to minimize the accuracy and fairness losses of\na machine learning model under the accurate fairness constraints. To the best\nof our knowledge, this is the first time that a Siamese approach is adapted for\nbias mitigation. We also propose fairness confusion matrix-based metrics,\nfair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between\naccuracy and individual fairness. Comparative case studies with popular\nfairness datasets show that our Siamese fairness approach can achieve on\naverage 1.02%-8.78% higher individual fairness (in terms of fairness through\nawareness) and 8.38%-13.69% higher accuracy, as well as 10.09%-20.57% higher\ntrue fair rate, and 5.43%-10.01% higher fair-F1 score, than the\nstate-of-the-art bias mitigation techniques. This demonstrates that our Siamese\nfairness approach can indeed improve individual fairness without trading\naccuracy. Finally, the accurate fairness criterion and Siamese fairness\napproach are applied to mitigate the possible service discrimination with a\nreal Ctrip dataset, by on average fairly serving 112.33% more customers\n(specifically, 81.29% more customers in an accurately fair way) than baseline\nmodels.",
          "arxiv_id": "2205.08704v2"
        }
      ],
      "3": [
        {
          "title": "A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies",
          "year": "2025-08",
          "abstract": "Public-sector bureaucracies seek to reap the benefits of artificial\nintelligence (AI), but face important concerns about accountability and\ntransparency when using AI systems. In particular, perception or actuality of\nAI agency might create ethics sinks - constructs that facilitate dissipation of\nresponsibility when AI systems of disputed moral status interface with\nbureaucratic structures. Here, we reject the notion that ethics sinks are a\nnecessary consequence of introducing AI systems into bureaucracies. Rather,\nwhere they appear, they are the product of structural design decisions across\nboth the technology and the institution deploying it. We support this claim via\na systematic application of conceptions of moral agency in AI ethics to\nWeberian bureaucracy. We establish that it is both desirable and feasible to\nrender AI systems as tools for the generation of organizational transparency\nand legibility, which continue the processes of Weberian rationalization\ninitiated by previous waves of digitalization. We present a three-point Moral\nAgency Framework for legitimate integration of AI in bureaucratic structures:\n(a) maintain clear and just human lines of accountability, (b) ensure humans\nwhose work is augmented by AI systems can verify the systems are functioning\ncorrectly, and (c) introduce AI only where it doesn't inhibit the capacity of\nbureaucracies towards either of their twin aims of legitimacy and stewardship.\nWe suggest that AI introduced within this framework can not only improve\nefficiency and productivity while avoiding ethics sinks, but also improve the\ntransparency and even the legitimacy of a bureaucracy.",
          "arxiv_id": "2508.08231v3"
        },
        {
          "title": "Why do Experts Disagree on Existential Risk and P(doom)? A Survey of AI Experts",
          "year": "2025-01",
          "abstract": "The development of artificial general intelligence (AGI) is likely to be one\nof humanity's most consequential technological advancements. Leading AI labs\nand scientists have called for the global prioritization of AI safety citing\nexistential risks comparable to nuclear war. However, research on catastrophic\nrisks and AI alignment is often met with skepticism, even by experts.\nFurthermore, online debate over the existential risk of AI has begun to turn\ntribal (e.g. name-calling such as \"doomer\" or \"accelerationist\"). Until now, no\nsystematic study has explored the patterns of belief and the levels of\nfamiliarity with AI safety concepts among experts. I surveyed 111 AI experts on\ntheir familiarity with AI safety concepts, key objections to AI safety, and\nreactions to safety arguments. My findings reveal that AI experts cluster into\ntwo viewpoints -- an \"AI as controllable tool\" and an \"AI as uncontrollable\nagent\" perspective -- diverging in beliefs toward the importance of AI safety.\nWhile most experts (78%) agreed or strongly agreed that \"technical AI\nresearchers should be concerned about catastrophic risks\", many were unfamiliar\nwith specific AI safety concepts. For example, only 21% of surveyed experts had\nheard of \"instrumental convergence,\" a fundamental concept in AI safety\npredicting that advanced AI systems will tend to pursue common sub-goals (such\nas self-preservation). The least concerned participants were the least familiar\nwith concepts like this, suggesting that effective communication of AI safety\nshould begin with establishing clear conceptual foundations in the field.",
          "arxiv_id": "2502.14870v1"
        },
        {
          "title": "Ethics in the Age of AI: An Analysis of AI Practitioners' Awareness and Challenges",
          "year": "2023-07",
          "abstract": "Ethics in AI has become a debated topic of public and expert discourse in\nrecent years. But what do people who build AI - AI practitioners - have to say\nabout their understanding of AI ethics and the challenges associated with\nincorporating it in the AI-based systems they develop? Understanding AI\npractitioners' views on AI ethics is important as they are the ones closest to\nthe AI systems and can bring about changes and improvements. We conducted a\nsurvey aimed at understanding AI practitioners' awareness of AI ethics and\ntheir challenges in incorporating ethics. Based on 100 AI practitioners'\nresponses, our findings indicate that majority of AI practitioners had a\nreasonable familiarity with the concept of AI ethics, primarily due to\nworkplace rules and policies. Privacy protection and security was the ethical\nprinciple that majority of them were aware of. Formal education/training was\nconsidered somewhat helpful in preparing practitioners to incorporate AI\nethics. The challenges that AI practitioners faced in the development of\nethical AI-based systems included (i) general challenges, (ii)\ntechnology-related challenges and (iii) human-related challenges. We also\nidentified areas needing further investigation and provided recommendations to\nassist AI practitioners and companies in incorporating ethics into AI\ndevelopment.",
          "arxiv_id": "2307.10057v1"
        }
      ],
      "4": [
        {
          "title": "LIBRA: Measuring Bias of Large Language Model from a Local Context",
          "year": "2025-02",
          "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing applications, yet their widespread use raises concerns regarding\ninherent biases that may reduce utility or harm for particular social groups.\nDespite the advancement in addressing LLM bias, existing research has two major\nlimitations. First, existing LLM bias evaluation focuses on the U.S. cultural\ncontext, making it challenging to reveal stereotypical biases of LLMs toward\nother cultures, leading to unfair development and use of LLMs. Second, current\nbias evaluation often assumes models are familiar with the target social\ngroups. When LLMs encounter words beyond their knowledge boundaries that are\nunfamiliar in their training data, they produce irrelevant results in the local\ncontext due to hallucinations and overconfidence, which are not necessarily\nindicative of inherent bias. This research addresses these limitations with a\nLocal Integrated Bias Recognition and Assessment Framework (LIBRA) for\nmeasuring bias using datasets sourced from local corpora without crowdsourcing.\nImplementing this framework, we develop a dataset comprising over 360,000 test\ncases in the New Zealand context. Furthermore, we propose the Enhanced\nIdealized CAT Score (EiCAT), integrating the iCAT score with a beyond knowledge\nboundary score (bbs) and a distribution divergence-based bias measurement to\ntackle the challenge of LLMs encountering words beyond knowledge boundaries.\nOur results show that the BERT family, GPT-2, and Llama-3 models seldom\nunderstand local words in different contexts. While Llama-3 exhibits larger\nbias, it responds better to different cultural contexts. The code and dataset\nare available at: https://github.com/ipangbo/LIBRA.",
          "arxiv_id": "2502.01679v1"
        },
        {
          "title": "Large Language Models are overconfident and amplify human bias",
          "year": "2025-05",
          "abstract": "Large language models (LLMs) are revolutionizing every aspect of society.\nThey are increasingly used in problem-solving tasks to substitute human\nassessment and reasoning. LLMs are trained on what humans write and thus prone\nto learn human biases. One of the most widespread human biases is\noverconfidence. We examine whether LLMs inherit this bias. We automatically\nconstruct reasoning problems with known ground truths, and prompt LLMs to\nassess the confidence in their answers, closely following similar protocols in\nhuman experiments. We find that all five LLMs we study are overconfident: they\noverestimate the probability that their answer is correct between 20% and 60%.\nHumans have accuracy similar to the more advanced LLMs, but far lower\noverconfidence. Although humans and LLMs are similarly biased in questions\nwhich they are certain they answered correctly, a key difference emerges\nbetween them: LLM bias increases sharply relative to humans if they become less\nsure that their answers are correct. We also show that LLM input has ambiguous\neffects on human decision making: LLM input leads to an increase in the\naccuracy, but it more than doubles the extent of overconfidence in the answers.",
          "arxiv_id": "2505.02151v1"
        },
        {
          "title": "Gender bias and stereotypes in Large Language Models",
          "year": "2023-08",
          "abstract": "Large Language Models (LLMs) have made substantial progress in the past\nseveral months, shattering state-of-the-art benchmarks in many domains. This\npaper investigates LLMs' behavior with respect to gender stereotypes, a known\nissue for prior models. We use a simple paradigm to test the presence of gender\nbias, building on but differing from WinoBias, a commonly used gender bias\ndataset, which is likely to be included in the training data of current LLMs.\nWe test four recently published LLMs and demonstrate that they express biased\nassumptions about men and women's occupations. Our contributions in this paper\nare as follows: (a) LLMs are 3-6 times more likely to choose an occupation that\nstereotypically aligns with a person's gender; (b) these choices align with\npeople's perceptions better than with the ground truth as reflected in official\njob statistics; (c) LLMs in fact amplify the bias beyond what is reflected in\nperceptions or the ground truth; (d) LLMs ignore crucial ambiguities in\nsentence structure 95% of the time in our study items, but when explicitly\nprompted, they recognize the ambiguity; (e) LLMs provide explanations for their\nchoices that are factually inaccurate and likely obscure the true reason behind\ntheir predictions. That is, they provide rationalizations of their biased\nbehavior. This highlights a key property of these models: LLMs are trained on\nimbalanced datasets; as such, even with the recent successes of reinforcement\nlearning with human feedback, they tend to reflect those imbalances back at us.\nAs with other types of societal biases, we suggest that LLMs must be carefully\ntested to ensure that they treat minoritized individuals and communities\nequitably.",
          "arxiv_id": "2308.14921v1"
        }
      ],
      "5": [
        {
          "title": "Transition of car-based human-mobility in the pandemic era: Data insight from a cross-border region in Europe",
          "year": "2025-09",
          "abstract": "Many transport authorities are collecting and publishing almost real-time\nroad traffic data to meet the growing trend of massive open data, a vital\nresource for foresight decision support systems considering deep data insights.\nWe explored the spatio-temporal transitions in the cross-country road traffic\nvolumes in the context of modelling behavioural transitions in car-based human\nmobility. This study reports on individual car-based daily travel behaviour\ndetected, before (2018) and during the COVID pandemic (2020), between Germany\nand neighbouring countries. In the case of Luxembourg, the Bridges and Roads\nAuthority has installed a large digital traffic observatory infrastructure\nthrough the adoption of sensor-based IoT technologies, like other European\nmember states. Since 2016, they have provided high-performance data processing\nand published open data on the country's road traffic. The dataset contains an\nhourly traffic count for different vehicle types, daily for representative\nobservation points, followed by a major road network. The original dataset\ncontains significant missing entries, so comprehensive data harmonization was\nperformed. We observed the decrease in traffic volumes during pandemic factors\n(e.g. lockdowns and remote work) period by following global trend of reduced\npersonal mobility. The understanding the dynamic adaptive travel behaviours\nprovide a potential opportunity to generate the actionable insight including\ntemporal and spatial implications. This study demonstrates that the national\nopen traffic data products can have adoption potential to address cross-border\ninsights. In relevance to the net-zero carbon transition, further study should\nshed light on the interpolation and downscaling approaches at the comprehensive\nroad-network level for identifying pollution hot spots, causal link to\nfunctional landuse patterns and calculation of spatial influence area.",
          "arxiv_id": "2509.05166v2"
        },
        {
          "title": "Smart Urban Mobility: When Mobility Systems Meet Smart Data",
          "year": "2020-05",
          "abstract": "Cities around the world are expanding dramatically, with urban population\ngrowth reaching nearly 2.5 billion people in urban areas and road traffic\ngrowth exceeding 1.2 billion cars by 2050. The economic contribution of the\ntransport sector represents 5% of the GDP in Europe and costs an average of US\n$482.05 billion in the United States. These figures indicate the rapid rise of\nindustrial cities and the urgent need to move from traditional cities to smart\ncities. This article provides a survey of different approaches and technologies\nsuch as intelligent transportation systems (ITS) that leverage communication\ntechnologies to help maintain road users safe while driving, as well as support\nautonomous mobility through the optimization of control systems. The role of\nITS is strengthened when combined with accurate artificial intelligence models\nthat are built to optimize urban planning, analyze crowd behavior and predict\ntraffic conditions. AI-driven ITS is becoming possible thanks to the existence\nof a large volume of mobility data generated by billions of users through their\nuse of new technologies and online social media. The optimization of urban\nplanning enhances vehicle routing capabilities and solves traffic congestion\nproblems, as discussed in this paper. From an ecological perspective, we\ndiscuss the measures and incentives provided to foster the use of mobility\nsystems. We also underline the role of the political will in promoting open\ndata in the transport sector, considered as an essential ingredient for\ndeveloping technological solutions necessary for cities to become healthier and\nmore sustainable.",
          "arxiv_id": "2005.06626v1"
        },
        {
          "title": "Exploring the effect of spatial scales in studying urban mobility pattern",
          "year": "2025-06",
          "abstract": "Urban mobility plays a crucial role in the functioning of cities, influencing\neconomic activity, accessibility, and quality of life. However, the\neffectiveness of analytical models in understanding urban mobility patterns can\nbe significantly affected by the spatial scales employed in the analysis. This\npaper explores the impact of spatial scales on the performance of the gravity\nmodel in explaining urban mobility patterns using public transport flow data in\nSingapore. The model is evaluated across multiple spatial scales of origin and\ndestination locations, ranging from individual bus stops and train stations to\nbroader regional aggregations. Results indicate the existence of an optimal\nintermediate spatial scale at which the gravity model performs best. At the\nfinest scale, where individual transport nodes are considered, the model\nexhibits poor performance due to noisy and highly variable travel patterns.\nConversely, at larger scales, model performance also suffers as\nover-aggregation of transport nodes results in excessive generalisation which\nobscures the underlying mobility dynamics. Furthermore, distance-based spatial\naggregation of transport nodes proves to outperform administrative\nboundary-based aggregation, suggesting that actual urban organisation and\nmovement patterns may not necessarily align with imposed administrative\ndivisions. These insights highlight the importance of selecting appropriate\nspatial scales in mobility analysis and urban modelling in general, offering\nvaluable guidance for urban and transport planning efforts aimed at enhancing\nmobility in complex urban environments.",
          "arxiv_id": "2506.16762v1"
        }
      ],
      "6": [
        {
          "title": "Integrating Information Technology in Healthcare: Recent Developments, Challenges, and Future Prospects for Urban and Regional Health",
          "year": "2023-07",
          "abstract": "The use of technology in healthcare has become increasingly popular in recent\nyears, with the potential to improve how healthcare is delivered, patient\noutcomes, and cost-effectiveness. This review paper provides an overview of how\ntechnology has been used in healthcare, particularly in cities and for\npersonalized medicine. The paper discusses different ways technology is being\nused in healthcare, such as electronic health records, telemedicine, remote\nmonitoring, medical imaging, wearable devices, and artificial intelligence. It\nalso looks at the challenges and problems that come with using technology in\nhealthcare, such as keeping patient data private and secure, making sure\ndifferent technology systems can work together, and ensuring patients are\ncomfortable using technology. In addition, the paper explores the potential of\ntechnology in healthcare, including improving how easily patients can get care,\nthe quality of care they receive, and the cost of care. It also talks about how\ntechnology can help personalize care to individual patients. Finally, the paper\nsummarizes the main points, makes recommendations for healthcare providers and\npolicymakers, and suggests directions for future research. Overall, this review\nshows how technology can be used to improve healthcare, while also\nacknowledging the challenges that come with using technology in this way.",
          "arxiv_id": "2307.16296v3"
        },
        {
          "title": "Developing a Robust Computable Phenotype Definition Workflow to Describe Health and Disease in Observational Health Research",
          "year": "2023-03",
          "abstract": "Health informatics can inform decisions that practitioners, patients,\npolicymakers, and researchers need to make about health and disease. Health\ninformatics is built upon patient health data leading to the need to codify\npatient health information. Such standardization is required to compute\npopulation statistics (such as prevalence, incidence, etc.) that are common\nmetrics used in fields such as epidemiology. Reliable decision-making about\nhealth and disease rests on our ability to organize, analyze, and assess data\nrepositories that contain patient health data.\n  While standards exist to structure and analyze patient data across patient\ndata sources such as health information exchanges, clinical data repositories,\nand health data marketplaces, analogous best practices for rigorously defining\npatient populations in health informatics contexts do not exist. Codifying best\npractices for developing disease definitions could support the effective\ndevelopment of clinical guidelines, inform algorithms used in clinical decision\nsupport systems, and additional patient guidelines.\n  In this paper, we present a workflow for the development of phenotype\ndefinitions. This workflow presents a series of recommendations for defining\nhealth and disease. Various examples within this paper are presented to\ndemonstrate this workflow in health informatics contexts.",
          "arxiv_id": "2304.06504v1"
        },
        {
          "title": "Access to care improves EHR reliability and clinical risk prediction model performance",
          "year": "2024-12",
          "abstract": "Disparities in access to healthcare have been well-documented in the United\nStates, but their effects on electronic health record (EHR) data reliability\nand resulting clinical models are poorly understood. Using an All of Us dataset\nof 134,513 participants, we investigate the effects of access to care on the\nmedical machine learning pipeline, including medical condition rates, data\nquality, outcome label accuracy, and prediction performance. Our findings\nreveal that patients with cost constrained or delayed care have worse EHR\nreliability as measured by patient self-reported conditions for 78% of examined\nmedical conditions. We demonstrate in a prediction task of Type II diabetes\nincidence that clinical risk predictive performance can be worse for patients\nwithout standard care, with balanced accuracy gaps of 3.6 and sensitivity gaps\nof 9.4 percentage points for those with cost-constrained or delayed care. We\nevaluate solutions to mitigate these disparities and find that including\npatient self-reported conditions improved performance for patients with lower\naccess to care, with 11.2 percentage points higher sensitivity, effectively\ndecreasing the performance gap between standard versus delayed or\ncost-constrained care. These findings provide the first large-scale evidence\nthat healthcare access systematically affects both data reliability and\nclinical prediction performance. By revealing how access barriers propagate\nthrough the medical machine learning pipeline, our work suggests that improving\nmodel equity requires addressing both data collection biases and algorithmic\nlimitations. More broadly, this analysis provides an empirical foundation for\ndeveloping clinical prediction systems that work effectively for all patients,\nregardless of their access to care.",
          "arxiv_id": "2412.07712v2"
        }
      ],
      "7": [
        {
          "title": "'Cyber security is a dark art': The CISO as soothsayer",
          "year": "2022-02",
          "abstract": "Commercial organisations continue to face a growing and evolving threat of\ndata breaches and system compromises, making their cyber-security function\ncritically important. Many organisations employ a Chief Information Security\nOfficer (CISO) to lead such a function. We conducted in-depth, semi-structured\ninterviews with 15 CISOs and six senior organisational leaders, between October\n2019 and July 2020, as part of a wider exploration into the purpose of CISOs\nand cyber-security functions. In this paper, we employ broader security\nscholarship related to ontological security and sociological notions of\nidentity work to provide an interpretative analysis of the CISO role in\norganisations. Research findings reveal that cyber security is an expert system\nthat positions the CISO as an interpreter of something that is mystical,\nunknown and fearful to the uninitiated. They show how the fearful nature of\ncyber security contributes to it being considered an ontological threat by the\norganisation, while responding to that threat contributes to the organisation's\noverall identity. We further show how cyber security is analogous to a belief\nsystem and how one of the roles of the CISO is akin to that of a modern-day\nsoothsayer for senior management; that this role is precarious and, at the same\ntime, superior, leading to alienation within the organisation. Our study also\nhighlights that the CISO identity of protector-from-threat, linked to the\nprecarious position, motivates self-serving actions that we term `cyber\nsophistry'. We conclude by outlining a series of implications for both\norganisations and CISOs.",
          "arxiv_id": "2202.12755v1"
        },
        {
          "title": "A vision for global privacy bridges: Technical and legal measures for international data markets",
          "year": "2020-05",
          "abstract": "From the early days of the information economy, personal data has been its\nmost valuable asset. Despite data protection laws and an acknowledged right to\nprivacy, trading personal information has become a business equated with\n\"trading oil\". Most of this business is done without the knowledge and active\ninformed consent of the people. But as data breaches and abuses are made public\nthrough the media, consumers react. They become irritated about companies' data\nhandling practices, lose trust, exercise political pressure and start to\nprotect their privacy with the help of technical tools. As a result, companies'\nInternet business models that are based on personal data are unsettled. An open\nconflict is arising between business demands for data and a desire for privacy.\nAs of 2015 no true answer is in sight of how to resolve this conflict.\nTechnologists, economists and regulators are struggling to develop technical\nsolutions and policies that meet businesses' demand for more data while still\nmaintaining privacy. Yet, most of the proposed solutions fail to account for\nmarket complexity and provide no pathway to technological and legal\nimplementation. They lack a bigger vision for data use and privacy. To break\nthis vicious cycle, we propose and test such a vision of a personal information\nmarket with privacy. We accumulate technical and legal measures that have been\nproposed by technical and legal scholars over the past two decades. And out of\nthis existing knowledge, we compose something new: a four-space market model\nfor personal data.",
          "arxiv_id": "2005.06324v1"
        },
        {
          "title": "\"Nobody should control the end user\": Exploring Privacy Perspectives of Indian Internet Users in Light of DPDPA",
          "year": "2025-08",
          "abstract": "With the rapid increase in online interactions, concerns over data privacy\nand transparency of data processing practices have become more pronounced.\nWhile regulations like the GDPR have driven the widespread adoption of cookie\nbanners in the EU, India's Digital Personal Data Protection Act (DPDPA)\npromises similar changes domestically, aiming to introduce a framework for data\nprotection. However, certain clauses within the DPDPA raise concerns about\npotential infringements on user privacy, given the exemptions for government\naccountability and user consent requirements. In this study, for the first\ntime, we explore Indian Internet users' awareness and perceptions of cookie\nbanners, online privacy, and privacy regulations, especially in light of the\nnewly passed DPDPA. We conducted an online anonymous survey with 428 Indian\nparticipants, which addressed: (1) users' perspectives on cookie banners, (2)\ntheir attitudes towards online privacy and privacy regulations, and (3) their\nacceptance of 10 contentious DPDPA clauses that favor state authorities and may\nenable surveillance. Our findings reveal that privacy-conscious users often\nlack consistent awareness of privacy mechanisms, and their concerns do not\nalways lead to protective actions. Our thematic analysis of 143 open ended\nresponses shows that users' privacy and data protection concerns are rooted in\nskepticism towards the government, shaping their perceptions of the DPDPA and\nfueling demands for policy revisions. Our study highlights the need for clearer\ncommunication regarding the DPDPA, user-centric consent mechanisms, and policy\nrefinements to enhance data privacy practices in India.",
          "arxiv_id": "2508.17962v1"
        }
      ],
      "8": [
        {
          "title": "Protecting the Decentralized Future: An Exploration of Common Blockchain Attacks and their Countermeasures",
          "year": "2023-06",
          "abstract": "Blockchain technology transformed the digital sphere by providing a\ntransparent, secure, and decentralized platform for data security across a\nrange of industries, including cryptocurrencies and supply chain management.\nBlockchain's integrity and dependability have been jeopardized by the rising\nnumber of security threats, which have attracted cybercriminals as a target. By\nsummarizing suggested fixes, this research aims to offer a thorough analysis of\nmitigating blockchain attacks. The objectives of the paper include identifying\nweak blockchain attacks, evaluating various solutions, and determining how\neffective and effective they are at preventing these attacks. The study also\nhighlights how crucial it is to take into account the particular needs of every\nblockchain application. This study provides beneficial perspectives and\ninsights for blockchain researchers and practitioners, making it essential\nreading for those interested in current and future trends in blockchain\nsecurity research.",
          "arxiv_id": "2306.11884v1"
        },
        {
          "title": "The Societal Implications of Blockchain Technology in the Evolution of Humanity as a \"Superorganism\"",
          "year": "2024-12",
          "abstract": "This article examines the broader societal implications of blockchain\ntechnology and crypto-assets, emphasizing their role in the evolution of\nhumanity as a \"superorganism\" with decentralized, self-regulating systems.\nDrawing on interdisciplinary concepts such as Nate Hagens' \"superorganism\" idea\nand Francis Heylighen's \"global brain\" theory, the paper contextualizes\nblockchain technology within the ongoing evolution of governance systems and\nglobal systems such as the financial system. Blockchain's decentralized nature,\nin conjunction with advancements like artificial intelligence and decentralized\nautonomous organizations (DAOs), could transform traditional financial,\neconomic, and governance structures by enabling the emergence of collective\ndistributed decision-making and global coordination. In parallel, the article\naligns blockchain's impact with developmental theories such as Spiral Dynamics.\nThis framework is used to illustrate blockchain's potential to foster societal\ngrowth beyond hierarchical models, promoting a shift from centralized authority\nto collaborative and self-governed communities. The analysis provides a\nholistic view of blockchain as more than an economic tool, positioning it as a\ncatalyst for the evolution of society into a mature, interconnected global\nplanetary organism.",
          "arxiv_id": "2501.10378v1"
        },
        {
          "title": "An Overview of Forks and Coordination in Blockchain Development",
          "year": "2021-02",
          "abstract": "Blockchain is a continuously developing technology that has made digital\ntransactions and related computing operations more transparent and secure\nthrough globally distributed and decentralized management of states, as well as\nthe strong immutability of blocks mined and transactions validated in a network\nenabled by the blockchain technology. This manuscript is aimed at elaborating\nthe concept of blockchain technology alongside its coordination and\nimplementation with other emerging technologies, such as smart contract, which\nworks with different blockchain frameworks, as well as enabling anonymous\ntransactions and decentralized consensus amongst different untrusting parties.\nThe discussion of blockchain forks is also covered in this manuscript,\ndepicting fork events created in the blockchain process, their brief history,\ntypes, and impacts upon the blockchain development and operation.",
          "arxiv_id": "2102.10006v1"
        }
      ],
      "9": [
        {
          "title": "The Cultivated Practices of Text-to-Image Generation",
          "year": "2023-06",
          "abstract": "Humankind is entering a novel creative era in which anybody can synthesize\ndigital information using generative artificial intelligence (AI).\nText-to-image generation, in particular, has become vastly popular and millions\nof practitioners produce AI-generated images and AI art online. This chapter\nfirst gives an overview of the key developments that enabled a healthy\nco-creative online ecosystem around text-to-image generation to rapidly emerge,\nfollowed by a high-level description of key elements in this ecosystem. A\nparticular focus is placed on prompt engineering, a creative practice that has\nbeen embraced by the AI art community. It is then argued that the emerging\nco-creative ecosystem constitutes an intelligent system on its own - a system\nthat both supports human creativity, but also potentially entraps future\ngenerations and limits future development efforts in AI. The chapter discusses\nthe potential risks and dangers of cultivating this co-creative ecosystem, such\nas the bias inherent in today's training data, potential quality degradation in\nfuture image generation systems due to synthetic data becoming common place,\nand the potential long-term effects of text-to-image generation on people's\nimagination, ambitions, and development.",
          "arxiv_id": "2306.11393v3"
        },
        {
          "title": "Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art",
          "year": "2024-01",
          "abstract": "Generative AI tools are used to create art-like outputs and sometimes aid in\nthe creative process. These tools have potential benefits for artists, but they\nalso have the potential to harm the art workforce and infringe upon artistic\nand intellectual property rights. Without explicit consent from artists,\nGenerative AI creators scrape artists' digital work to train Generative AI\nmodels and produce art-like outputs at scale. These outputs are now being used\nto compete with human artists in the marketplace as well as being used by some\nartists in their generative processes to create art. We surveyed 459 artists to\ninvestigate the tension between artists' opinions on Generative AI art's\npotential utility and harm. This study surveys artists' opinions on the utility\nand threat of Generative AI art models, fair practices in the disclosure of\nartistic works in AI art training models, ownership and rights of AI art\nderivatives, and fair compensation. Results show that a majority of artists\nbelieve creators should disclose what art is being used in AI training, that AI\noutputs should not belong to model creators, and express concerns about AI's\nimpact on the art workforce and who profits from their art. We hope the results\nof this work will further meaningful collaboration and alignment between the\nart community and Generative AI researchers and developers.",
          "arxiv_id": "2401.15497v5"
        },
        {
          "title": "Constructing Dreams using Generative AI",
          "year": "2023-05",
          "abstract": "Generative AI tools introduce new and accessible forms of media creation for\nyouth. They also raise ethical concerns about the generation of fake media,\ndata protection, privacy and ownership of AI-generated art. Since generative AI\nis already being used in products used by youth, it is critical that they\nunderstand how these tools work and how they can be used or misused. In this\nwork, we facilitated students' generative AI learning through expression of\ntheir imagined future identities. We designed a learning workshop - Dreaming\nwith AI - where students learned about the inner workings of generative AI\ntools, used text-to-image generation algorithms to create their imaged future\ndreams, reflected on the potential benefits and harms of generative AI tools\nand voiced their opinions about policies for the use of these tools in\nclassrooms. In this paper, we present the learning activities and experiences\nof 34 high school students who engaged in our workshops. Students reached\ncreative learning objectives by using prompt engineering to create their future\ndreams, gained technical knowledge by learning the abilities, limitations,\ntext-visual mappings and applications of generative AI, and identified most\npotential societal benefits and harms of generative AI.",
          "arxiv_id": "2305.12013v1"
        }
      ],
      "10": [
        {
          "title": "Chasing Carbon: The Elusive Environmental Footprint of Computing",
          "year": "2020-10",
          "abstract": "Given recent algorithm, software, and hardware innovation, computing has\nenabled a plethora of new applications. As computing becomes increasingly\nubiquitous, however, so does its environmental impact. This paper brings the\nissue to the attention of computer-systems researchers. Our analysis, built on\nindustry-reported characterization, quantifies the environmental effects of\ncomputing in terms of carbon emissions. Broadly, carbon emissions have two\nsources: operational energy consumption, and hardware manufacturing and\ninfrastructure. Although carbon emissions from the former are decreasing thanks\nto algorithmic, software, and hardware innovations that boost performance and\npower efficiency, the overall carbon footprint of computer systems continues to\ngrow. This work quantifies the carbon output of computer systems to show that\nmost emissions related to modern mobile and data-center equipment come from\nhardware manufacturing and infrastructure. We therefore outline future\ndirections for minimizing the environmental impact of computing systems.",
          "arxiv_id": "2011.02839v1"
        },
        {
          "title": "The Sunk Carbon Fallacy: Rethinking Carbon Footprint Metrics for Effective Carbon-Aware Scheduling",
          "year": "2024-10",
          "abstract": "The rapid increase in computing demand and its corresponding energy\nconsumption have focused attention on computing's impact on the climate and\nsustainability. Prior work proposes metrics that quantify computing's carbon\nfootprint across several lifecycle phases, including its supply chain,\noperation, and end-of-life. Industry uses these metrics to optimize the carbon\nfootprint of manufacturing hardware and running computing applications.\nUnfortunately, prior work on optimizing datacenters' carbon footprint often\nsuccumbs to the \\emph{sunk cost fallacy} by considering embodied carbon\nemissions (a sunk cost) when making operational decisions (i.e., job scheduling\nand placement), which leads to operational decisions that do not always reduce\nthe total carbon footprint.\n  In this paper, we evaluate carbon-aware job scheduling and placement on a\ngiven set of servers for a number of carbon accounting metrics. Our analysis\nreveals state-of-the-art carbon accounting metrics that include embodied carbon\nemissions when making operational decisions can actually increase the total\ncarbon footprint of executing a set of jobs. We study the factors that affect\nthe added carbon cost of such suboptimal decision-making. We then use a\nreal-world case study from a datacenter to demonstrate how the sunk carbon\nfallacy manifests itself in practice. Finally, we discuss the implications of\nour findings in better guiding effective carbon-aware scheduling in on-premise\nand cloud datacenters.",
          "arxiv_id": "2410.15087v1"
        },
        {
          "title": "Towards a Systematic Survey for Carbon Neutral Data Centers",
          "year": "2021-10",
          "abstract": "Data centers are carbon-intensive enterprises due to their massive energy\nconsumption, and it is estimated that data center industry will account for 8\\%\nof global carbon emissions by 2030. However, both technological and policy\ninstruments for reducing or even neutralizing data center carbon emissions have\nnot been thoroughly investigated. To bridge this gap, this survey paper\nproposes a roadmap towards carbon-neutral data centers that takes into account\nboth policy instruments and technological methodologies. We begin by presenting\nthe carbon footprint of data centers, as well as some insights into the major\nsources of carbon emissions. Following that, carbon neutrality plans for major\nglobal cloud providers are discussed to summarize current industrial efforts in\nthis direction. In what follows, we introduce the carbon market as a policy\ninstrument to explain how to offset data center carbon emissions in a\ncost-efficient manner. On the technological front, we propose achieving\ncarbon-neutral data centers by increasing renewable energy penetration,\nimproving energy efficiency, and boosting energy circulation simultaneously. A\ncomprehensive review of existing technologies on these three topics is\nelaborated subsequently. Based on this, a multi-pronged approach towards carbon\nneutrality is envisioned and a digital twin-powered industrial artificial\nintelligence (AI) framework is proposed to make this solution a reality.\nFurthermore, three key scientific challenges for putting such a framework in\nplace are discussed. Finally, several applications for this framework are\npresented to demonstrate its enormous potential.",
          "arxiv_id": "2110.09284v3"
        }
      ],
      "11": [
        {
          "title": "Benefits and Harms of Large Language Models in Digital Mental Health",
          "year": "2023-11",
          "abstract": "The past decade has been transformative for mental health research and\npractice. The ability to harness large repositories of data, whether from\nelectronic health records (EHR), mobile devices, or social media, has revealed\na potential for valuable insights into patient experiences, promising early,\nproactive interventions, as well as personalized treatment plans. Recent\ndevelopments in generative artificial intelligence, particularly large language\nmodels (LLMs), show promise in leading digital mental health to uncharted\nterritory. Patients are arriving at doctors' appointments with information\nsourced from chatbots, state-of-the-art LLMs are being incorporated in medical\nsoftware and EHR systems, and chatbots from an ever-increasing number of\nstartups promise to serve as AI companions, friends, and partners. This article\npresents contemporary perspectives on the opportunities and risks posed by LLMs\nin the design, development, and implementation of digital mental health tools.\nWe adopt an ecological framework and draw on the affordances offered by LLMs to\ndiscuss four application areas -- care-seeking behaviors from individuals in\nneed of care, community care provision, institutional and medical care\nprovision, and larger care ecologies at the societal level. We engage in a\nthoughtful consideration of whether and how LLM-based technologies could or\nshould be employed for enhancing mental health. The benefits and harms our\narticle surfaces could serve to help shape future research, advocacy, and\nregulatory efforts focused on creating more responsible, user-friendly,\nequitable, and secure LLM-based tools for mental health treatment and\nintervention.",
          "arxiv_id": "2311.14693v1"
        },
        {
          "title": "Risks from Language Models for Automated Mental Healthcare: Ethics and Structure for Implementation",
          "year": "2024-04",
          "abstract": "Amidst the growing interest in developing task-autonomous AI for automated\nmental health care, this paper addresses the ethical and practical challenges\nassociated with the issue and proposes a structured framework that delineates\nlevels of autonomy, outlines ethical requirements, and defines beneficial\ndefault behaviors for AI agents in the context of mental health support. We\nalso evaluate fourteen state-of-the-art language models (ten off-the-shelf,\nfour fine-tuned) using 16 mental health-related questionnaires designed to\nreflect various mental health conditions, such as psychosis, mania, depression,\nsuicidal thoughts, and homicidal tendencies. The questionnaire design and\nresponse evaluations were conducted by mental health clinicians (M.D.s). We\nfind that existing language models are insufficient to match the standard\nprovided by human professionals who can navigate nuances and appreciate\ncontext. This is due to a range of issues, including overly cautious or\nsycophantic responses and the absence of necessary safeguards. Alarmingly, we\nfind that most of the tested models could cause harm if accessed in mental\nhealth emergencies, failing to protect users and potentially exacerbating\nexisting symptoms. We explore solutions to enhance the safety of current\nmodels. Before the release of increasingly task-autonomous AI systems in mental\nhealth, it is crucial to ensure that these models can reliably detect and\nmanage symptoms of common psychiatric disorders to prevent harm to users. This\ninvolves aligning with the ethical framework and default behaviors outlined in\nour study. We contend that model developers are responsible for refining their\nsystems per these guidelines to safeguard against the risks posed by current AI\ntechnologies to user mental health and safety.\n  Trigger warning: Contains and discusses examples of sensitive mental health\ntopics, including suicide and self-harm.",
          "arxiv_id": "2406.11852v2"
        },
        {
          "title": "Harnessing Large Language Models for Mental Health: Opportunities, Challenges, and Ethical Considerations",
          "year": "2024-12",
          "abstract": "Large Language Models (LLMs) are transforming mental health care by enhancing\naccessibility, personalization, and efficiency in therapeutic interventions.\nThese AI-driven tools empower mental health professionals with real-time\nsupport, improved data integration, and the ability to encourage care-seeking\nbehaviors, particularly in underserved communities. By harnessing LLMs,\npractitioners can deliver more empathetic, tailored, and effective support,\naddressing longstanding gaps in mental health service provision. However, their\nimplementation comes with significant challenges and ethical concerns.\nPerformance limitations, data privacy risks, biased outputs, and the potential\nfor generating misleading information underscore the critical need for\nstringent ethical guidelines and robust evaluation mechanisms. The sensitive\nnature of mental health data further necessitates meticulous safeguards to\nprotect patient rights and ensure equitable access to AI-driven care.\nProponents argue that LLMs have the potential to democratize mental health\nresources, while critics warn of risks such as misuse and the diminishment of\nhuman connection in therapy. Achieving a balance between innovation and ethical\nresponsibility is imperative. This paper examines the transformative potential\nof LLMs in mental health care, highlights the associated technical and ethical\ncomplexities, and advocates for a collaborative, multidisciplinary approach to\nensure these advancements align with the goal of providing compassionate,\nequitable, and effective mental health support.",
          "arxiv_id": "2501.10370v1"
        }
      ],
      "12": [
        {
          "title": "Machine Learning on the COVID-19 Pandemic, Human Mobility and Air Quality: A Review",
          "year": "2021-03",
          "abstract": "The ongoing COVID-19 global pandemic is affecting every facet of human lives\n(e.g., public health, education, economy, transportation, and the environment).\nThis novel pandemic and citywide implemented lockdown measures are affecting\nvirus transmission, people's travel patterns, and air quality. Many studies\nhave been conducted to predict the COVID-19 diffusion, assess the impacts of\nthe pandemic on human mobility and air quality, and assess the impacts of\nlockdown measures on viral spread with a range of Machine Learning (ML)\ntechniques. This review study aims to analyze results from past research to\nunderstand the interactions among the COVID-19 pandemic, lockdown measures,\nhuman mobility, and air quality. The critical review of prior studies indicates\nthat urban form, people's socioeconomic and physical conditions, social\ncohesion, and social distancing measures significantly affect human mobility\nand COVID-19 transmission. during the COVID-19 pandemic, many people are\ninclined to use private transportation for necessary travel purposes to\nmitigate coronavirus-related health problems. This review study also noticed\nthat COVID-19 related lockdown measures significantly improve air quality by\nreducing the concentration of air pollutants, which in turn improves the\nCOVID-19 situation by reducing respiratory-related sickness and deaths of\npeople. It is argued that ML is a powerful, effective, and robust analytic\nparadigm to handle complex and wicked problems such as a global pandemic. This\nstudy also discusses policy implications, which will be helpful for\npolicymakers to take prompt actions to moderate the severity of the pandemic\nand improve urban environments by adopting data-driven analytic methods.",
          "arxiv_id": "2104.04059v1"
        },
        {
          "title": "Deep Learning Approach to Forecasting COVID-19 Cases in Residential Buildings of Hong Kong Public Housing Estates: The Role of Environment and Sociodemographics",
          "year": "2024-03",
          "abstract": "Introduction: The current study investigates the complex association between\nCOVID-19 and the studied districts' socioecology (e.g. internal and external\nbuilt environment, sociodemographic profiles, etc.) to quantify their\ncontributions to the early outbreaks and epidemic resurgence of COVID-19.\nMethods: We aligned the analytic model's architecture with the hierarchical\nstructure of the resident's socioecology using a multi-headed hierarchical\nconvolutional neural network to structure the vast array of hierarchically\nrelated predictive features representing buildings' internal and external built\nenvironments and residents' sociodemographic profiles as model input. COVID-19\ncases accumulated in buildings across three adjacent districts in HK, both\nbefore and during HK's epidemic resurgence, were modeled. A forward-chaining\nvalidation was performed to examine the model's performance in forecasting\nCOVID-19 cases over the 3-, 7-, and 14-day horizons during the two months\nsubsequent to when the model for COVID-19 resurgence was built to align with\nthe forecasting needs in an evolving pandemic. Results: Different sets of\nfactors were found to be linked to the earlier waves of COVID-19 outbreaks\ncompared to the epidemic resurgence of the pandemic. Sociodemographic factors\nsuch as work hours, monthly household income, employment types, and the number\nof non-working adults or children in household populations were of high\nimportance to the studied buildings' COVID-19 case counts during the early\nwaves of COVID-19. Factors constituting one's internal built environment, such\nas the number of distinct households in the buildings, the number of distinct\nhouseholds per floor, and the number of floors, corridors, and lifts, had the\ngreatest unique contributions to the building-level COVID-19 case counts during\nepidemic resurgence.",
          "arxiv_id": "2403.15759v1"
        },
        {
          "title": "COVID-19 Pandemic Outbreak in the Subcontinent: A data-driven analysis",
          "year": "2020-08",
          "abstract": "Human civilization is experiencing a critical situation that presents itself\nfor a new coronavirus disease 2019 (COVID-19). This virus emerged in late\nDecember 2019 in Wuhan city, Hubei, China. The grim fact of COVID-19 is, it is\nhighly contagious in nature, therefore, spreads rapidly all over the world and\ncauses severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Responding\nto the severity of COVID-19 research community directs the attention to the\nanalysis of COVID-19, to diminish its antagonistic impact towards society.\nNumerous studies claim that the subcontinent, i.e., Bangladesh, India, and\nPakistan, could remain in the worst affected region by the COVID-19. In order\nto prevent the spread of COVID-19, it is important to predict the trend of\nCOVID-19 beforehand the planning of effective control strategies.\nFundamentally, the idea is to dependably estimate the reproduction number to\njudge the spread rate of COVID-19 in a particular region. Consequently, this\npaper uses publicly available epidemiological data of Bangladesh, India, and\nPakistan to estimate the reproduction numbers. More specifically, we use\nvarious models (for example, susceptible infection recovery (SIR), exponential\ngrowth (EG), sequential Bayesian (SB), maximum likelihood (ML) and time\ndependent (TD)) to estimate the reproduction numbers and observe the model\nfitness in the corresponding data set. Experimental results show that the\nreproduction numbers produced by these models are greater than 1.2\n(approximately) indicates that COVID-19 is gradually spreading in the\nsubcontinent.",
          "arxiv_id": "2008.09803v1"
        }
      ],
      "13": [
        {
          "title": "Technological impact of biomedical research: the role of basicness and novelty",
          "year": "2020-06",
          "abstract": "An ongoing interest in innovation studies is to understand how knowledge\ngenerated from scientific research can be used in the development of\ntechnologies. While previous inquiries have devoted to studying the scientific\ncapacity of technologies and institutional factors facilitating technology\ntransfer, little is known about the intrinsic characteristics of scientific\npublications that gain direct technological impact. Here we focus on two\nfeatures, namely basicness and novelty. Using a corpus of 3.8 million papers\npublished between 1980 and 1999, we find that basic science papers and novel\npapers are substantially more likely to achieve direct technological impact.\nFurther analysis that limits to papers with technological impact reveals that\nbasic science and novel science have more patent citations, experience shorter\ntime lag, and have impact in broader technological fields.",
          "arxiv_id": "2006.02472v1"
        },
        {
          "title": "Interdisciplinary research and technological impact: Evidence from biomedicine",
          "year": "2020-06",
          "abstract": "Interdisciplinary research (IDR) has been considered as an important source\nfor scientific breakthroughs and as a solution to today's complex societal\nchallenges. While ample empirical evidence has suggested its benefits within\nthe academia such as better creativity and higher scientific impact and\nvisibility, its societal benefits -- a key argument originally used for\npromoting IDR -- remain relatively unexplored. Here, we study one aspect of\nsocietal benefits, that is contributing to the development of patented\ntechnologies, and examine how IDR papers are referenced as \"prior art\" by\npatents over time. We draw on a large sample of biomedical papers published in\n23 years and measure the degree of interdisciplinarity of a paper using three\npopular indicators, namely variety, balance, and disparity. We find that papers\nthat cites more fields (variety) and whose distributions over those cited\nfields are more even (balance) are more likely to receive patent citations, but\nboth effects can be offset if papers draw upon more distant fields (disparity).\nThese associations are consistent across different citation-window lengths. We\nfurther find that conditional on receiving patent citations, the intensity of\ntheir technological impact, as measured as both raw and quality-adjusted number\nof citing patents, increases with balance and disparity. Our work may have\npolicy implications for interdisciplinary research and scientific and\ntechnological impact.",
          "arxiv_id": "2006.15383v3"
        },
        {
          "title": "Diversity of Expertise is Key to Scientific Impact: a Large-Scale Analysis in the Field of Computer Science",
          "year": "2023-06",
          "abstract": "Understanding the relationship between the composition of a research team and\nthe potential impact of their research papers is crucial as it can steer the\ndevelopment of new science policies for improving the research enterprise.\nNumerous studies assess how the characteristics and diversity of research teams\ncan influence their performance across several dimensions: ethnicity,\ninternationality, size, and others. In this paper, we explore the impact of\ndiversity in terms of the authors' expertise. To this purpose, we retrieved\n114K papers in the field of Computer Science and analysed how the diversity of\nresearch fields within a research team relates to the number of citations their\npapers received in the upcoming 5 years. The results show that two different\nmetrics we defined, reflecting the diversity of expertise, are significantly\nassociated with the number of citations. This suggests that, at least in\nComputer Science, diversity of expertise is key to scientific impact.",
          "arxiv_id": "2306.15344v2"
        }
      ],
      "14": [
        {
          "title": "How mass surveillance can crowd out installations of COVID-19 contact tracing apps",
          "year": "2021-10",
          "abstract": "During the COVID-19 pandemic, many countries have developed and deployed\ncontact tracing technologies to curb the spread of the disease by locating and\nisolating people who have been in contact with coronavirus carriers.\nSubsequently, understanding why people install and use contact tracing apps is\nbecoming central to their effectiveness and impact. This paper analyzes\nsituations where centralized mass surveillance technologies are deployed\nsimultaneously with a voluntary contact tracing mobile app. We use this\nparallel deployment as a natural experiment that tests how attitudes toward\nmass deployments affect people's installation of the contact tracing app. Based\non a representative survey of Israelis (n=519), our findings show that positive\nattitudes toward mass surveillance were related to a reduced likelihood of\ninstalling contact tracing apps and an increased likelihood of uninstalling\nthem. These results also hold when controlling for privacy concerns about the\ncontact tracing app, attitudes toward the app, trust in authorities, and\ndemographic properties. Similar reasoning may also be relevant for crowding out\nvoluntary participation in data collection systems.",
          "arxiv_id": "2110.01567v1"
        },
        {
          "title": "How Reliable is Smartphone-based Electronic Contact Tracing for COVID-19?",
          "year": "2020-05",
          "abstract": "Smartphone-based electronic contact tracing is currently considered an\nessential tool towards easing lockdowns, curfews, and shelter-in-place orders\nissued by most governments around the world in response to the 2020 novel\ncoronavirus (SARS-CoV-2) crisis. While the focus on developing smartphone-based\ncontact tracing applications or apps has been on privacy concerns stemming from\nthe use of such apps, an important question that has not received sufficient\nattention is: How reliable will such smartphone-based electronic contact\ntracing be?\n  This is a technical question related to how two smartphones reliably register\ntheir mutual proximity. Here, we examine in detail the technical prerequisites\nrequired for effective smartphone-based contact tracing. The underlying\nmechanism that any contact tracing app relies on is called Neighbor Discovery\n(ND), which involves smartphones transmitting and scanning for Bluetooth\nsignals to record their mutual presence whenever they are in close proximity.\nThe hardware support and the software protocols used for ND in smartphones,\nhowever, were not designed for reliable contact tracing. In this paper, we\nquantitatively evaluate how reliably can smartphones do contact tracing. Our\nresults point towards the design of a wearable solution for contact tracing\nthat can overcome the shortcomings of a smartphone-based solution to provide\nmore reliable and accurate contact tracing. To the best of our knowledge, this\nis the first study that quantifies, both, the suitability and also the\ndrawbacks of smartphone-based contact tracing. Further, our results can be used\nto parameterize a ND protocol to maximize the reliability of any contact\ntracing app that uses it.",
          "arxiv_id": "2005.05625v2"
        },
        {
          "title": "A Note on Cryptographic Algorithms for Private Data Analysis in Contact Tracing Applications",
          "year": "2020-05",
          "abstract": "Contact tracing is an important measure to counter the COVID-19 pandemic. In\nthe early phase, many countries employed manual contact tracing to contain the\nrate of disease spread, however it has many issues. The manual approach is\ncumbersome, time consuming and also requires active participation of a large\nnumber of people to realize it. In order to overcome these drawbacks, digital\ncontact tracing has been proposed that typically involves deploying a contact\ntracing application on people's mobile devices which can track their movements\nand close social interactions. While studies suggest that digital contact\ntracing is more effective than manual contact tracing, it has been observed\nthat higher adoption rates of the contact tracing app may result in a better\ncontrolled epidemic. This also increases the confidence in the accuracy of the\ncollected data and the subsequent analytics. One key reason for low adoption\nrate of contact tracing applications is the concern about individual privacy.\nIn fact, several studies report that contact tracing applications deployed in\nmultiple countries are not privacy friendly and have potential to be used for\nmass surveillance by the concerned governments. Hence, privacy respecting\ncontact tracing application is the need of the hour that can lead to highly\neffective, efficient contact tracing. As part of this study, we focus on\nvarious cryptographic techniques that can help in addressing the Private Set\nIntersection problem which lies at the heart of privacy respecting contact\ntracing. We analyze the computation and communication complexities of these\ntechniques under the typical client-server architecture utilized by contact\ntracing applications. Further we evaluate those computation and communication\ncomplexity expressions for India scenario and thus identify cryptographic\ntechniques that can be more suitably deployed there.",
          "arxiv_id": "2005.10634v1"
        }
      ],
      "15": [
        {
          "title": "Validation of the Virtual Reality Neuroscience Questionnaire: Maximum Duration of Immersive Virtual Reality Sessions Without the Presence of Pertinent Adverse Symptomatology",
          "year": "2021-01",
          "abstract": "Research suggests that the duration of a VR session modulates the presence\nand intensity of VRISE, but there are no suggestions regarding the appropriate\nmaximum duration of VR sessions. The implementation of high-end VR HMDs in\nconjunction with ergonomic VR software seems to mitigate the presence of VRISE\nsubstantially. However, a brief tool does not currently exist to appraise and\nreport both the quality of software features and VRISE intensity\nquantitatively. The VRNQ was developed to assess the quality of VR software in\nterms of user experience, game mechanics, in-game assistance, and VRISE. Forty\nparticipants aged between 28 and 43 years were recruited (18 gamers and 22\nnon-gamers) for the study. They participated in 3 different VR sessions until\nthey felt weary or discomfort and subsequently filled in the VRNQ. Our results\ndemonstrated that VRNQ is a valid tool for assessing VR software as it has good\nconvergent, discriminant, and construct validity. The maximum duration of VR\nsessions should be between 55-70 minutes when the VR software meets or exceeds\nthe parsimonious cut-offs of the VRNQ and the users are familiarized with the\nVR system. Also. the gaming experience does not seem to affect how long VR\nsessions should last. Also, while the quality of VR software substantially\nmodulates the maximum duration of VR sessions, age and education do not.\nFinally, deeper immersion, better quality of graphics and sound, and more\nhelpful in-game instructions and prompts were found to reduce VRISE intensity.\nThe VRNQ facilitates the brief assessment and reporting of the quality of VR\nsoftware features and/or the intensity of VRISE, while its minimum and\nparsimonious cut-offs may appraise the suitability of VR software. The findings\nof this study contribute to the establishment of rigorous VR methods that are\ncrucial for the viability of immersive VR as a research and clinical tool.",
          "arxiv_id": "2101.08146v1"
        },
        {
          "title": "Wireless Edge-Empowered Metaverse: A Learning-Based Incentive Mechanism for Virtual Reality",
          "year": "2021-11",
          "abstract": "The Metaverse is regarded as the next-generation Internet paradigm that\nallows humans to play, work, and socialize in an alternative virtual world with\nimmersive experience, for instance, via head-mounted display for Virtual\nReality (VR) rendering. With the help of ubiquitous wireless connections and\npowerful edge computing technologies, VR users in wireless edge-empowered\nMetaverse can immerse in the virtual through the access of VR services offered\nby different providers. However, VR applications are computation- and\ncommunication-intensive. The VR service providers (SPs) have to optimize the VR\nservice delivery efficiently and economically given their limited communication\nand computation resources. An incentive mechanism can be thus applied as an\neffective tool for managing VR services between providers and users. Therefore,\nin this paper, we propose a learning-based Incentive Mechanism framework for VR\nservices in the Metaverse. First, we propose the quality of perception as the\nmetric for VR users immersing in the virtual world. Second, for quick trading\nof VR services between VR users (i.e., buyers) and VR SPs (i.e., sellers), we\ndesign a double Dutch auction mechanism to determine optimal pricing and\nallocation rules in this market. Third, for auction communication reduction, we\ndesign a deep reinforcement learning-based auctioneer to accelerate this\nauction process. Experimental results demonstrate that the proposed framework\ncan achieve near-optimal social welfare while reducing at least half of the\nauction information exchange cost than baseline methods.",
          "arxiv_id": "2111.03776v1"
        },
        {
          "title": "Guidelines for the Development of Immersive Virtual Reality Software for Cognitive Neuroscience and Neuropsychology: The Development of Virtual Reality Everyday Assessment Lab (VR-EAL)",
          "year": "2021-01",
          "abstract": "Virtual reality (VR) head-mounted displays (HMD) appear to be effective\nresearch tools, which may address the problem of ecological validity in\nneuropsychological testing. However, their widespread implementation is\nhindered by VR induced symptoms and effects (VRISE) and the lack of skills in\nVR software development. This study offers guidelines for the development of VR\nsoftware in cognitive neuroscience and neuropsychology, by describing and\ndiscussing the stages of the development of Virtual Reality Everyday Assessment\nLab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques\nfor evaluating cognitive functions within a realistic storyline are discussed.\nThe utility of various assets in Unity, software development kits, and other\nsoftware are described so that cognitive scientists can overcome challenges\npertinent to VRISE and the quality of the VR software. In addition, this pilot\nstudy attempts to evaluate VR-EAL in accordance with the necessary criteria for\nVR software for research purposes. The VR neuroscience questionnaire (VRNQ;\nKourtesis et al., 2019b) was implemented to appraise the quality of the three\nversions of VR-EAL in terms of user experience, game mechanics, in-game\nassistance, and VRISE. Twenty-five participants aged between 20 and 45 years\nwith 12-16 years of full-time education evaluated various versions of VR-EAL.\nThe final version of VR-EAL achieved high scores in every sub-score of the VRNQ\nand exceeded its parsimonious cut-offs. It also appeared to have better in-game\nassistance and game mechanics, while its improved graphics substantially\nincreased the quality of the user experience and almost eradicated VRISE. The\nresults substantially support the feasibility of the development of effective\nVR research and clinical software without the presence of VRISE during a\n60-minute VR session.",
          "arxiv_id": "2101.08166v1"
        }
      ],
      "16": [
        {
          "title": "Constructing dynamic residential energy lifestyles using Latent Dirichlet Allocation",
          "year": "2022-04",
          "abstract": "The rapid expansion of Advanced Meter Infrastructure (AMI) has dramatically\naltered the energy information landscape. However, our ability to use this\ninformation to generate actionable insights about residential electricity\ndemand remains limited. In this research, we propose and test a new framework\nfor understanding residential electricity demand by using a dynamic energy\nlifestyles approach that is iterative and highly extensible. To obtain energy\nlifestyles, we develop a novel approach that applies Latent Dirichlet\nAllocation (LDA), a method commonly used for inferring the latent topical\nstructure of text data, to extract a series of latent household energy\nattributes. By doing so, we provide a new perspective on household electricity\nconsumption where each household is characterized by a mixture of energy\nattributes that form the building blocks for identifying a sparse collection of\nenergy lifestyles. We examine this approach by running experiments on one year\nof hourly smart meter data from 60,000 households and we extract six energy\nattributes that describe general daily use patterns. We then use clustering\ntechniques to derive six distinct energy lifestyle profiles from energy\nattribute proportions. Our lifestyle approach is also flexible to varying time\ninterval lengths, and we test our lifestyle approach seasonally (Autumn,\nWinter, Spring, and Summer) to track energy lifestyle dynamics within and\nacross households and find that around 73% of households manifest multiple\nlifestyles across a year. These energy lifestyles are then compared to\ndifferent energy use characteristics, and we discuss their practical\napplications for demand response program design and lifestyle change analysis.",
          "arxiv_id": "2204.10770v1"
        },
        {
          "title": "Energy personas in Danish households",
          "year": "2025-05",
          "abstract": "Technologies to monitor the provision of renewable energy are part of\nemerging technologies to help address the discrepancy between renewable energy\nproduction and its related usage in households. This paper presents various\nways householders use a technological artifact for the real-time monitoring of\nrenewable energy provision. Such a monitoring thus affords householders with an\nopportunity to adjust their energy consumption according to renewable energy\nprovision. In Denmark, Ewii, previously Barry, is a Danish energy supplier\nwhich provides householders with an opportunity to monitor energy sources in\nreal time through a technological solution of the same name. This paper use\nprovision afforded by Ewii as a case for exploring how householders organize\nthemselves to use a technological artefact that supports the monitoring of\nenergy and its related usage. This study aims to inform technology design\nthrough the derivation of four personas. The derived personas highlight the\ndifferences in energy monitoring practices for the householders and their\nengagement. These personas are characterised as dedicated, organised, sporadic,\nand convenient. Understanding these differences in energy monitoring practice\nusing the technological artefact form a solid element in the design of future\nenergy technologies that interfere with the everyday practices and energy\nconsumption for households. This is paramount for future energy related\ntechnology design, and for the clarification of usage assumptions that are\nembedded in the rollout of energy related technology as a country such as\nDenmark moves through its green transition.",
          "arxiv_id": "2505.07408v1"
        },
        {
          "title": "An Extensive and Methodical Review of Smart Grids for Sustainable Energy Management-Addressing Challenges with AI, Renewable Energy Integration and Leading-edge Technologies",
          "year": "2025-01",
          "abstract": "Energy management decreases energy expenditures and consumption while\nsimultaneously increasing energy efficiency, reducing carbon emissions, and\nenhancing operational performance. Smart grids are a type of sophisticated\nenergy infrastructure that increase the generation and distribution of\nelectricity's sustainability, dependability, and efficiency by utilizing\ndigital communication technologies. They combine a number of cutting-edge\ntechniques and technology to improve energy resource management. A large amount\nof research study on the topic of smart grids for energy management has been\ncompleted in the last several years. The authors of the present study want to\ncover a number of topics, including smart grid benefits and components,\ntechnical developments, integrating renewable energy sources, using artificial\nintelligence and data analytics, cybersecurity, and privacy. Smart Grids for\nEnergy Management are an innovative field of study aiming at tackling various\ndifficulties and magnifying the efficiency, dependability, and sustainability\nof energy systems, including: 1) Renewable sources of power like solar and wind\nare intermittent and unpredictable 2) Defending smart grid system from various\ncyber-attacks 3) Incorporating an increasing number of electric vehicles into\nthe system of power grid without overwhelming it. Additionally, it is proposed\nto use AI and data analytics for better performance on the grid, reliability,\nand energy management. It also looks into how AI and data analytics can be used\nto optimize grid performance, enhance reliability, and improve energy\nmanagement. The authors will explore these significant challenges and ongoing\nresearch. Lastly, significant issues in this field are noted, and\nrecommendations for further work are provided.",
          "arxiv_id": "2501.14143v1"
        }
      ],
      "17": [
        {
          "title": "PreFair: Privately Generating Justifiably Fair Synthetic Data",
          "year": "2022-12",
          "abstract": "When a database is protected by Differential Privacy (DP), its usability is\nlimited in scope. In this scenario, generating a synthetic version of the data\nthat mimics the properties of the private data allows users to perform any\noperation on the synthetic data, while maintaining the privacy of the original\ndata. Therefore, multiple works have been devoted to devising systems for DP\nsynthetic data generation. However, such systems may preserve or even magnify\nproperties of the data that make it unfair, endering the synthetic data unfit\nfor use. In this work, we present PreFair, a system that allows for DP fair\nsynthetic data generation. PreFair extends the state-of-the-art DP data\ngeneration mechanisms by incorporating a causal fairness criterion that ensures\nfair synthetic data. We adapt the notion of justifiable fairness to fit the\nsynthetic data generation scenario. We further study the problem of generating\nDP fair synthetic data, showing its intractability and designing algorithms\nthat are optimal under certain assumptions. We also provide an extensive\nexperimental evaluation, showing that PreFair generates synthetic data that is\nsignificantly fairer than the data generated by leading DP data generation\nmechanisms, while remaining faithful to the private data.",
          "arxiv_id": "2212.10310v2"
        },
        {
          "title": "Personalized Differential Privacy for Ridge Regression",
          "year": "2024-01",
          "abstract": "The increased application of machine learning (ML) in sensitive domains\nrequires protecting the training data through privacy frameworks, such as\ndifferential privacy (DP). DP requires to specify a uniform privacy level\n$\\varepsilon$ that expresses the maximum privacy loss that each data point in\nthe entire dataset is willing to tolerate. Yet, in practice, different data\npoints often have different privacy requirements. Having to set one uniform\nprivacy level is usually too restrictive, often forcing a learner to guarantee\nthe stringent privacy requirement, at a large cost to accuracy. To overcome\nthis limitation, we introduce our novel Personalized-DP Output Perturbation\nmethod (PDP-OP) that enables to train Ridge regression models with individual\nper data point privacy levels. We provide rigorous privacy proofs for our\nPDP-OP as well as accuracy guarantees for the resulting model. This work is the\nfirst to provide such theoretical accuracy guarantees when it comes to\npersonalized DP in machine learning, whereas previous work only provided\nempirical evaluations. We empirically evaluate PDP-OP on synthetic and real\ndatasets and with diverse privacy distributions. We show that by enabling each\ndata point to specify their own privacy requirement, we can significantly\nimprove the privacy-accuracy trade-offs in DP. We also show that PDP-OP\noutperforms the personalized privacy techniques of Jorgensen et al. (2015).",
          "arxiv_id": "2401.17127v1"
        },
        {
          "title": "Aim High, Stay Private: Differentially Private Synthetic Data Enables Public Release of Behavioral Health Information with High Utility",
          "year": "2025-06",
          "abstract": "Sharing health and behavioral data raises significant privacy concerns, as\nconventional de-identification methods are susceptible to privacy attacks.\nDifferential Privacy (DP) provides formal guarantees against re-identification\nrisks, but practical implementation necessitates balancing privacy protection\nand the utility of data.\n  We demonstrate the use of DP to protect individuals in a real behavioral\nhealth study, while making the data publicly available and retaining high\nutility for downstream users of the data. We use the Adaptive Iterative\nMechanism (AIM) to generate DP synthetic data for Phase 1 of the Lived\nExperiences Measured Using Rings Study (LEMURS). The LEMURS dataset comprises\nphysiological measurements from wearable devices (Oura rings) and self-reported\nsurvey data from first-year college students. We evaluate the synthetic\ndatasets across a range of privacy budgets, epsilon = 1 to 100, focusing on the\ntrade-off between privacy and utility.\n  We evaluate the utility of the synthetic data using a framework informed by\nactual uses of the LEMURS dataset. Our evaluation identifies the trade-off\nbetween privacy and utility across synthetic datasets generated with different\nprivacy budgets. We find that synthetic data sets with epsilon = 5 preserve\nadequate predictive utility while significantly mitigating privacy risks. Our\nmethodology establishes a reproducible framework for evaluating the practical\nimpacts of epsilon on generating private synthetic datasets with numerous\nattributes and records, contributing to informed decision-making in data\nsharing practices.",
          "arxiv_id": "2507.02971v1"
        }
      ],
      "18": [
        {
          "title": "Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era",
          "year": "2024-03",
          "abstract": "Explainable AI (XAI) refers to techniques that provide human-understandable\ninsights into the workings of AI models. Recently, the focus of XAI is being\nextended toward explaining Large Language Models (LLMs). This extension calls\nfor a significant transformation in the XAI methodologies for two reasons.\nFirst, many existing XAI methods cannot be directly applied to LLMs due to\ntheir complexity and advanced capabilities. Second, as LLMs are increasingly\ndeployed in diverse applications, the role of XAI shifts from merely opening\nthe ``black box'' to actively enhancing the productivity and applicability of\nLLMs in real-world settings. Meanwhile, the conversation and generation\nabilities of LLMs can reciprocally enhance XAI. Therefore, in this paper, we\nintroduce Usable XAI in the context of LLMs by analyzing (1) how XAI can\nexplain and improve LLM-based AI systems and (2) how XAI techniques can be\nimproved by using LLMs. We introduce 10 strategies, introducing the key\ntechniques for each and discussing their associated challenges. We also provide\ncase studies to demonstrate how to obtain and leverage explanations. The code\nused in this paper can be found at:\nhttps://github.com/JacksonWuxs/UsableXAI_LLM.",
          "arxiv_id": "2403.08946v2"
        },
        {
          "title": "\"Help Me Help the AI\": Understanding How Explainability Can Support Human-AI Interaction",
          "year": "2022-10",
          "abstract": "Despite the proliferation of explainable AI (XAI) methods, little is\nunderstood about end-users' explainability needs and behaviors around XAI\nexplanations. To address this gap and contribute to understanding how\nexplainability can support human-AI interaction, we conducted a mixed-methods\nstudy with 20 end-users of a real-world AI application, the Merlin bird\nidentification app, and inquired about their XAI needs, uses, and perceptions.\nWe found that participants desire practically useful information that can\nimprove their collaboration with the AI, more so than technical system details.\nRelatedly, participants intended to use XAI explanations for various purposes\nbeyond understanding the AI's outputs: calibrating trust, improving their task\nskills, changing their behavior to supply better inputs to the AI, and giving\nconstructive feedback to developers. Finally, among existing XAI approaches,\nparticipants preferred part-based explanations that resemble human reasoning\nand explanations. We discuss the implications of our findings and provide\nrecommendations for future XAI design.",
          "arxiv_id": "2210.03735v2"
        },
        {
          "title": "Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction",
          "year": "2024-08",
          "abstract": "Artificial intelligence models encounter significant challenges due to their\nblack-box nature, particularly in safety-critical domains such as healthcare,\nfinance, and autonomous vehicles. Explainable Artificial Intelligence (XAI)\naddresses these challenges by providing explanations for how these models make\ndecisions and predictions, ensuring transparency, accountability, and fairness.\nExisting studies have examined the fundamental concepts of XAI, its general\nprinciples, and the scope of XAI techniques. However, there remains a gap in\nthe literature as there are no comprehensive reviews that delve into the\ndetailed mathematical representations, design methodologies of XAI models, and\nother associated aspects. This paper provides a comprehensive literature review\nencompassing common terminologies and definitions, the need for XAI,\nbeneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI\nmethods in different application areas. The survey is aimed at XAI researchers,\nXAI practitioners, AI model developers, and XAI beneficiaries who are\ninterested in enhancing the trustworthiness, transparency, accountability, and\nfairness of their AI models.",
          "arxiv_id": "2409.00265v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T21:39:59Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}