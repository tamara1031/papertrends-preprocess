{
  "topics": {
    "data": {
      "0": {
        "name": "0_code_software_models_data",
        "keywords": [
          [
            "code",
            0.029093016872632552
          ],
          [
            "software",
            0.02514223107954045
          ],
          [
            "models",
            0.016329913187306637
          ],
          [
            "data",
            0.015117884434609189
          ],
          [
            "model",
            0.014618836340984128
          ],
          [
            "LLMs",
            0.013173587703805247
          ],
          [
            "systems",
            0.01291092566653725
          ],
          [
            "paper",
            0.012738616741760201
          ],
          [
            "approach",
            0.012694316485670381
          ],
          [
            "development",
            0.012275785006390325
          ]
        ],
        "count": 14112
      },
      "1": {
        "name": "1_apps_app_Android_privacy",
        "keywords": [
          [
            "apps",
            0.03998321094189176
          ],
          [
            "app",
            0.03587777023014523
          ],
          [
            "Android",
            0.03132150944193691
          ],
          [
            "privacy",
            0.02309001128949552
          ],
          [
            "mobile",
            0.021330277538640453
          ],
          [
            "user",
            0.02040772210968956
          ],
          [
            "data",
            0.01616132515365706
          ],
          [
            "GUI",
            0.01546100474237301
          ],
          [
            "game",
            0.015075942700009965
          ],
          [
            "developers",
            0.014713989637537542
          ]
        ],
        "count": 732
      },
      "2": {
        "name": "2_smart_contracts_blockchain_smart contracts",
        "keywords": [
          [
            "smart",
            0.07169135756404746
          ],
          [
            "contracts",
            0.06818858904656418
          ],
          [
            "blockchain",
            0.055062357641145546
          ],
          [
            "smart contracts",
            0.05063686392007971
          ],
          [
            "contract",
            0.04493649267818645
          ],
          [
            "smart contract",
            0.030870478696412164
          ],
          [
            "Smart",
            0.026539466991777703
          ],
          [
            "Ethereum",
            0.026270931868928652
          ],
          [
            "Blockchain",
            0.021368726502520755
          ],
          [
            "vulnerabilities",
            0.020411586343411513
          ]
        ],
        "count": 373
      },
      "3": {
        "name": "3_quantum_Quantum_software_quantum software",
        "keywords": [
          [
            "quantum",
            0.18278994251362332
          ],
          [
            "Quantum",
            0.07027912900630091
          ],
          [
            "software",
            0.043921222177376665
          ],
          [
            "quantum software",
            0.043574289507639204
          ],
          [
            "computing",
            0.037507608404412196
          ],
          [
            "classical",
            0.03423813811821825
          ],
          [
            "quantum computing",
            0.028697112898492257
          ],
          [
            "programs",
            0.02430182135635455
          ],
          [
            "computers",
            0.018710606989285436
          ],
          [
            "circuit",
            0.01851380061204063
          ]
        ],
        "count": 216
      }
    },
    "correlations": [
      [
        1.0,
        -0.7217163685816844,
        -0.7511849308241221,
        -0.4703325781080173
      ],
      [
        -0.7217163685816844,
        1.0,
        -0.7541670367007864,
        -0.7467776444575943
      ],
      [
        -0.7511849308241221,
        -0.7541670367007864,
        1.0,
        -0.7521403493581509
      ],
      [
        -0.4703325781080173,
        -0.7467776444575943,
        -0.7521403493581509,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        76,
        9,
        7,
        1
      ],
      "2020-02": [
        78,
        8,
        7,
        2
      ],
      "2020-03": [
        101,
        4,
        4,
        0
      ],
      "2020-04": [
        127,
        3,
        11,
        0
      ],
      "2020-05": [
        140,
        12,
        11,
        1
      ],
      "2020-06": [
        101,
        8,
        3,
        1
      ],
      "2020-07": [
        123,
        8,
        10,
        1
      ],
      "2020-08": [
        116,
        15,
        11,
        0
      ],
      "2020-09": [
        125,
        3,
        7,
        2
      ],
      "2020-10": [
        111,
        7,
        3,
        0
      ],
      "2020-11": [
        98,
        7,
        3,
        0
      ],
      "2020-12": [
        138,
        11,
        4,
        2
      ],
      "2021-01": [
        134,
        13,
        5,
        1
      ],
      "2021-02": [
        190,
        13,
        10,
        1
      ],
      "2021-03": [
        328,
        23,
        12,
        8
      ],
      "2021-04": [
        161,
        13,
        6,
        2
      ],
      "2021-05": [
        138,
        2,
        7,
        3
      ],
      "2021-06": [
        129,
        6,
        7,
        3
      ],
      "2021-07": [
        150,
        7,
        6,
        2
      ],
      "2021-08": [
        189,
        9,
        5,
        3
      ],
      "2021-09": [
        142,
        9,
        2,
        0
      ],
      "2021-10": [
        139,
        7,
        7,
        1
      ],
      "2021-11": [
        89,
        7,
        5,
        3
      ],
      "2021-12": [
        138,
        7,
        8,
        3
      ],
      "2022-01": [
        151,
        6,
        6,
        2
      ],
      "2022-02": [
        145,
        5,
        4,
        2
      ],
      "2022-03": [
        165,
        14,
        8,
        5
      ],
      "2022-04": [
        183,
        10,
        9,
        4
      ],
      "2022-05": [
        152,
        8,
        6,
        3
      ],
      "2022-06": [
        145,
        7,
        8,
        3
      ],
      "2022-07": [
        137,
        8,
        6,
        0
      ],
      "2022-08": [
        175,
        7,
        9,
        3
      ],
      "2022-09": [
        158,
        13,
        4,
        3
      ],
      "2022-10": [
        116,
        12,
        4,
        4
      ],
      "2022-11": [
        119,
        9,
        8,
        1
      ],
      "2022-12": [
        129,
        7,
        6,
        2
      ],
      "2023-01": [
        140,
        17,
        3,
        0
      ],
      "2023-02": [
        160,
        9,
        2,
        6
      ],
      "2023-03": [
        201,
        16,
        12,
        4
      ],
      "2023-04": [
        170,
        6,
        11,
        3
      ],
      "2023-05": [
        253,
        9,
        12,
        3
      ],
      "2023-06": [
        184,
        9,
        8,
        8
      ],
      "2023-07": [
        220,
        12,
        9,
        9
      ],
      "2023-08": [
        265,
        17,
        13,
        7
      ],
      "2023-09": [
        204,
        10,
        10,
        4
      ],
      "2023-10": [
        225,
        13,
        10,
        5
      ],
      "2023-11": [
        187,
        11,
        12,
        4
      ],
      "2023-12": [
        201,
        5,
        5,
        2
      ],
      "2024-01": [
        301,
        8,
        8,
        6
      ],
      "2024-02": [
        281,
        10,
        9,
        3
      ],
      "2024-03": [
        253,
        5,
        17,
        3
      ],
      "2024-04": [
        275,
        14,
        11,
        10
      ],
      "2024-05": [
        256,
        7,
        9,
        14
      ],
      "2024-06": [
        286,
        12,
        10,
        3
      ],
      "2024-07": [
        267,
        21,
        16,
        2
      ],
      "2024-08": [
        303,
        17,
        11,
        7
      ],
      "2024-09": [
        248,
        25,
        12,
        8
      ],
      "2024-10": [
        287,
        9,
        8,
        10
      ],
      "2024-11": [
        244,
        12,
        12,
        9
      ],
      "2024-12": [
        287,
        8,
        13,
        5
      ],
      "2025-01": [
        316,
        12,
        17,
        6
      ],
      "2025-02": [
        346,
        12,
        10,
        7
      ],
      "2025-03": [
        401,
        10,
        8,
        6
      ],
      "2025-04": [
        390,
        19,
        19,
        7
      ],
      "2025-05": [
        371,
        16,
        14,
        7
      ],
      "2025-06": [
        377,
        11,
        21,
        13
      ],
      "2025-07": [
        419,
        12,
        11,
        12
      ],
      "2025-08": [
        335,
        16,
        13,
        8
      ],
      "2025-09": [
        176,
        6,
        11,
        4
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code",
          "year": "2022-06",
          "abstract": "Few-shot learning with large-scale, pre-trained language models is a powerful\nway to answer questions about code, e.g., how to complete a given code example,\nor even generate code snippets from scratch. The success of these models raises\nthe question whether they could serve as a basis for building a wide range code\ngeneration tools. Traditionally, such tools are built manually and separately\nfor each task. Instead, few-shot learning may allow to obtain different tools\nfrom a single pre-trained language model by simply providing a few examples or\na natural language description of the expected tool behavior. This paper\nstudies to what extent a state-of-the-art, pre-trained language model of code,\nCodex, may serve this purpose. We consider three code manipulation and code\ngeneration tasks targeted by a range of traditional tools: (i) code mutation;\n(ii) test oracle generation from natural language documentation; and (iii) test\ncase generation. For each task, we compare few-shot learning to a manually\nbuilt tool. Our results show that the model-based tools complement (code\nmutation), are on par (test oracle generation), or even outperform their\nrespective traditionally built tool (test case generation), while imposing far\nless effort to develop them. By comparing the effectiveness of different\nvariants of the model-based tools, we provide insights on how to design an\nappropriate input (\"prompt\") to the model and what influence the size of the\nmodel has. For example, we find that providing a small natural language\ndescription of the code generation task is an easy way to improve predictions.\nOverall, we conclude that few-shot language models are surprisingly effective,\nyet there is still more work to be done, such as exploring more diverse ways of\nprompting and tackling even more involved tasks.",
          "arxiv_id": "2206.01335v2"
        },
        {
          "title": "Large Language Models for Code Generation: The Practitioners Perspective",
          "year": "2025-01",
          "abstract": "Large Language Models (LLMs) have emerged as coding assistants, capable of\ngenerating source code from natural language prompts. With the increasing\nadoption of LLMs in software development, academic research and industry based\nprojects are developing various tools, benchmarks, and metrics to evaluate the\neffectiveness of LLM-generated code. However, there is a lack of solutions\nevaluated through empirically grounded methods that incorporate practitioners\nperspectives to assess functionality, syntax, and accuracy in real world\napplications. To address this gap, we propose and develop a multi-model unified\nplatform to generate and execute code based on natural language prompts. We\nconducted a survey with 60 software practitioners from 11 countries across four\ncontinents working in diverse professional roles and domains to evaluate the\nusability, performance, strengths, and limitations of each model. The results\npresent practitioners feedback and insights into the use of LLMs in software\ndevelopment, including their strengths and weaknesses, key aspects overlooked\nby benchmarks and metrics, and a broader understanding of their practical\napplicability. These findings can help researchers and practitioners make\ninformed decisions for systematically selecting and using LLMs in software\ndevelopment projects. Future research will focus on integrating more diverse\nmodels into the proposed system, incorporating additional case studies, and\nconducting developer interviews for deeper empirical insights into LLM-driven\nsoftware development.",
          "arxiv_id": "2501.16998v1"
        },
        {
          "title": "PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)",
          "year": "2024-09",
          "abstract": "The capability of generating high-quality source code using large language\nmodels (LLMs) reduces software development time and costs. However, they often\nintroduce security vulnerabilities due to training on insecure open-source\ndata. This highlights the need for ensuring secure and functional code\ngeneration. This paper introduces PromSec, an algorithm for prom optimization\nfor secure and functioning code generation using LLMs. In PromSec, we combine\n1) code vulnerability clearing using a generative adversarial graph neural\nnetwork, dubbed as gGAN, to fix and reduce security vulnerabilities in\ngenerated codes and 2) code generation using an LLM into an interactive loop,\nsuch that the outcome of the gGAN drives the LLM with enhanced prompts to\ngenerate secure codes while preserving their functionality. Introducing a new\ncontrastive learning approach in gGAN, we formulate code-clearing and\ngeneration as a dual-objective optimization problem, enabling PromSec to\nnotably reduce the number of LLM inferences. PromSec offers a cost-effective\nand practical solution for generating secure, functional code. Extensive\nexperiments conducted on Python and Java code datasets confirm that PromSec\neffectively enhances code security while upholding its intended functionality.\nOur experiments show that while a state-of-the-art approach fails to address\nall code vulnerabilities, PromSec effectively resolves them. Moreover, PromSec\nachieves more than an order-of-magnitude reduction in operation time, number of\nLLM queries, and security analysis costs. Furthermore, prompts optimized with\nPromSec for a certain LLM are transferable to other LLMs across programming\nlanguages and generalizable to unseen vulnerabilities in training. This study\nis a step in enhancing the trustworthiness of LLMs for secure and functional\ncode generation, supporting their integration into real-world software\ndevelopment.",
          "arxiv_id": "2409.12699v1"
        }
      ],
      "1": [
        {
          "title": "DinoDroid: Testing Android Apps Using Deep Q-Networks",
          "year": "2022-10",
          "abstract": "The large demand of mobile devices creates significant concerns about the\nquality of mobile applications (apps). Developers need to guarantee the quality\nof mobile apps before it is released to the market. There have been many\napproaches using different strategies to test the GUI of mobile apps. However,\nthey still need improvement due to their limited effectiveness. In this paper,\nwe propose DinoDroid, an approach based on deep Q-networks to automate testing\nof Android apps. DinoDroid learns a behavior model from a set of existing apps\nand the learned model can be used to explore and generate tests for new apps.\nDinoDroid is able to capture the fine-grained details of GUI events (e.g., the\ncontent of GUI widgets) and use them as features that are fed into deep neural\nnetwork, which acts as the agent to guide app exploration. DinoDroid\nautomatically adapts the learned model during the exploration without the need\nof any modeling strategies or pre-defined rules. We conduct experiments on 64\nopen-source Android apps. The results showed that DinoDroid outperforms\nexisting Android testing tools in terms of code coverage and bug detection.",
          "arxiv_id": "2210.06307v1"
        },
        {
          "title": "An Empirical Evaluation of GDPR Compliance Violations in Android mHealth Apps",
          "year": "2020-08",
          "abstract": "The purpose of the General Data Protection Regulation (GDPR) is to provide\nimproved privacy protection. If an app controls personal data from users, it\nneeds to be compliant with GDPR. However, GDPR lists general rules rather than\nexact step-by-step guidelines about how to develop an app that fulfills the\nrequirements. Therefore, there may exist GDPR compliance violations in existing\napps, which would pose severe privacy threats to app users. In this paper, we\ntake mobile health applications (mHealth apps) as a peephole to examine the\nstatus quo of GDPR compliance in Android apps. We first propose an automated\nsystem, named \\mytool, to bridge the semantic gap between the general rules of\nGDPR and the app implementations by identifying the data practices declared in\nthe app privacy policy and the data relevant behaviors in the app code. Then,\nbased on \\mytool, we detect three kinds of GDPR compliance violations,\nincluding the incompleteness of privacy policy, the inconsistency of data\ncollections, and the insecurity of data transmission. We perform an empirical\nevaluation of 796 mHealth apps. The results reveal that 189 (23.7\\%) of them do\nnot provide complete privacy policies. Moreover, 59 apps collect sensitive data\nthrough different measures, but 46 (77.9\\%) of them contain at least one\ninconsistent collection behavior. Even worse, among the 59 apps, only 8 apps\ntry to ensure the transmission security of collected data. However, all of them\ncontain at least one encryption or SSL misuse. Our work exposes severe privacy\nissues to raise awareness of privacy protection for app users and developers.",
          "arxiv_id": "2008.05864v2"
        },
        {
          "title": "SeMA: Extending and Analyzing Storyboards to Develop Secure Android Apps",
          "year": "2020-01",
          "abstract": "Mobile apps provide various critical services, such as banking,\ncommunication, and healthcare. To this end, they have access to our personal\ninformation and have the ability to perform actions on our behalf. Hence,\nsecuring mobile apps is crucial to ensuring the privacy and safety of its\nusers.\n  Recent research efforts have focused on developing solutions to secure mobile\necosystems (i.e., app platforms, apps, and app stores), specifically in the\ncontext of detecting vulnerabilities in Android apps. Despite this attention,\nknown vulnerabilities are often found in mobile apps, which can be exploited by\nmalicious apps to harm the user. Further, fixing vulnerabilities after\ndeveloping an app has downsides in terms of time, resources, user\ninconvenience, and information loss.\n  In an attempt to address this concern, we have developed SeMA, a mobile app\ndevelopment methodology that builds on existing mobile app design artifacts\nsuch as storyboards. With SeMA, security is a first-class citizen in an app's\ndesign -- app designers and developers can collaborate to specify and reason\nabout the security properties of an app at an abstract level without being\ndistracted by implementation level details. Our realization of SeMA using\nAndroid Studio tooling demonstrates the methodology is complementary to\nexisting design and development practices. An evaluation of the effectiveness\nof SeMA shows the methodology can detect and help prevent 49 vulnerabilities\nknown to occur in Android apps. Further, a usability study of the methodology\ninvolving ten real-world developers shows the methodology is likely to reduce\nthe development time and help developers uncover and prevent known\nvulnerabilities while designing apps.",
          "arxiv_id": "2001.10052v4"
        }
      ],
      "2": [
        {
          "title": "When Deep Learning Meets Smart Contracts",
          "year": "2020-08",
          "abstract": "Ethereum has become a widely used platform to enable secure, Blockchain-based\nfinancial and business transactions. However, many identified bugs and\nvulnerabilities in smart contracts have led to serious financial losses, which\nraises serious concerns about smart contract security. Thus, there is a\nsignificant need to better maintain smart contract code and ensure its high\nreliability. In this research: (1) Firstly, we propose an automated deep\nlearning based approach to learn structural code embeddings of smart contracts\nin Solidity, which is useful for clone detection, bug detection and contract\nvalidation on smart contracts. We apply our approach to more than 22K solidity\ncontracts collected from the Ethereum blockchain, results show that the clone\nratio of solidity code is at around 90%, much higher than traditional software.\nWe collect a list of 52 known buggy smart contracts belonging to 10 kinds of\ncommon vulnerabilities as our bug database. Our approach can identify more than\n1000 clone related bugs based on our bug databases efficiently and accurately.\n(2) Secondly, according to developers' feedback, we have implemented the\napproach in a web-based tool, named SmartEmbed, to facilitate Solidity\ndevelopers for using our approach. Our tool can assist Solidity developers to\nefficiently identify repetitive smart contracts in the existing Ethereum\nblockchain, as well as checking their contract against a known set of bugs,\nwhich can help to improve the users' confidence in the reliability of the\ncontract. We optimize the implementations of SmartEmbed which is sufficient in\nsupporting developers in real-time for practical uses. The Ethereum ecosystem\nas well as the individual Solidity developer can both benefit from our\nresearch.",
          "arxiv_id": "2008.04093v1"
        },
        {
          "title": "A Framework and DataSet for Bugs in Ethereum Smart Contracts",
          "year": "2020-09",
          "abstract": "Ethereum is the largest blockchain platform that supports smart contracts.\nUsers deploy smart contracts by publishing the smart contract's bytecode to the\nblockchain. Since the data in the blockchain cannot be modified, even if these\ncontracts contain bugs, it is not possible to patch deployed smart contracts\nwith code updates. Moreover, there is currently neither a comprehensive\nclassification framework for Ethereum smart contract bugs, nor detailed\ncriteria for detecting bugs in smart contracts, making it difficult for\ndevelopers to fully understand the negative effects of bugs and design new\napproaches to detect bugs. In this paper, to fill the gap, we first collect as\nmany smart contract bugs as possible from multiple sources and divide these\nbugs into 9 categories by extending the IEEE Standard Classification for\nSoftware Anomalies. Then, we design the criteria for detecting each kind of\nbugs, and construct a dataset of smart contracts covering all kinds of bugs.\nWith our framework and dataset, developers can learn smart contract bugs and\ndevelop new tools to detect and locate bugs in smart contracts. Moreover, we\nevaluate the state-of-the-art tools for smart contract analysis with our\ndataset and obtain some interesting findings: 1) Mythril, Slither and Remix are\nthe most worthwhile combination of analysis tools. 2) There are still 10 kinds\nof bugs that cannot be detected by any analysis tool.",
          "arxiv_id": "2009.02066v1"
        },
        {
          "title": "Smart Contracts for SMEs and Large Companies",
          "year": "2025-05",
          "abstract": "Research on blockchains addresses multiple issues, with one being writing\nsmart contracts. In our previous research we described methodology and a tool\nto generate, in automated fashion, smart contracts from BPMN models. The\ngenerated smart contracts provide support for multi-step transactions that\nfacilitate repair/upgrade of smart contracts. In this paper we show how the\napproach is used to support collaborations via smart contracts for companies\nranging from SMEs with little IT capabilities to companies with IT using\nblockchain smart contracts. Furthermore, we also show how the approach is used\nfor certain applications to generate smart contracts by a BPMN modeler who does\nnot need any knowledge of blockchain technology or smart contract development -\nthus we are hoping to facilitate democratization of smart contracts and\nblockchain technology.",
          "arxiv_id": "2505.22619v1"
        }
      ],
      "3": [
        {
          "title": "Symbolic quantum programming for supporting applications of quantum computing technologies",
          "year": "2023-02",
          "abstract": "The goal of this paper is to deliver the overview of the current state of the\nart, to provide experience report on developing quantum software tools, and to\noutline the perspective for developing quantum programming tools supporting\nsymbolic programming for the needs of quantum computing technologies. The main\nfocus of this paper is on quantum computing technologies, as they can in the\nmost direct way benefit from developing tools enabling the symbolic\nmanipulation of quantum circuits and providing software tools for creating,\noptimizing, and testing quantum programs. We deliver a short survey of the most\npopular approaches in the field of quantum software development and we aim at\npointing their strengths and weaknesses. This helps to formulate a list of\ndesirable characteristics which should be included in quantum computing\nframeworks. Next, we describe a software architecture and its preliminary\nimplementation supporting the development of quantum programs using symbolic\napproach, encouraging the functional programming paradigm, and, at the same,\ntime enabling the integration with high-performance and cloud computing. The\ndescribed software consists of several packages developed to address different\nneeds, but nevertheless sharing common design concepts. We also outline how the\npresented approach could be used in tasks in quantum software engineering,\nnamely quantum software testing and quantum circuit construction.",
          "arxiv_id": "2302.09401v1"
        },
        {
          "title": "Quantum Software Engineering: A New Genre of Computing",
          "year": "2022-11",
          "abstract": "Quantum computing (QC) is no longer only a scientific interest but is rapidly\nbecoming an industrially available technology that can potentially tackle the\nlimitations of classical computing. Over the last few years, major technology\ngiants have invested in developing hardware and programming frameworks to\ndevelop quantum-specific applications. QC hardware technologies are gaining\nmomentum, however, operationalizing the QC technologies trigger the need for\nsoftware-intensive methodologies, techniques, processes, tools, roles, and\nresponsibilities for developing industrial-centric quantum software\napplications. This paper presents the vision of the quantum software\nengineering (QSE) life cycle consisting of quantum requirements engineering,\nquantum software design, quantum software implementation, quantum software\ntesting, and quantum software maintenance. This paper particularly calls for\njoint contributions of software engineering research and industrial community\nto present real-world solutions to support the entire quantum software\ndevelopment activities. The proposed vision facilitates the researchers and\npractitioners to propose new processes, reference architectures, novel tools,\nand practices to leverage quantum computers and develop emerging and next\ngenerations of quantum software.",
          "arxiv_id": "2211.13990v1"
        },
        {
          "title": "Bug Characteristics in Quantum Software Ecosystem",
          "year": "2022-04",
          "abstract": "With the advance in quantum computing in recent years, quantum software\nbecomes vital for exploring the full potential of quantum computing systems.\nQuantum programming is different from classical programming, for example, the\nstate of a quantum program is probabilistic in nature, and a quantum computer\nis error-prone due to the instability of quantum mechanisms. Therefore, the\ncharacteristics of bugs in quantum software projects may be very different from\nthat of classical software projects. This work aims to understand the\ncharacteristics of bugs in quantum software projects, in order to provide\ninsights to help devise effective testing and debugging mechanisms. To achieve\nthis goal, we conduct an empirical study on the bug reports of 125 quantum\nsoftware projects. We observe that quantum software projects are more buggy\nthan classical software projects and that quantum project bugs are more costly\nto fix than classical project bugs. We also identify the types of the bugs and\nthe quantum programming components where they occurred. Our study shows that\nthe bugs are spread across different components, but quantum-specific bugs\nparticularly appear in the compiler, gate operation, and state preparation\ncomponents. The three most occurring types of bugs are Program anomaly bugs,\nConfiguration bugs, and Data type and structure bugs. Our study highlights some\nparticularly challenging areas in quantum software development, such as the\nlack of scientific quantum computation libraries that implement comprehensive\nmathematical functions for quantum computing. Quantum developers also seek\nspecialized data manipulation libraries for quantum software engineering like\nNumpy for quantum computing. Our findings also provide insights for future work\nto advance the quantum program development, testing, and debugging of quantum\nsoftware, such as providing tooling support for debugging low-level circuits.",
          "arxiv_id": "2204.11965v1"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T22:22:04Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}