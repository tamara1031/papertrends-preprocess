{
  "topics": {
    "data": {
      "0": {
        "name": "0_model_systems_checking_synthesis",
        "keywords": [
          [
            "model",
            0.019257171272276868
          ],
          [
            "systems",
            0.01863405511840054
          ],
          [
            "checking",
            0.014832166657581365
          ],
          [
            "synthesis",
            0.013875434690422243
          ],
          [
            "problem",
            0.013715560486141958
          ],
          [
            "temporal",
            0.013200455869198442
          ],
          [
            "LTL",
            0.012987358500030409
          ],
          [
            "verification",
            0.01277841355087125
          ],
          [
            "safety",
            0.012747292797487386
          ],
          [
            "model checking",
            0.012518091357159204
          ]
        ],
        "count": 1003
      },
      "1": {
        "name": "1_order_graphs_problem_classes",
        "keywords": [
          [
            "order",
            0.018893126360486966
          ],
          [
            "graphs",
            0.01736754644109199
          ],
          [
            "problem",
            0.016207685330354018
          ],
          [
            "classes",
            0.015619844340550332
          ],
          [
            "graph",
            0.015241505536159354
          ],
          [
            "class",
            0.015114784147509835
          ],
          [
            "finite",
            0.014703202628297026
          ],
          [
            "complexity",
            0.014687122284203451
          ],
          [
            "bounded",
            0.014062599497934763
          ],
          [
            "automata",
            0.012840870047025787
          ]
        ],
        "count": 990
      },
      "2": {
        "name": "2_type_theory_type theory_types",
        "keywords": [
          [
            "type",
            0.04768374036619063
          ],
          [
            "theory",
            0.03533606054948798
          ],
          [
            "type theory",
            0.0262238845579126
          ],
          [
            "types",
            0.02420062795988032
          ],
          [
            "categories",
            0.023792195472660854
          ],
          [
            "category",
            0.02031968060326354
          ],
          [
            "lambda",
            0.01605675827643525
          ],
          [
            "calculus",
            0.0151740132006311
          ],
          [
            "theories",
            0.012875121383921597
          ],
          [
            "terms",
            0.012324732491574574
          ]
        ],
        "count": 655
      },
      "3": {
        "name": "3_neural_learning_reasoning_networks",
        "keywords": [
          [
            "neural",
            0.02887759272483122
          ],
          [
            "learning",
            0.02031402684777791
          ],
          [
            "reasoning",
            0.020266095865281237
          ],
          [
            "networks",
            0.020066752879074848
          ],
          [
            "models",
            0.017559704733991047
          ],
          [
            "neural networks",
            0.016519328728402827
          ],
          [
            "Neural",
            0.015662426515490404
          ],
          [
            "explanations",
            0.01487315200568248
          ],
          [
            "network",
            0.014843779399462742
          ],
          [
            "verification",
            0.014825569199280615
          ]
        ],
        "count": 439
      },
      "4": {
        "name": "4_logic_modal_proof_logics",
        "keywords": [
          [
            "logic",
            0.04901961882972367
          ],
          [
            "modal",
            0.0386755888729823
          ],
          [
            "proof",
            0.03570892055213139
          ],
          [
            "logics",
            0.03096475114271369
          ],
          [
            "intuitionistic",
            0.030319910021151777
          ],
          [
            "semantics",
            0.023131336056494794
          ],
          [
            "sequent",
            0.021259126279153714
          ],
          [
            "classical",
            0.019849523204728513
          ],
          [
            "cut",
            0.01963880597702056
          ],
          [
            "modal logic",
            0.0169094328238547
          ]
        ],
        "count": 353
      },
      "5": {
        "name": "5_programs_program_verification_memory",
        "keywords": [
          [
            "programs",
            0.025845596879037213
          ],
          [
            "program",
            0.025010542801447485
          ],
          [
            "verification",
            0.024499338557579853
          ],
          [
            "memory",
            0.014177187558286992
          ],
          [
            "data",
            0.013166129839046609
          ],
          [
            "analysis",
            0.012851195779150532
          ],
          [
            "logic",
            0.012353647304072905
          ],
          [
            "correctness",
            0.012201282029457087
          ],
          [
            "code",
            0.011453531648163394
          ],
          [
            "approach",
            0.010813878407646159
          ]
        ],
        "count": 351
      },
      "6": {
        "name": "6_query_queries_ontology_ontologies",
        "keywords": [
          [
            "query",
            0.034381826341901615
          ],
          [
            "queries",
            0.0328683773918888
          ],
          [
            "ontology",
            0.02666552919130757
          ],
          [
            "ontologies",
            0.020706375446087923
          ],
          [
            "data",
            0.01908537706061004
          ],
          [
            "knowledge",
            0.018606005084228383
          ],
          [
            "DL",
            0.01679901061235804
          ],
          [
            "conjunctive",
            0.014500747004927884
          ],
          [
            "complexity",
            0.014116213451223247
          ],
          [
            "answering",
            0.013284720219508071
          ]
        ],
        "count": 258
      },
      "7": {
        "name": "7_epistemic_knowledge_logic_belief",
        "keywords": [
          [
            "epistemic",
            0.040191482672321095
          ],
          [
            "knowledge",
            0.033408694832445796
          ],
          [
            "logic",
            0.03111229156226143
          ],
          [
            "belief",
            0.0306609368752646
          ],
          [
            "agents",
            0.02644854778806718
          ],
          [
            "agent",
            0.022371042436619238
          ],
          [
            "model",
            0.018370856300647453
          ],
          [
            "epistemic logic",
            0.015535281500639217
          ],
          [
            "Epistemic",
            0.014611173591792866
          ],
          [
            "paper",
            0.014577810304059477
          ]
        ],
        "count": 239
      },
      "8": {
        "name": "8_proof_theorem_proofs_proving",
        "keywords": [
          [
            "proof",
            0.03945754699441239
          ],
          [
            "theorem",
            0.028479635382856514
          ],
          [
            "proofs",
            0.02820448544629527
          ],
          [
            "proving",
            0.022962150555870822
          ],
          [
            "Isabelle",
            0.022843509131309753
          ],
          [
            "theorem proving",
            0.02118833179849945
          ],
          [
            "formal",
            0.020341885591019345
          ],
          [
            "learning",
            0.01687290162957949
          ],
          [
            "language",
            0.013851739247353865
          ],
          [
            "problems",
            0.013752824861213092
          ]
        ],
        "count": 202
      },
      "9": {
        "name": "9_quantum_Quantum_circuits_classical",
        "keywords": [
          [
            "quantum",
            0.1341373401459384
          ],
          [
            "Quantum",
            0.04298975023907544
          ],
          [
            "circuits",
            0.0300768145296661
          ],
          [
            "classical",
            0.02192476780071649
          ],
          [
            "quantum circuits",
            0.01948056362089685
          ],
          [
            "logic",
            0.018244448964867595
          ],
          [
            "quantum programs",
            0.017843814215811108
          ],
          [
            "language",
            0.017682603981810013
          ],
          [
            "circuit",
            0.016732486588129262
          ],
          [
            "programs",
            0.016356210602314507
          ]
        ],
        "count": 187
      },
      "10": {
        "name": "10_SAT_solvers_SMT_solver",
        "keywords": [
          [
            "SAT",
            0.05104979625115838
          ],
          [
            "solvers",
            0.0371777569252768
          ],
          [
            "SMT",
            0.034027822377571904
          ],
          [
            "solver",
            0.02529021880687354
          ],
          [
            "solving",
            0.022189528828953167
          ],
          [
            "search",
            0.020782666825148226
          ],
          [
            "problems",
            0.020330975195390493
          ],
          [
            "model",
            0.018024996348447272
          ],
          [
            "Boolean",
            0.017497930377269037
          ],
          [
            "problem",
            0.016096911521553944
          ]
        ],
        "count": 126
      },
      "11": {
        "name": "11_ASP_Answer_answer_Set",
        "keywords": [
          [
            "ASP",
            0.0777116745873062
          ],
          [
            "Answer",
            0.03467219736496525
          ],
          [
            "answer",
            0.03180326763493202
          ],
          [
            "Set",
            0.02953539075614307
          ],
          [
            "programs",
            0.029349268865036218
          ],
          [
            "Programming",
            0.027645102173171204
          ],
          [
            "set",
            0.022657802597992962
          ],
          [
            "program",
            0.018922393024561796
          ],
          [
            "logic",
            0.01787545695746817
          ],
          [
            "answer sets",
            0.015141804207677035
          ]
        ],
        "count": 105
      }
    },
    "correlations": [
      [
        1.0,
        -0.39438962157233226,
        -0.4821588796465214,
        -0.6788297774068444,
        -0.5916889670868481,
        -0.6561440508123455,
        -0.7122815900261659,
        -0.5435257900685484,
        -0.6721217751888989,
        -0.7402528076059671,
        -0.7013251072881873,
        -0.7275762528529323
      ],
      [
        -0.39438962157233226,
        1.0,
        -0.39647239168033094,
        -0.7090025486177809,
        -0.5108338137031851,
        -0.6945238741973505,
        -0.7051792512601016,
        -0.6412003871281442,
        -0.6719542251547983,
        -0.7430330720084726,
        -0.7213316522864106,
        -0.7374874230005737
      ],
      [
        -0.4821588796465214,
        -0.39647239168033094,
        1.0,
        -0.7269168156198427,
        -0.6161675614398703,
        -0.704028631136346,
        -0.7398174003105896,
        -0.6750251828336353,
        -0.6566847602330776,
        -0.7364250593375536,
        -0.7336711142830074,
        -0.7403354390515425
      ],
      [
        -0.6788297774068444,
        -0.7090025486177809,
        -0.7269168156198427,
        1.0,
        -0.7210845729737059,
        -0.7119099494117372,
        -0.7219203868507207,
        -0.6977414062661567,
        -0.7145830866142806,
        -0.7597731361446534,
        -0.7175247523541328,
        -0.7365682657439239
      ],
      [
        -0.5916889670868481,
        -0.5108338137031851,
        -0.6161675614398703,
        -0.7210845729737059,
        1.0,
        -0.7019731623387014,
        -0.7252213825335332,
        -0.4490893959114064,
        -0.5649530143842328,
        -0.7384542423216129,
        -0.7381263351973373,
        -0.7240013779241713
      ],
      [
        -0.6561440508123455,
        -0.6945238741973505,
        -0.704028631136346,
        -0.7119099494117372,
        -0.7019731623387014,
        1.0,
        -0.744038403696448,
        -0.7184646837059467,
        -0.701551293658458,
        -0.7523543736054514,
        -0.7272125488287895,
        -0.5795905801560323
      ],
      [
        -0.7122815900261659,
        -0.7051792512601016,
        -0.7398174003105896,
        -0.7219203868507207,
        -0.7252213825335332,
        -0.744038403696448,
        1.0,
        -0.7224510529701713,
        -0.7532985322426802,
        -0.7615854675580582,
        -0.7489433278554898,
        -0.7286573248468642
      ],
      [
        -0.5435257900685484,
        -0.6412003871281442,
        -0.6750251828336353,
        -0.6977414062661567,
        -0.4490893959114064,
        -0.7184646837059467,
        -0.7224510529701713,
        1.0,
        -0.7121483323441051,
        -0.74990825499499,
        -0.737815528426162,
        -0.7269675410764938
      ],
      [
        -0.6721217751888989,
        -0.6719542251547983,
        -0.6566847602330776,
        -0.7145830866142806,
        -0.5649530143842328,
        -0.701551293658458,
        -0.7532985322426802,
        -0.7121483323441051,
        1.0,
        -0.7513701420750142,
        -0.7359616615900899,
        -0.7432536621390693
      ],
      [
        -0.7402528076059671,
        -0.7430330720084726,
        -0.7364250593375536,
        -0.7597731361446534,
        -0.7384542423216129,
        -0.7523543736054514,
        -0.7615854675580582,
        -0.74990825499499,
        -0.7513701420750142,
        1.0,
        -0.7452279167419622,
        -0.7615477722149202
      ],
      [
        -0.7013251072881873,
        -0.7213316522864106,
        -0.7336711142830074,
        -0.7175247523541328,
        -0.7381263351973373,
        -0.7272125488287895,
        -0.7489433278554898,
        -0.737815528426162,
        -0.7359616615900899,
        -0.7452279167419622,
        1.0,
        -0.7291606810144422
      ],
      [
        -0.7275762528529323,
        -0.7374874230005737,
        -0.7403354390515425,
        -0.7365682657439239,
        -0.7240013779241713,
        -0.5795905801560323,
        -0.7286573248468642,
        -0.7269675410764938,
        -0.7432536621390693,
        -0.7615477722149202,
        -0.7291606810144422,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        27,
        12,
        10,
        3,
        14,
        8,
        5,
        5,
        11,
        3,
        3,
        1
      ],
      "2020-02": [
        19,
        15,
        16,
        4,
        16,
        6,
        3,
        2,
        15,
        2,
        4,
        3
      ],
      "2020-03": [
        36,
        9,
        8,
        3,
        12,
        1,
        7,
        4,
        5,
        3,
        4,
        2
      ],
      "2020-04": [
        41,
        5,
        10,
        5,
        9,
        4,
        3,
        7,
        8,
        3,
        7,
        3
      ],
      "2020-05": [
        31,
        15,
        19,
        4,
        15,
        5,
        4,
        3,
        12,
        6,
        9,
        3
      ],
      "2020-06": [
        25,
        9,
        15,
        7,
        14,
        5,
        3,
        4,
        5,
        3,
        2,
        1
      ],
      "2020-07": [
        50,
        16,
        21,
        8,
        20,
        6,
        3,
        5,
        2,
        3,
        9,
        2
      ],
      "2020-08": [
        32,
        14,
        11,
        2,
        18,
        5,
        3,
        3,
        6,
        3,
        5,
        13
      ],
      "2020-09": [
        36,
        7,
        13,
        6,
        13,
        2,
        2,
        2,
        6,
        1,
        6,
        10
      ],
      "2020-10": [
        31,
        14,
        26,
        6,
        9,
        4,
        5,
        6,
        10,
        2,
        4,
        2
      ],
      "2020-11": [
        19,
        4,
        8,
        2,
        6,
        6,
        2,
        2,
        3,
        3,
        0,
        4
      ],
      "2020-12": [
        35,
        3,
        12,
        3,
        8,
        5,
        1,
        2,
        7,
        6,
        7,
        1
      ],
      "2021-01": [
        37,
        13,
        19,
        4,
        12,
        3,
        1,
        2,
        9,
        4,
        0,
        2
      ],
      "2021-02": [
        29,
        13,
        19,
        2,
        16,
        4,
        3,
        6,
        10,
        2,
        4,
        0
      ],
      "2021-03": [
        24,
        3,
        14,
        2,
        14,
        3,
        1,
        3,
        4,
        7,
        5,
        1
      ],
      "2021-04": [
        42,
        14,
        19,
        5,
        18,
        2,
        1,
        3,
        16,
        3,
        4,
        4
      ],
      "2021-05": [
        46,
        17,
        17,
        4,
        17,
        4,
        2,
        6,
        11,
        7,
        5,
        2
      ],
      "2021-06": [
        33,
        8,
        13,
        5,
        17,
        4,
        2,
        11,
        8,
        3,
        6,
        4
      ],
      "2021-07": [
        39,
        9,
        16,
        4,
        17,
        3,
        5,
        1,
        7,
        8,
        8,
        3
      ],
      "2021-08": [
        30,
        13,
        7,
        6,
        16,
        7,
        3,
        8,
        7,
        1,
        2,
        9
      ],
      "2021-09": [
        35,
        10,
        11,
        4,
        14,
        5,
        2,
        7,
        4,
        9,
        8,
        15
      ],
      "2021-10": [
        32,
        4,
        16,
        6,
        16,
        4,
        2,
        4,
        9,
        6,
        3,
        1
      ],
      "2021-11": [
        26,
        8,
        10,
        2,
        9,
        5,
        2,
        2,
        5,
        3,
        1,
        2
      ],
      "2021-12": [
        30,
        3,
        17,
        11,
        17,
        4,
        5,
        1,
        11,
        3,
        3,
        5
      ],
      "2022-01": [
        26,
        11,
        8,
        6,
        9,
        1,
        2,
        5,
        7,
        3,
        3,
        2
      ],
      "2022-02": [
        27,
        15,
        12,
        8,
        12,
        4,
        4,
        2,
        7,
        2,
        5,
        2
      ],
      "2022-03": [
        28,
        14,
        18,
        4,
        8,
        4,
        3,
        8,
        7,
        2,
        2,
        0
      ],
      "2022-04": [
        30,
        9,
        17,
        2,
        28,
        2,
        3,
        1,
        6,
        9,
        1,
        1
      ],
      "2022-05": [
        48,
        7,
        17,
        4,
        23,
        12,
        4,
        10,
        16,
        6,
        7,
        8
      ],
      "2022-06": [
        25,
        16,
        14,
        6,
        10,
        5,
        4,
        4,
        5,
        7,
        3,
        0
      ],
      "2022-07": [
        42,
        7,
        15,
        9,
        17,
        3,
        4,
        3,
        11,
        2,
        4,
        1
      ],
      "2022-08": [
        32,
        9,
        5,
        6,
        9,
        2,
        10,
        5,
        10,
        1,
        5,
        6
      ],
      "2022-09": [
        33,
        13,
        12,
        3,
        16,
        5,
        6,
        3,
        9,
        1,
        3,
        3
      ],
      "2022-10": [
        19,
        9,
        15,
        4,
        19,
        2,
        6,
        1,
        11,
        2,
        2,
        1
      ],
      "2022-11": [
        22,
        11,
        13,
        1,
        6,
        4,
        3,
        8,
        1,
        0,
        6,
        2
      ],
      "2022-12": [
        21,
        8,
        11,
        4,
        11,
        5,
        5,
        1,
        5,
        4,
        2,
        0
      ],
      "2023-01": [
        25,
        11,
        21,
        6,
        17,
        5,
        5,
        2,
        4,
        4,
        3,
        1
      ],
      "2023-02": [
        30,
        12,
        19,
        4,
        10,
        6,
        2,
        4,
        12,
        5,
        2,
        1
      ],
      "2023-03": [
        33,
        7,
        25,
        7,
        18,
        3,
        5,
        7,
        18,
        7,
        9,
        3
      ],
      "2023-04": [
        34,
        15,
        17,
        3,
        21,
        1,
        4,
        6,
        8,
        2,
        1,
        0
      ],
      "2023-05": [
        51,
        16,
        23,
        8,
        23,
        16,
        5,
        7,
        11,
        0,
        4,
        7
      ],
      "2023-06": [
        29,
        9,
        13,
        5,
        19,
        1,
        11,
        8,
        6,
        1,
        8,
        2
      ],
      "2023-07": [
        41,
        23,
        22,
        7,
        30,
        5,
        9,
        18,
        7,
        6,
        7,
        3
      ],
      "2023-08": [
        41,
        9,
        10,
        6,
        17,
        1,
        6,
        7,
        3,
        4,
        3,
        12
      ],
      "2023-09": [
        31,
        8,
        16,
        3,
        14,
        6,
        2,
        4,
        7,
        2,
        3,
        0
      ],
      "2023-10": [
        42,
        12,
        16,
        3,
        17,
        6,
        7,
        7,
        10,
        3,
        6,
        3
      ],
      "2023-11": [
        33,
        10,
        10,
        5,
        9,
        4,
        2,
        6,
        11,
        9,
        4,
        3
      ],
      "2023-12": [
        27,
        8,
        16,
        4,
        14,
        2,
        0,
        5,
        5,
        3,
        3,
        2
      ],
      "2024-01": [
        44,
        15,
        14,
        12,
        12,
        5,
        3,
        4,
        16,
        3,
        3,
        2
      ],
      "2024-02": [
        38,
        14,
        17,
        4,
        18,
        7,
        4,
        8,
        10,
        4,
        7,
        3
      ],
      "2024-03": [
        31,
        13,
        5,
        5,
        20,
        9,
        6,
        4,
        9,
        4,
        8,
        4
      ],
      "2024-04": [
        40,
        15,
        18,
        2,
        24,
        6,
        6,
        6,
        14,
        1,
        9,
        0
      ],
      "2024-05": [
        56,
        14,
        17,
        11,
        22,
        6,
        5,
        9,
        7,
        3,
        6,
        5
      ],
      "2024-06": [
        34,
        8,
        8,
        4,
        21,
        1,
        3,
        5,
        5,
        6,
        10,
        4
      ],
      "2024-07": [
        29,
        15,
        19,
        6,
        10,
        4,
        4,
        2,
        7,
        0,
        4,
        7
      ],
      "2024-08": [
        34,
        8,
        8,
        7,
        11,
        1,
        3,
        3,
        3,
        5,
        6,
        8
      ],
      "2024-09": [
        21,
        4,
        12,
        1,
        6,
        3,
        2,
        3,
        6,
        2,
        1,
        3
      ],
      "2024-10": [
        47,
        5,
        14,
        8,
        17,
        3,
        3,
        6,
        14,
        4,
        7,
        3
      ],
      "2024-11": [
        35,
        11,
        17,
        5,
        11,
        6,
        0,
        3,
        8,
        3,
        4,
        1
      ],
      "2024-12": [
        29,
        11,
        8,
        2,
        25,
        1,
        8,
        10,
        14,
        4,
        4,
        4
      ],
      "2025-01": [
        45,
        13,
        12,
        3,
        14,
        5,
        3,
        5,
        17,
        4,
        7,
        1
      ],
      "2025-02": [
        39,
        12,
        13,
        3,
        17,
        4,
        5,
        7,
        11,
        2,
        7,
        13
      ],
      "2025-03": [
        36,
        7,
        11,
        3,
        13,
        4,
        4,
        3,
        11,
        3,
        6,
        2
      ],
      "2025-04": [
        37,
        16,
        13,
        7,
        16,
        5,
        3,
        8,
        9,
        7,
        6,
        3
      ],
      "2025-05": [
        53,
        16,
        14,
        9,
        22,
        5,
        1,
        10,
        25,
        2,
        13,
        2
      ],
      "2025-06": [
        28,
        12,
        13,
        8,
        21,
        5,
        3,
        6,
        14,
        7,
        6,
        6
      ],
      "2025-07": [
        56,
        12,
        15,
        4,
        26,
        4,
        7,
        9,
        15,
        6,
        8,
        12
      ],
      "2025-08": [
        32,
        7,
        8,
        11,
        22,
        8,
        5,
        5,
        13,
        6,
        8,
        4
      ],
      "2025-09": [
        19,
        6,
        4,
        2,
        8,
        3,
        4,
        5,
        4,
        3,
        3,
        0
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Probabilistic Model Checking and Autonomy",
          "year": "2021-11",
          "abstract": "Design and control of autonomous systems that operate in uncertain or\nadversarial environments can be facilitated by formal modelling and analysis.\nProbabilistic model checking is a technique to automatically verify, for a\ngiven temporal logic specification, that a system model satisfies the\nspecification, as well as to synthesise an optimal strategy for its control.\nThis method has recently been extended to multi-agent systems that exhibit\ncompetitive or cooperative behaviour modelled via stochastic games and\nsynthesis of equilibria strategies. In this paper, we provide an overview of\nprobabilistic model checking, focusing on models supported by the PRISM and\nPRISM-games model checkers. This includes fully observable and partially\nobservable Markov decision processes, as well as turn-based and concurrent\nstochastic games, together with associated probabilistic temporal logics. We\ndemonstrate the applicability of the framework through illustrative examples\nfrom autonomous systems. Finally, we highlight research challenges and suggest\ndirections for future work in this area.",
          "arxiv_id": "2111.10630v1"
        },
        {
          "title": "LTLf Synthesis on Probabilistic Systems",
          "year": "2020-09",
          "abstract": "Many systems are naturally modeled as Markov Decision Processes (MDPs),\ncombining probabilities and strategic actions. Given a model of a system as an\nMDP and some logical specification of system behavior, the goal of synthesis is\nto find a policy that maximizes the probability of achieving this behavior. A\npopular choice for defining behaviors is Linear Temporal Logic (LTL). Policy\nsynthesis on MDPs for properties specified in LTL has been well studied. LTL,\nhowever, is defined over infinite traces, while many properties of interest are\ninherently finite. Linear Temporal Logic over finite traces (LTLf) has been\nused to express such properties, but no tools exist to solve policy synthesis\nfor MDP behaviors given finite-trace properties. We present two algorithms for\nsolving this synthesis problem: the first via reduction of LTLf to LTL and the\nsecond using native tools for LTLf. We compare the scalability of these two\napproaches for synthesis and show that the native approach offers better\nscalability compared to existing automaton generation tools for LTL.",
          "arxiv_id": "2009.10883v1"
        },
        {
          "title": "Rational Verification for Probabilistic Systems",
          "year": "2021-07",
          "abstract": "Rational verification is the problem of determining which temporal logic\nproperties will hold in a multi-agent system, under the assumption that agents\nin the system act rationally, by choosing strategies that collectively form a\ngame-theoretic equilibrium. Previous work in this area has largely focussed on\ndeterministic systems. In this paper, we develop the theory and algorithms for\nrational verification in probabilistic systems. We focus on concurrent\nstochastic games (CSGs), which can be used to model uncertainty and randomness\nin complex multi-agent environments. We study the rational verification problem\nfor both non-cooperative games and cooperative games in the qualitative\nprobabilistic setting. In the former case, we consider LTL properties satisfied\nby the Nash equilibria of the game and in the latter case LTL properties\nsatisfied by the core. In both cases, we show that the problem is\n2EXPTIME-complete, thus not harder than the much simpler verification problem\nof model checking LTL properties of systems modelled as Markov decision\nprocesses (MDPs).",
          "arxiv_id": "2107.09119v2"
        }
      ],
      "1": [
        {
          "title": "First-Order Model Checking on Monadically Stable Graph Classes",
          "year": "2023-11",
          "abstract": "A graph class $\\mathscr{C}$ is called monadically stable if one cannot\ninterpret, in first-order logic, arbitrary large linear orders in colored\ngraphs from $\\mathscr{C}$. We prove that the model checking problem for\nfirst-order logic is fixed-parameter tractable on every monadically stable\ngraph class. This extends the results of [Grohe, Kreutzer, and Siebertz; J. ACM\n'17] for nowhere dense classes and of [Dreier, M\\\"ahlmann, and Siebertz; STOC\n'23] for structurally nowhere dense classes to all monadically stable classes.\n  As a complementary hardness result, we prove that for every hereditary graph\nclass $\\mathscr{C}$ that is edge-stable (excludes some half-graph as a\nsemi-induced subgraph) but not monadically stable, first-order model checking\nis $\\mathrm{AW}[*]$-hard on $\\mathscr{C}$, and $\\mathrm{W}[1]$-hard when\nrestricted to existential sentences. This confirms, in the special case of\nedge-stable classes, an on-going conjecture that the notion of monadic NIP\ndelimits the tractability of first-order model checking on hereditary classes\nof graphs.\n  For our tractability result, we first prove that monadically stable graph\nclasses have almost linear neighborhood complexity. Using this, we construct\nsparse neighborhood covers for monadically stable classes, which provides the\nmissing ingredient for the algorithm of [Dreier, M\\\"ahlmann, and Siebertz; STOC\n'23]. The key component of this construction is the usage of orders with low\ncrossing number [Welzl; SoCG '88], a tool from the area of range queries.\n  For our hardness result, we prove a new characterization of monadically\nstable graph classes in terms of forbidden induced subgraphs. We then use this\ncharacterization to show that in hereditary classes that are edge-stable but\nnot monadically stable, one can effectively interpret the class of all graphs\nusing only existential formulas.",
          "arxiv_id": "2311.18740v1"
        },
        {
          "title": "Canonical decompositions in monadically stable and bounded shrubdepth graph classes",
          "year": "2023-03",
          "abstract": "We use model-theoretic tools originating from stability theory to derive a\nresult we call the Finitary Substitute Lemma, which intuitively says the\nfollowing. Suppose we work in a stable graph class C, and using a first-order\nformula {\\phi} with parameters we are able to define, in every graph G in C, a\nrelation R that satisfies some hereditary first-order assertion {\\psi}. Then we\nare able to find a first-order formula {\\phi}' that has the same property, but\nadditionally is finitary: there is finite bound k such that in every graph G in\nC, different choices of parameters give only at most k different relations R\nthat can be defined using {\\phi}'. We use the Finitary Substitute Lemma to\nderive two corollaries about the existence of certain canonical decompositions\nin classes of well-structured graphs.\n  - We prove that in the Splitter game, which characterizes nowhere dense graph\nclasses, and in the Flipper game, which characterizes monadically stable graph\nclasses, there is a winning strategy for Splitter, respectively Flipper, that\ncan be defined in first-order logic from the game history. Thus, the strategy\nis canonical.\n  - We show that for any fixed graph class C of bounded shrubdepth, there is an\nO(n^2)-time algorithm that given an n-vertex graph G in C, computes in an\nisomorphism-invariant way a structure H of bounded treedepth in which G can be\ninterpreted. A corollary of this result is an O(n^2)-time isomorphism test and\ncanonization algorithm for any fixed class of bounded shrubdepth.",
          "arxiv_id": "2303.01473v1"
        },
        {
          "title": "Flip-Breakability: A Combinatorial Dichotomy for Monadically Dependent Graph Classes",
          "year": "2024-03",
          "abstract": "A conjecture in algorithmic model theory predicts that the model-checking\nproblem for first-order logic is fixed-parameter tractable on a hereditary\ngraph class if and only if the class is monadically dependent. Originating in\nmodel theory, this notion is defined in terms of logic, and encompasses nowhere\ndense classes, monadically stable classes, and classes of bounded twin-width.\nWorking towards this conjecture, we provide the first two combinatorial\ncharacterizations of monadically dependent graph classes. This yields the\nfollowing dichotomy.\n  On the structure side, we characterize monadic dependence by a\nRamsey-theoretic property called flip-breakability. This notion generalizes the\nnotions of uniform quasi-wideness, flip-flatness, and bounded grid rank, which\ncharacterize nowhere denseness, monadic stability, and bounded twin-width,\nrespectively, and played a key role in their respective model checking\nalgorithms. Natural restrictions of flip-breakability additionally characterize\nbounded treewidth and cliquewidth and bounded treedepth and shrubdepth.\n  On the non-structure side, we characterize monadic dependence by explicitly\nlisting few families of forbidden induced subgraphs. This result is analogous\nto the characterization of nowhere denseness via forbidden subdivided cliques,\nand allows us to resolve one half of the motivating conjecture: First-order\nmodel checking is AW[$*$]-hard on every hereditary graph class that is\nmonadically independent. The result moreover implies that hereditary graph\nclasses which are small, have almost bounded twin-width, or have almost bounded\nflip-width, are monadically dependent.\n  Lastly, we lift our result to also obtain a combinatorial dichotomy in the\nmore general setting of monadically dependent classes of binary structures.",
          "arxiv_id": "2403.15201v2"
        }
      ],
      "2": [
        {
          "title": "A biequivalence of path categories and axiomatic Martin-LÃ¶f type theories",
          "year": "2025-03",
          "abstract": "The semantics of extensional type theory has an elegant categorical\ndescription: models of Sigma-types and extensional Id-types are biequivalent to\nfinitely complete categories. We establish a similar result for intensional\ntype theories: weak models of Sigma-types and axiomatic Id-types are\nbiequivalent to path categories. These axiomatic Id-types only satisfy\nbeta-reduction rule as a propositional equality, and appear in cubical type\ntheory, as well as axiomatic type theory (type theory without definitional\nequality). Path categories take inspiration from homotopy theory and simplify\nthe structure of type theory using a primitive notion of equivalence. Our\nbiequivalence allows us to turn path categories into actual models of type\ntheory: we turn them into weak models, where substitution is only specified up\nto isomorphism, which we can in turn strictify using the left adjoint\nsplitting. In addition, we introduce a more fine-grained notion: that of a\ndisplay path category, and prove a similar biequivalence. These display path\ncategories still model axiomatic Id-types, but not the intensional notion of\nSigma-types. We show how they can be extended with axiomatic notions of\nSigma-types and Pi-types, allowing us to model axiomatic type theory.",
          "arxiv_id": "2503.15431v1"
        },
        {
          "title": "Directed univalence in simplicial homotopy type theory",
          "year": "2024-07",
          "abstract": "Simplicial type theory extends homotopy type theory with a directed path type\nwhich internalizes the notion of a homomorphism within a type. This concept has\nsignificant applications both within mathematics -- where it allows for\nsynthetic (higher) category theory -- and programming languages -- where it\nleads to a directed version of the structure identity principle. In this work,\nwe construct the first types in simplicial type theory with non-trivial\nhomomorphisms. We extend simplicial type theory with modalities and new\nreasoning principles to obtain triangulated type theory in order to construct\nthe universe of discrete types $\\mathcal{S}$. We prove that homomorphisms in\nthis type correspond to ordinary functions of types i.e., that $\\mathcal{S}$ is\ndirected univalent. The construction of $\\mathcal{S}$ is foundational for both\nof the aforementioned applications of simplicial type theory. We are able to\ndefine several crucial examples of categories and to recover important results\nfrom category theory. Using $\\mathcal{S}$, we are also able to define various\ntypes whose usage is guaranteed to be functorial. These provide the first\ncomplete examples of the proposed directed structure identity principle.",
          "arxiv_id": "2407.09146v1"
        },
        {
          "title": "Internal $\\infty$-Categorical Models of Dependent Type Theory: Towards 2LTT Eating HoTT",
          "year": "2020-09",
          "abstract": "Using dependent type theory to formalise the syntax of dependent type theory\nis a very active topic of study and goes under the name of \"type theory eating\nitself\" or \"type theory in type theory.\" Most approaches are at least loosely\nbased on Dybjer's categories with families (CwF's) and come with a type CON of\ncontexts, a type family TY indexed over it modelling types, and so on. This\nworks well in versions of type theory where the principle of unique identity\nproofs (UIP) holds. In homotopy type theory (HoTT) however, it is a\nlong-standing and frequently discussed open problem whether the type theory\n\"eats itself\" and can serve as its own interpreter. The fundamental underlying\ndifficulty seems to be that categories are not suitable to capture a type\ntheory in the absence of UIP.\n  In this paper, we develop a notion of $\\infty$-categories with families\n($\\infty$-CwF's). The approach to higher categories used relies on the\npreviously suggested semi-Segal types, with a new construction of identity\nsubstitutions that allow for both univalent and non-univalent variations. The\ntype-theoretic universe as well as the internalised syntax are models, although\nit remains a conjecture that the latter is initial. To circumvent the known\nunsolved problem of constructing semisimplicial types, the definition is\npresented in two-level type theory (2LTT).\n  Apart from introducing $\\infty$-CwF's, the paper explains the shortcomings of\n1-categories in type theory without UIP as well as the difficulties of and\napproaches to internal higher-dimensional categories.",
          "arxiv_id": "2009.01883v2"
        }
      ],
      "3": [
        {
          "title": "Towards Reliable Neural Specifications",
          "year": "2022-10",
          "abstract": "Having reliable specifications is an unavoidable challenge in achieving\nverifiable correctness, robustness, and interpretability of AI systems.\nExisting specifications for neural networks are in the paradigm of data as\nspecification. That is, the local neighborhood centering around a reference\ninput is considered to be correct (or robust). While existing specifications\ncontribute to verifying adversarial robustness, a significant problem in many\nresearch domains, our empirical study shows that those verified regions are\nsomewhat tight, and thus fail to allow verification of test set inputs, making\nthem impractical for some real-world applications. To this end, we propose a\nnew family of specifications called neural representation as specification,\nwhich uses the intrinsic information of neural networks - neural activation\npatterns (NAPs), rather than input data to specify the correctness and/or\nrobustness of neural network predictions. We present a simple statistical\napproach to mining neural activation patterns. To show the effectiveness of\ndiscovered NAPs, we formally verify several important properties, such as\nvarious types of misclassifications will never happen for a given NAP, and\nthere is no ambiguity between different NAPs. We show that by using NAP, we can\nverify a significant region of the input space, while still recalling 84% of\nthe data on MNIST. Moreover, we can push the verifiable bound to 10 times\nlarger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be\nused as a more reliable and extensible specification for neural network\nverification.",
          "arxiv_id": "2210.16114v5"
        },
        {
          "title": "Set-Based Training for Neural Network Verification",
          "year": "2024-01",
          "abstract": "Neural networks are vulnerable to adversarial attacks, i.e., small input\nperturbations can significantly affect the outputs of a neural network.\nTherefore, to ensure safety of neural networks in safety-critical environments,\nthe robustness of a neural network must be formally verified against input\nperturbations, e.g., from noisy sensors. To improve the robustness of neural\nnetworks and thus simplify the formal verification, we present a novel\nset-based training procedure in which we compute the set of possible outputs\ngiven the set of possible inputs and compute for the first time a gradient set,\ni.e., each possible output has a different gradient. Therefore, we can directly\nreduce the size of the output enclosure by choosing gradients toward its\ncenter. Small output enclosures increase the robustness of a neural network\nand, at the same time, simplify its formal verification. The latter benefit is\ndue to the fact that a larger size of propagated sets increases the\nconservatism of most verification methods. Our extensive evaluation\ndemonstrates that set-based training produces robust neural networks with\ncompetitive performance, which can be verified using fast (polynomial-time)\nverification algorithms due to the reduced output set.",
          "arxiv_id": "2401.14961v4"
        },
        {
          "title": "Neural Logic Reasoning",
          "year": "2020-08",
          "abstract": "Recent years have witnessed the success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of cognitive reasoning. However, the concrete ability of\nreasoning is critical to many theoretical and practical problems. On the other\nhand, traditional symbolic reasoning methods do well in making logical\ninference, but they are mostly hard rule-based reasoning, which limits their\ngeneralization ability to different tasks since difference tasks may require\ndifferent rules. Both reasoning and generalization ability are important for\nprediction tasks such as recommender systems, where reasoning provides strong\nconnection between user history and target items for accurate prediction, and\ngeneralization helps the model to draw a robust user portrait over noisy\ninputs.\n  In this paper, we propose Logic-Integrated Neural Network (LINN) to integrate\nthe power of deep learning and logic reasoning. LINN is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations such as AND, OR, NOT as neural\nmodules, and conducts propositional logical reasoning through the network for\ninference. Experiments on theoretical task show that LINN achieves significant\nperformance on solving logical equations and variables. Furthermore, we test\nour approach on the practical task of recommendation by formulating the task\ninto a logical inference problem. Experiments show that LINN significantly\noutperforms state-of-the-art recommendation models in Top-K recommendation,\nwhich verifies the potential of LINN in practice.",
          "arxiv_id": "2008.09514v1"
        }
      ],
      "4": [
        {
          "title": "Wijesekera-style constructive modal logics",
          "year": "2022-10",
          "abstract": "We define a family of propositional constructive modal logics corresponding\neach to a different classical modal system. The logics are defined in the style\nof Wijesekera's constructive modal logic, and are both proof-theoretically and\nsemantically motivated. On the one hand, they correspond to the\nsingle-succedent restriction of standard sequent calculi for classical modal\nlogics. On the other hand, they are obtained by incorporating the\nhereditariness of intuitionistic Kripke models into the classical satisfaction\nclauses for modal formulas. We show that, for the considered classical logics,\nthe proof-theoretical and the semantical approach return the same constructive\nsystems.",
          "arxiv_id": "2210.09937v1"
        },
        {
          "title": "Base-extension Semantics for Intuitionistic Modal Logics",
          "year": "2025-07",
          "abstract": "The proof theory and semantics of intuitionistic modal logics have been\nstudied by Simpson in terms of Prawitz-style labelled natural deduction systems\nand Kripke models. An alternative to model-theoretic semantics is provided by\nproof-theoretic semantics, which is a logical realization of inferentialism, in\nwhich the meaning of constructs is understood through their use. The key idea\nin proof-theoretic semantics is that of a base of atomic rules, all of which\nrefer only to propositional atoms and involve no logical connectives. A\nspecific form of proof-theoretic semantics, known as base-extension semantics\n(B-eS), is concerned with the validity of formulae and provides a direct\ncounterpart to Kripke models that is grounded in the provability of atomic\nformulae in a base. We establish, systematically, B-eS for Simpson's\nintuitionistic modal logics and, also systematically, obtain soundness and\ncompleteness theorems with respect to Simpson's natural deduction systems.",
          "arxiv_id": "2507.06834v1"
        },
        {
          "title": "Uniform Lyndon interpolation for intuitionistic monotone modal logic",
          "year": "2022-08",
          "abstract": "In this paper we show that the intuitionistic monotone modal logic\n$\\mathsf{iM}$ has the uniform Lyndon interpolation property (ULIP). The logic\n$\\mathsf{iM}$ is a non-normal modal logic on an intuitionistic basis, and the\nproperty ULIP is a strengthening of interpolation in which the interpolant\ndepends only on the premise or the conclusion of an implication, respecting the\npolarities of the propositional variables. Our method to prove ULIP yields\nexplicit uniform interpolants and makes use of a terminating sequent calculus\nfor $\\mathsf{iM}$ that we have developed for this purpose. As far as we know,\nthe results that $\\mathsf{iM}$ has ULIP and a terminating sequent calculus are\nthe first of their kind for an intuitionistic non-normal modal logic. However,\nrather than proving these particular results, our aim is to show the\nflexibility of the constructive proof-theoretic method that we use for proving\nULIP. It has been developed over the last few years and has been applied to\nsubstructural, intermediate, classical (non-)normal modal and intuitionistic\nnormal modal logics. In light of these results, intuitionistic non-normal modal\nlogics seem a natural next class to try to apply the method to, and we take the\nfirst step in that direction in this paper.",
          "arxiv_id": "2208.04607v1"
        }
      ],
      "5": [
        {
          "title": "Flexible Refinement Proofs in Separation Logic",
          "year": "2021-10",
          "abstract": "Refinement transforms an abstract system model into a concrete, executable\nprogram, such that properties established for the abstract model carry over to\nthe concrete implementation. Refinement has been used successfully in the\ndevelopment of substantial verified systems. Nevertheless, existing refinement\ntechniques have limitations that impede their practical usefulness. Some\ntechniques generate executable code automatically, which generally leads to\nimplementations with sub-optimal performance. Others employ bottom-up program\nverification to reason about efficient implementations, but impose strict\nrequirements on the structure of the code, the structure of the refinement\nproofs, as well as the employed verification logic and tools.\n  In this paper, we present a novel refinement technique that removes these\nlimitations. Our technique uses separation logic to reason about efficient\nconcurrent implementations. It prescribes only a loose coupling between an\nabstract model and the concrete implementation. It thereby supports a wide\nrange of program structures, data representations, and proof structures. We\nmake only minimal assumptions about the underlying program logic, which allows\nour technique to be used in combination with a wide range of logics and to be\nautomated using off-the-shelf separation logic verifiers. We formalize the\ntechnique, prove the central trace inclusion property, and demonstrate its\nusefulness on several case studies.",
          "arxiv_id": "2110.13559v1"
        },
        {
          "title": "A Formal CHERI-C Semantics for Verification",
          "year": "2022-11",
          "abstract": "CHERI-C extends the C programming language by adding hardware capabilities,\nensuring a certain degree of memory safety while remaining efficient.\nCapabilities can also be employed for higher-level security measures, such as\nsoftware compartmentalization, that have to be used correctly to achieve the\ndesired security guarantees. As the extension changes the semantics of C, new\ntheories and tooling are required to reason about CHERI-C code and verify\ncorrectness. In this work, we present a formal memory model that provides a\nmemory semantics for CHERI-C programs. We present a generalised theory with\nrich properties suitable for verification and potentially other types of\nanalyses. Our theory is backed by an Isabelle/HOL formalisation that also\ngenerates an OCaml executable instance of the memory model. The verified and\nextracted code is then used to instantiate the parametric Gillian program\nanalysis framework, with which we can perform concrete execution of CHERI-C\nprograms. The tool can run a CHERI-C test suite, demonstrating the correctness\nof our tool, and catch a good class of safety violations that the CHERI\nhardware might miss.",
          "arxiv_id": "2211.07511v2"
        },
        {
          "title": "Semi-Automated Modular Formal Verification of Critical Software: Liveness and Completeness Thresholds",
          "year": "2024-03",
          "abstract": "In this dissertation we describe two contributions to the state of the art in\nreasoning about liveness and safety, respectively.\n  Programs for multiprocessor machines commonly perform busy waiting for\nsynchronization. We propose the first separation logic for modularly verifying\ntermination of such programs under fair scheduling. Our logic requires the\nproof author to associate a ghost signal with each busy-waiting loop and allows\nsuch loops to iterate while their corresponding signal $s$ is not set. The\nproof author further has to define a well-founded order on signals and to prove\nthat if the looping thread holds an obligation to set a signal $s'$, then $s'$\nis ordered above $s$. By using conventional shared state invariants to\nassociate the state of ghost signals with the state of data structures,\nprograms busy-waiting for arbitrary conditions over arbitrary data structures\ncan be verified.\n  Moreover, we present the first study of completeness thresholds for bounded\nmemory safety proofs. Specifically, we consider heap-manipulating programs that\niterate over arrays without allocating or freeing memory. In this setting, we\npresent the first notion of completeness thresholds for program verification\nwhich reduce unbounded memory safety proofs to bounded ones. Furthermore, we\ndemonstrate that we can characterise completeness thresholds for simple classes\nof array traversing programs. Finally, we suggest avenues of research to scale\nthis technique theoretically, i.e., to larger classes of programs (heap\nmanipulation, tree-like data structures), and practically by highlighting\nautomation opportunities.",
          "arxiv_id": "2403.00934v2"
        }
      ],
      "6": [
        {
          "title": "Answering Counting Queries over DL-Lite Ontologies",
          "year": "2020-09",
          "abstract": "Ontology-mediated query answering (OMQA) is a promising approach to data\naccess and integration that has been actively studied in the knowledge\nrepresentation and database communities for more than a decade. The vast\nmajority of work on OMQA focuses on conjunctive queries, whereas more\nexpressive queries that feature counting or other forms of aggregation remain\nlargely unex-plored. In this paper, we introduce a general form of counting\nquery, relate it to previous proposals, and study the complexity of answering\nsuch queries in the presence of DL-Lite ontologies. As it follows from existing\nwork that query answering is intractable and often of high complexity, we\nconsider some practically relevant restrictions, for which we establish\nimproved complexity bounds.",
          "arxiv_id": "2009.09801v1"
        },
        {
          "title": "Temporal Conjunctive Query Answering in the Extended DL-Lite Family",
          "year": "2020-03",
          "abstract": "Ontology-based query answering (OBQA) augments classical query answering in\ndatabases by domain knowledge encoded in an ontology. Systems for OBQA use the\nontological knowledge to infer new information that is not explicitly given in\nthe data. Moreover, they usually employ the open-world assumption, which means\nthat knowledge that is not stated explicitly in the data and that is not\ninferred is not assumed to be true or false. Classical OBQA however considers\nonly a snapshot of the data, which means that information about the temporal\nevolution of the data is not used for reasoning and hence lost. We investigate\ntemporal conjunctive queries (TCQs) that allow to access temporal data through\nclassical ontologies. In particular, we study combined and data complexity of\nTCQ entailment for ontologies written in description logics from the extended\nDL-Lite family. Many of these logics allow for efficient reasoning in the\natemporal setting and are successfully applied in practice. We show\ncomprehensive complexity results for temporal reasoning with these logics.",
          "arxiv_id": "2003.09508v1"
        },
        {
          "title": "Finding Good Proofs for Answers to Conjunctive Queries Mediated by Lightweight Ontologies (Technical Report)",
          "year": "2022-06",
          "abstract": "In ontology-mediated query answering, access to incomplete data sources is\nmediated by a conceptual layer constituted by an ontology. To correctly compute\nanswers to queries, it is necessary to perform complex reasoning over the\nconstraints expressed by the ontology. In the literature, there exists a\nmultitude of techniques incorporating the ontological knowledge into queries.\nHowever, few of these approaches were designed for comprehensibility of the\nquery answers. In this article, we try to bridge these two qualities by\nadapting a proof framework originally applied to axiom entailment for\nconjunctive query answering. We investigate the data and combined complexity of\ndetermining the existence of a proof below a given quality threshold, which can\nbe measured in different ways. By distinguishing various parameters such as the\nshape of a query, we obtain an overview of the complexity of this problem for\nthe lightweight ontology languages DL-Lite_R and EL, and also have a brief look\nat temporal query answering.",
          "arxiv_id": "2206.09758v2"
        }
      ],
      "7": [
        {
          "title": "Learning What Others Know",
          "year": "2021-09",
          "abstract": "We propose a number of powerful dynamic-epistemic logics for multi-agent\ninformation sharing and acts of publicly or privately accessing other agents'\ninformation databases. The static base of our logics is obtained by adding to\nstandard epistemic logic comparative epistemic assertions, that can express\nepistemic superiority between groups or individuals, as well as a common\ndistributed knowledge operator (that combines features of both common knowledge\nand distributed knowledge). On the dynamic side, we introduce actions by which\nepistemic superiority can be acquired: \"sharing all one knows\" (by e.g. giving\naccess to one's information database to all or some of the other agents), as\nwell as more complex informational events, such as hacking. We completely\naxiomatize several such logics and prove their decidability.",
          "arxiv_id": "2109.07255v1"
        },
        {
          "title": "Logic of Awareness for Nested Knowledge",
          "year": "2024-02",
          "abstract": "Reasoning abilities of human beings are limited. Logics that treat logical\ninference for human knowledge should reflect these limited abilities. Logic of\nawareness is one of those logics. In the logic, what an agent with a limited\nreasoning ability actually knows at a given moment (explicit knowledge) is\ndistinguished from the ideal knowledge that an agent obtains by performing all\npossible inferences with what she already knows (implicit knowledge). This\npaper proposes a logic for explicit knowledge. In particular, we focus more on\nnested explicit knowledge, which means another agent's knowledge that an agent\nactually knows at a given moment. We develope a new formalization of two ideas\nand propose Kripke-style semantics. The first idea is the effect on an agent's\nreasoning ability by a state of an agent's awareness. We incorporate a relation\non possible worlds called an indistinguishable relation to represent ignorance\ndue to lack of awareness. The second idea is a state of each agent's awareness\nin the other agent's mind. We incorporate a non-empty finite sequence of agents\ncalled \\textit{a chain of belief for awareness}. Our logic is called Awareness\nLogic with Partitions and Chains (ALPC). Employing an example, we show how\nnested explicit knowledge is formalized with our logic. Thereafter, we propose\nthe proof system and prove the completeness. Finally, we discuss directions for\nextending and applying our logic and conclude. Our logic offers a foundation\nfor a formal representation of human knowledge. We expect that the logic can be\napplied to computer science and game theory by describing and analyzing\nstrategic behavior in a game and practical agent communication.",
          "arxiv_id": "2402.08282v1"
        },
        {
          "title": "Epistemic Logic over Similarity Graphs: Common, Distributed and Mutual Knowledge",
          "year": "2023-09",
          "abstract": "In this paper, we delve into the study of epistemic logics, interpreted\nthrough similarity models based on weighted graphs. We explore eight languages\nthat extend the traditional epistemic language by incorporating modalities of\ncommon, distributed, and mutual knowledge. The concept of individual knowledge\nis redefined under these similarity models. It is no longer just a matter of\npersonal knowledge, but is now enriched and understood as knowledge under the\nindividual's epistemic ability. Common knowledge is presented as higher-order\nknowledge that is universally known to any degree, a definition that aligns\nwith existing literature. We reframe distributed knowledge as a form of\nknowledge acquired by collectively leveraging the abilities of a group of\nagents. In contrast, mutual knowledge is defined as the knowledge obtained\nthrough the shared abilities of a group. We then focus on the resulting logics,\nexamining their relative expressivity, semantic correspondence to the classical\nepistemic logic, proof systems and the computational complexity associated with\nthe model checking problem and the satisfiability/validity problem. This paper\noffers significant insights into the logical analysis and understanding of\nthese enriched forms of knowledge, contributing to the broader discourse on\nepistemic logic.",
          "arxiv_id": "2310.00264v1"
        }
      ],
      "8": [
        {
          "title": "SubgoalXL: Subgoal-based Expert Learning for Theorem Proving",
          "year": "2024-08",
          "abstract": "Formal theorem proving, a field at the intersection of mathematics and\ncomputer science, has seen renewed interest with advancements in large language\nmodels (LLMs). This paper introduces SubgoalXL, a novel approach that\nsynergizes subgoal-based proofs with expert learning to enhance LLMs'\ncapabilities in formal theorem proving within the Isabelle environment.\nSubgoalXL addresses two critical challenges: the scarcity of specialized\nmathematics and theorem-proving data, and the need for improved multi-step\nreasoning abilities in LLMs. By optimizing data efficiency and employing\nsubgoal-level supervision, SubgoalXL extracts richer information from limited\nhuman-generated proofs. The framework integrates subgoal-oriented proof\nstrategies with an expert learning system, iteratively refining formal\nstatement, proof, and subgoal generators. Leveraging the Isabelle environment's\nadvantages in subgoal-based proofs, SubgoalXL achieves a new state-of-the-art\nperformance of 56.1\\% in Isabelle on the standard miniF2F dataset, marking an\nabsolute improvement of 4.9\\%. Notably, SubgoalXL successfully solves 41 AMC12,\n9 AIME, and 3 IMO problems from miniF2F. These results underscore the\neffectiveness of maximizing limited data utility and employing targeted\nguidance for complex reasoning in formal theorem proving, contributing to the\nongoing advancement of AI reasoning capabilities. The implementation is\navailable at \\url{https://github.com/zhaoxlpku/SubgoalXL}.",
          "arxiv_id": "2408.11172v1"
        },
        {
          "title": "Generating Millions Of Lean Theorems With Proofs By Exploring State Transition Graphs",
          "year": "2025-02",
          "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\ngenerating mathematical proofs. However, a persistent challenge is that LLMs\noccasionally make mistakes, while even a minor mistake can invalidate an entire\nproof. Proof assistants like Lean offer a great remedy. They are designed for\nverifying each step of a proof in a formal language, and in recent years\nresearchers have created AI models to generate proofs in their languages.\nHowever, the scarcity of large-scale datasets of Lean proofs restrict the\nperformance of such Automated Theorem Proving (ATP) models.\n  We developed LeanNavigator, a novel method for generating a large-scale\ndataset of Lean theorems and proofs by finding new ways to prove existing Lean\ntheorems. By leveraging an interactive Lean client and an efficient method for\nproof step generation, LeanNavigator efficiently produces new theorems with\ncorresponding proofs. Applying this approach to Mathlib4, we generated 4.7\nmillion theorems totaling 1 billion tokens, surpassing previous datasets by\nmore than an order of magnitude. Using this extensive dataset, we trained an AI\nmodel that outperforms the state-of-the-art ReProver model in theorem-proving\ntasks. These results confirm our hypothesis and demonstrate the critical role\nof large datasets in improving the performance of automated theorem provers.",
          "arxiv_id": "2503.04772v1"
        },
        {
          "title": "Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean",
          "year": "2024-04",
          "abstract": "Neural theorem proving combines large language models (LLMs) with proof\nassistants such as Lean, where the correctness of formal proofs can be\nrigorously verified, leaving no room for hallucination. With existing neural\ntheorem provers pretrained on a fixed collection of data and offering valuable\nsuggestions at times, it is challenging for them to continually prove novel\ntheorems in a fully autonomous mode, where human insights may be critical. In\nthis paper, we explore LLMs as copilots that assist humans in proving theorems.\nWe introduce Lean Copilot, a general framework for running LLM inference\nnatively in Lean. It enables programmers to build various LLM-based proof\nautomation tools that integrate seamlessly into the workflow of Lean users.\nLean users can use our pretrained models or bring their own ones that run\neither locally (with or without GPUs) or on the cloud. Using Lean Copilot, we\nbuild LLM-based tools that suggest proof steps, complete proof goals, and\nselect relevant premises. Experimental results on the Mathematics in Lean\ntextbook demonstrate the effectiveness of our method compared to existing\nrule-based proof automation in Lean (aesop). When assisting humans, Lean\nCopilot requires only 2.08 manually-entered proof steps on average (3.86\nrequired by aesop); when automating the theorem proving process, Lean Copilot\nautomates 74.2% proof steps on average, 85% better than aesop (40.1%). We open\nsource all code and artifacts under a permissive MIT license to facilitate\nfurther research.",
          "arxiv_id": "2404.12534v3"
        }
      ],
      "9": [
        {
          "title": "Quantum Recursive Programming with Quantum Case Statements",
          "year": "2023-11",
          "abstract": "We introduce a novel scheme of quantum recursive programming, in which large\nunitary transformations, i.e. quantum gates, can be recursively defined using\nquantum case statements, which are quantum counterparts of conditionals and\ncase statements extensively used in classical programming. A simple programming\nlanguage for supporting this kind of quantum recursion is defined, and its\nsemantics is formally described. A series of examples are presented to show\nthat some quantum algorithms can be elegantly written as quantum recursive\nprograms.",
          "arxiv_id": "2311.01725v1"
        },
        {
          "title": "Quantum circuits are just a phase",
          "year": "2025-07",
          "abstract": "Quantum programs today are written at a low level of abstraction - quantum\ncircuits akin to assembly languages - and even advanced quantum programming\nlanguages essentially function as circuit description languages. This state of\naffairs impedes scalability, clarity, and support for higher-level reasoning.\nMore abstract and expressive quantum programming constructs are needed.\n  To this end, we introduce a novel yet simple quantum programming language for\ngenerating unitaries from \"just a phase\"; we combine a (global) phase operation\nthat captures phase shifts with a quantum analogue of the \"if let\" construct\nthat captures subspace selection via pattern matching. This minimal language\nlifts the focus from quantum gates to eigendecomposition, conjugation, and\ncontrolled unitaries; common building blocks in quantum algorithm design.\n  We demonstrate several aspects of the expressive power of our language in\nseveral ways. Firstly, we establish that our representation is universal by\nderiving a universal quantum gate set. Secondly, we show that important quantum\nalgorithms can be expressed naturally and concisely, including Grover's search\nalgorithm, Hamiltonian simulation, Quantum Fourier Transform, Quantum Signal\nProcessing, and the Quantum Eigenvalue Transformation. Furthermore, we give\nclean denotational semantics grounded in categorical quantum mechanics.\nFinally, we implement a prototype compiler that efficiently translates terms of\nour language to quantum circuits, and prove that it is sound with respect to\nthese semantics. Collectively, these contributions show that this construct\noffers a principled and practical step toward more abstract and structured\nquantum programming.",
          "arxiv_id": "2507.11676v1"
        },
        {
          "title": "Quantum First-Order Logics That Capture Logarithmic-Time/Space Quantum Computability",
          "year": "2025-01",
          "abstract": "We introduce a quantum analogue of classical first-order logic (FO) and\ndevelop a theory of quantum first-order logic as a basis of the productive\ndiscussions on the power of logical expressiveness toward quantum computing.\nThe purpose of this work is to logically express \"quantum computation\" by\nintroducing specially-featured quantum connectives and quantum quantifiers that\nquantify fixed-dimensional quantum states. Our approach is founded on the\nrecently introduced recursion-theoretical schematic definitions of time-bounded\nquantum functions, which map finite-dimensional Hilbert spaces to themselves.\nThe quantum first-order logic (QFO) in this work therefore looks quite\ndifferent from the well-known old concept of quantum logic based on lattice\ntheory. We demonstrate that quantum first-order logics possess an ability of\nexpressing bounded-error quantum logarithmic-time computability by the use of\nnew \"functional\" quantum variables. In contrast, an extra inclusion of quantum\ntransitive closure operator helps us characterize quantum logarithmic-space\ncomputability. The same computability can be achieved by the use of different\n\"functional\" quantum variables.",
          "arxiv_id": "2501.12007v1"
        }
      ],
      "10": [
        {
          "title": "Logic Optimization Meets SAT: A Novel Framework for Circuit-SAT Solving",
          "year": "2024-03",
          "abstract": "The Circuit Satisfiability (CSAT) problem, a variant of the Boolean\nSatisfiability (SAT) problem, plays a critical role in integrated circuit\ndesign and verification. However, existing SAT solvers, optimized for\nConjunctive Normal Form (CNF), often struggle with the intrinsic complexity of\ncircuit structures when directly applied to CSAT instances. To address this\nchallenge, we propose a novel preprocessing framework that leverages advanced\nlogic synthesis techniques and a reinforcement learning (RL) agent to optimize\nCSAT problem instances. The framework introduces a cost-customized Look-Up\nTable (LUT) mapping strategy that prioritizes solving efficiency, effectively\ntransforming circuits into simplified forms tailored for SAT solvers. Our\nmethod achieves significant runtime reductions across diverse industrial-scale\nCSAT benchmarks, seamlessly integrating with state-of-the-art SAT solvers.\nExtensive experimental evaluations demonstrate up to 63\\% reduction in solving\ntime compared to conventional approaches, highlighting the potential of\nEDA-driven innovations to advance SAT-solving capabilities.",
          "arxiv_id": "2403.19446v2"
        },
        {
          "title": "Disjoint Projected Enumeration for SAT and SMT without Blocking Clauses",
          "year": "2024-10",
          "abstract": "All-Solution Satisfiability (AllSAT) and its extension, All-Solution\nSatisfiability Modulo Theories (AllSMT), have become more relevant in recent\nyears, mainly in formal verification and artificial intelligence applications.\nThe goal of these problems is the enumeration of all satisfying assignments of\na formula (for SAT and SMT problems, respectively), making them useful for test\ngeneration, model checking, and probabilistic inference. Nevertheless,\ntraditional AllSAT algorithms face significant computational challenges due to\nthe exponential growth of the search space and inefficiencies caused by\nblocking clauses, which cause memory blowups and degrade unit propagation\nperformances in the long term. This paper presents two novel solvers:\ntabularAllSAT, a projected AllSAT solver, and tabularAllSMT, a projected AllSMT\nsolver. Both solvers combine Conflict-Driven Clause Learning (CDCL) with\nchronological backtracking to improve efficiency while ensuring disjoint\nenumeration. To retrieve compact partial assignments we propose a novel\naggressive implicant shrinking algorithm, compatible with chronological\nbacktracking, to minimize the number of partial assignments, reducing overall\nsearch complexity. Furthermore, we extend the solver framework to handle\nprojected enumeration and SMT formulas effectively and efficiently, adapting\nthe baseline framework to integrate theory reasoning and the distinction\nbetween important and non-important variables. An extensive experimental\nevaluation demonstrates the superiority of our approach compared to\nstate-of-the-art solvers, particularly in scenarios requiring projection and\nSMT-based reasoning.",
          "arxiv_id": "2410.18707v2"
        },
        {
          "title": "Local Search For Satisfiability Modulo Integer Arithmetic Theories",
          "year": "2022-11",
          "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of deciding the\nsatisfiability of a formula with respect to certain background first order\ntheories. In this paper, we focus on Satisfiablity Modulo Integer Arithmetic,\nwhich is referred to as SMT(IA), including both linear and non-linear integer\narithmetic theories. Dominant approaches to SMT rely on calling a CDCL-based\nSAT solver, either in a lazy or eager favor. Local search, a competitive\napproach to solving combinatorial problems including SAT, however, has not been\nwell studied for SMT. We develop the first local search algorithm for SMT(IA)\nby directly operating on variables, breaking through the traditional framework.\nWe propose a local search framework by considering the distinctions between\nBoolean and integer variables. Moreover, we design a novel operator and scoring\nfunctions tailored for integer arithmetic, as well as a two-level operation\nselection heuristic. Putting these together, we develop a local search SMT(IA)\nsolver called LS-IA. Experiments are carried out to evaluate LS-IA on\nbenchmarks from SMTLIB. The results show that LS-IA is competitive and\ncomplementary with state-of-the-art SMT solvers, and performs particularly well\non those formulae with only integer variables. A simple sequential portfolio\nwith Z3 improves the state-of-the-art on satisfiable benchmark sets from\nSMT-LIB.",
          "arxiv_id": "2211.10219v3"
        }
      ],
      "11": [
        {
          "title": "Extending Answer Set Programming with Rational Numbers",
          "year": "2023-12",
          "abstract": "Answer Set Programming (ASP) is a widely used declarative programming\nparadigm that has shown great potential in solving complex computational\nproblems. However, the inability to natively support non-integer arithmetic has\nbeen highlighted as a major drawback in real-world applications. This feature\nis crucial to accurately model and manage real-world data and information as\nemerged in various contexts, such as the smooth movement of video game\ncharacters, the 3D movement of mechanical arms, and data streamed by sensors.\nNevertheless, extending ASP in this direction, without affecting its\ndeclarative nature and its well-defined semantics, poses non-trivial\nchallenges; thus, no ASP system is able to reason natively with non-integer\ndomains. Indeed, the widespread floating-point arithmetic is not applicable to\nthe ASP case, as the reproducibility of results cannot be guaranteed and the\nsemantics of an ASP program would not be uniquely and declaratively determined,\nregardless of the employed machine or solver. To overcome such limitations and\nin the realm of pure ASP, this paper proposes an extension of ASP in which\nnon-integers are approximated to rational numbers, fully granting\nreproducibility and declarativity. We provide a well-defined semantics for the\nASP-Core-2 standard extended with rational numbers and an implementation\nthereof. We hope this work could serve as a stepping stone towards a more\nexpressive and versatile ASP language that can handle a broader range of\nreal-world problems.",
          "arxiv_id": "2312.04249v1"
        },
        {
          "title": "Omission-based Abstraction for Answer Set Programs",
          "year": "2020-04",
          "abstract": "Abstraction is a well-known approach to simplify a complex problem by\nover-approximating it with a deliberate loss of information. It was not\nconsidered so far in Answer Set Programming (ASP), a convenient tool for\nproblem solving. We introduce a method to automatically abstract ASP programs\nthat preserves their structure by reducing the vocabulary while ensuring an\nover-approximation (i.e., each original answer set maps to some abstract answer\nset). This allows for generating partial answer set candidates that can help\nwith approximation of reasoning. Computing the abstract answer sets is\nintuitively easier due to a smaller search space, at the cost of encountering\nspurious answer sets. Faithful (non-spurious) abstractions may be used to\nrepresent projected answer sets and to guide solvers in answer set\nconstruction. For dealing with spurious answer sets, we employ an ASP debugging\napproach to help with abstraction refinement, which determines atoms as badly\nomitted and adds them back in the abstraction. As a show case, we apply\nabstraction to explain unsatisfiability of ASP programs in terms of blocker\nsets, which are the sets of atoms such that abstraction to them preserves\nunsatisfiability. Their usefulness is demonstrated by experimental results.",
          "arxiv_id": "2004.01410v1"
        },
        {
          "title": "A framework for Conditional Reasoning in Answer Set Programming",
          "year": "2025-06",
          "abstract": "In this paper we introduce a Conditional Answer Set Programming framework\n(Conditional ASP) for the definition of conditional extensions of Answer Set\nProgramming (ASP). The approach builds on a conditional logic with typicality,\nand on the combination of a conditional knowledge base with an ASP program, and\nallows for conditional reasoning over the answer sets of the program. The\nformalism relies on a multi-preferential semantics (and on the KLM preferential\nsemantics, as a special case) to provide an interpretation of conditionals.",
          "arxiv_id": "2506.03997v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T22:18:16Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}