{
  "topics": {
    "data": {
      "0": {
        "name": "0_optimization_algorithm_algorithms_problems",
        "keywords": [
          [
            "optimization",
            0.02565856888289151
          ],
          [
            "algorithm",
            0.02343232317849298
          ],
          [
            "algorithms",
            0.021016144411442034
          ],
          [
            "problems",
            0.01954302153187751
          ],
          [
            "problem",
            0.01781264579995071
          ],
          [
            "objective",
            0.017105132551652916
          ],
          [
            "evolutionary",
            0.012357249193448905
          ],
          [
            "solutions",
            0.012238984687454735
          ],
          [
            "Optimization",
            0.011983624725664532
          ],
          [
            "search",
            0.011536093456199919
          ]
        ],
        "count": 1665
      },
      "1": {
        "name": "1_learning_agents_agent_reinforcement",
        "keywords": [
          [
            "learning",
            0.02062583367068256
          ],
          [
            "agents",
            0.017072148925966604
          ],
          [
            "agent",
            0.01460330605759549
          ],
          [
            "reinforcement",
            0.013067576612453627
          ],
          [
            "reinforcement learning",
            0.012915072197014793
          ],
          [
            "RL",
            0.012898307624404283
          ],
          [
            "policy",
            0.01238102078791219
          ],
          [
            "environments",
            0.01127820853445811
          ],
          [
            "control",
            0.010938776164198477
          ],
          [
            "algorithms",
            0.010615818834482774
          ]
        ],
        "count": 779
      },
      "2": {
        "name": "2_SNNs_Spiking_spiking_SNN",
        "keywords": [
          [
            "SNNs",
            0.0358942372662363
          ],
          [
            "Spiking",
            0.02445982679750723
          ],
          [
            "spiking",
            0.02391702343271318
          ],
          [
            "SNN",
            0.022989397647845827
          ],
          [
            "spike",
            0.019546503211646308
          ],
          [
            "neural",
            0.016803323045844757
          ],
          [
            "Neural",
            0.016449720798222957
          ],
          [
            "temporal",
            0.016446928488827856
          ],
          [
            "networks",
            0.01638563127916211
          ],
          [
            "training",
            0.015470012401138858
          ]
        ],
        "count": 508
      },
      "3": {
        "name": "3_activation_functions_networks_neural",
        "keywords": [
          [
            "activation",
            0.035492949780227434
          ],
          [
            "functions",
            0.03123359623542233
          ],
          [
            "networks",
            0.02921893794507995
          ],
          [
            "neural",
            0.02551420006751617
          ],
          [
            "function",
            0.023643154722296063
          ],
          [
            "activation functions",
            0.02251378493095643
          ],
          [
            "ReLU",
            0.02139884667936517
          ],
          [
            "neural networks",
            0.02085792919250551
          ],
          [
            "network",
            0.018272939087177708
          ],
          [
            "deep",
            0.014594930875081017
          ]
        ],
        "count": 369
      },
      "4": {
        "name": "4_neuromorphic_hardware_energy_computing",
        "keywords": [
          [
            "neuromorphic",
            0.03178683648625783
          ],
          [
            "hardware",
            0.02726720463559645
          ],
          [
            "energy",
            0.01954658158582407
          ],
          [
            "computing",
            0.018149740855717206
          ],
          [
            "neural",
            0.014880959730899545
          ],
          [
            "SNN",
            0.014738847504372894
          ],
          [
            "Neuromorphic",
            0.014304475202171884
          ],
          [
            "devices",
            0.013529889675506735
          ],
          [
            "neuron",
            0.012168287907591958
          ],
          [
            "SNNs",
            0.01201933587653922
          ]
        ],
        "count": 355
      },
      "5": {
        "name": "5_LLMs_LLM_evolutionary_symbolic",
        "keywords": [
          [
            "LLMs",
            0.019980202964015297
          ],
          [
            "LLM",
            0.019967618344584975
          ],
          [
            "evolutionary",
            0.01443704051346393
          ],
          [
            "symbolic",
            0.014410687758676198
          ],
          [
            "regression",
            0.013161666776839562
          ],
          [
            "search",
            0.013019775087297363
          ],
          [
            "programming",
            0.012471817080508854
          ],
          [
            "symbolic regression",
            0.012241889872650112
          ],
          [
            "genetic",
            0.012082900618865564
          ],
          [
            "models",
            0.011963231739216736
          ]
        ],
        "count": 348
      },
      "6": {
        "name": "6_NAS_search_architecture_architectures",
        "keywords": [
          [
            "NAS",
            0.033897606932566354
          ],
          [
            "search",
            0.028064500238961954
          ],
          [
            "architecture",
            0.021350036489714227
          ],
          [
            "architectures",
            0.018127447550348497
          ],
          [
            "Neural",
            0.016992581569876625
          ],
          [
            "Architecture",
            0.016983641239773094
          ],
          [
            "neural",
            0.016965661036811325
          ],
          [
            "network",
            0.01517531675675287
          ],
          [
            "Search",
            0.015030999160890098
          ],
          [
            "performance",
            0.01362273994233996
          ]
        ],
        "count": 325
      },
      "7": {
        "name": "7_adversarial_attacks_data_models",
        "keywords": [
          [
            "adversarial",
            0.029874899765044996
          ],
          [
            "attacks",
            0.018404264520044684
          ],
          [
            "data",
            0.017902448616408783
          ],
          [
            "models",
            0.017243503408908276
          ],
          [
            "image",
            0.016176673395988283
          ],
          [
            "training",
            0.014541249697993208
          ],
          [
            "model",
            0.014044952828412638
          ],
          [
            "generative",
            0.013476774921811522
          ],
          [
            "attack",
            0.013161110289153743
          ],
          [
            "images",
            0.012497853882672173
          ]
        ],
        "count": 301
      },
      "8": {
        "name": "8_learning_networks_neural_memory",
        "keywords": [
          [
            "learning",
            0.027101778661167024
          ],
          [
            "networks",
            0.021800847169908696
          ],
          [
            "neural",
            0.020016530404575423
          ],
          [
            "memory",
            0.018523868696711278
          ],
          [
            "network",
            0.017214618821933834
          ],
          [
            "recurrent",
            0.015600878518148542
          ],
          [
            "brain",
            0.013749866929470831
          ],
          [
            "biological",
            0.012724794797038847
          ],
          [
            "neural networks",
            0.012459596974315895
          ],
          [
            "model",
            0.01150988598948555
          ]
        ],
        "count": 294
      },
      "9": {
        "name": "9_language_models_speech_model",
        "keywords": [
          [
            "language",
            0.019609993360938285
          ],
          [
            "models",
            0.019296287295454854
          ],
          [
            "speech",
            0.016047379244679468
          ],
          [
            "model",
            0.015697115514290396
          ],
          [
            "attention",
            0.015124035893337757
          ],
          [
            "tasks",
            0.012134194498191236
          ],
          [
            "learning",
            0.012057917487492588
          ],
          [
            "training",
            0.011592615688887052
          ],
          [
            "neural",
            0.011356451661721228
          ],
          [
            "Transformer",
            0.011325307004874116
          ]
        ],
        "count": 275
      },
      "10": {
        "name": "10_pruning_network_networks_training",
        "keywords": [
          [
            "pruning",
            0.030486310498068225
          ],
          [
            "network",
            0.016979812772995505
          ],
          [
            "networks",
            0.016348222105631582
          ],
          [
            "training",
            0.01629343560367507
          ],
          [
            "neural",
            0.0159800666647301
          ],
          [
            "accuracy",
            0.0142921370265013
          ],
          [
            "inference",
            0.014034841976950232
          ],
          [
            "memory",
            0.013637503711415384
          ],
          [
            "Neural",
            0.01360864441081193
          ],
          [
            "performance",
            0.013353586997646681
          ]
        ],
        "count": 227
      },
      "11": {
        "name": "11_neural_equations_PDE_differential",
        "keywords": [
          [
            "neural",
            0.02168791144033165
          ],
          [
            "equations",
            0.021014094354505252
          ],
          [
            "PDE",
            0.017028117224974024
          ],
          [
            "differential",
            0.01647419508907751
          ],
          [
            "network",
            0.015882701064694055
          ],
          [
            "PINNs",
            0.015209115689677909
          ],
          [
            "differential equations",
            0.014632823018891787
          ],
          [
            "model",
            0.014508381524573205
          ],
          [
            "equation",
            0.014310423703097586
          ],
          [
            "neural network",
            0.014105189912980804
          ]
        ],
        "count": 165
      },
      "12": {
        "name": "12_forecasting_series_data_time series",
        "keywords": [
          [
            "forecasting",
            0.02676680730664668
          ],
          [
            "series",
            0.02548807534726192
          ],
          [
            "data",
            0.02366277241941755
          ],
          [
            "time series",
            0.022454509647923854
          ],
          [
            "model",
            0.02017488282662074
          ],
          [
            "time",
            0.020003776184846205
          ],
          [
            "stock",
            0.01909009551110112
          ],
          [
            "models",
            0.015893380957773547
          ],
          [
            "prediction",
            0.01556499624657005
          ],
          [
            "anomaly",
            0.015320191154109349
          ]
        ],
        "count": 142
      },
      "13": {
        "name": "13_images_medical_segmentation_image",
        "keywords": [
          [
            "images",
            0.018284195064273787
          ],
          [
            "medical",
            0.015964886133625147
          ],
          [
            "segmentation",
            0.015482284480806397
          ],
          [
            "image",
            0.014961101819127657
          ],
          [
            "data",
            0.014744433937247468
          ],
          [
            "learning",
            0.01455978538580509
          ],
          [
            "deep",
            0.01430679439071816
          ],
          [
            "disease",
            0.014245048677508487
          ],
          [
            "models",
            0.014147150858602206
          ],
          [
            "accuracy",
            0.013430144762112012
          ]
        ],
        "count": 140
      },
      "14": {
        "name": "14_graph_Graph_graphs_node",
        "keywords": [
          [
            "graph",
            0.08478966139271112
          ],
          [
            "Graph",
            0.03573995739305586
          ],
          [
            "graphs",
            0.025686080380013465
          ],
          [
            "node",
            0.0232978086730611
          ],
          [
            "GNNs",
            0.021814458037529218
          ],
          [
            "networks",
            0.019782341164699943
          ],
          [
            "learning",
            0.0193181530395599
          ],
          [
            "neural",
            0.018021690605595463
          ],
          [
            "graph neural",
            0.017103099296243162
          ],
          [
            "GNN",
            0.016202894458603543
          ]
        ],
        "count": 121
      },
      "15": {
        "name": "15_reservoir_RC_Reservoir_chaotic",
        "keywords": [
          [
            "reservoir",
            0.07356949260441821
          ],
          [
            "RC",
            0.0436180933261266
          ],
          [
            "Reservoir",
            0.032006722897527165
          ],
          [
            "chaotic",
            0.029288461841690563
          ],
          [
            "reservoir computing",
            0.023721836337345443
          ],
          [
            "time",
            0.02268351407984086
          ],
          [
            "systems",
            0.022474570458136382
          ],
          [
            "computing",
            0.021326210193457693
          ],
          [
            "dynamical",
            0.02094595012789808
          ],
          [
            "dynamics",
            0.020558202867427437
          ]
        ],
        "count": 117
      }
    },
    "correlations": [
      [
        1.0,
        -0.6863751518972709,
        -0.7428455053872938,
        -0.6778387014870613,
        -0.7268472973883114,
        -0.7181216746707663,
        -0.660824337581551,
        -0.7073657059201689,
        -0.7028804486910303,
        -0.6835727387312962,
        -0.7270511180756787,
        -0.7232483009313009,
        -0.666937632948565,
        -0.7276937735584934,
        -0.7240410506716388,
        -0.75091239460265
      ],
      [
        -0.6863751518972709,
        1.0,
        -0.7201524746327351,
        -0.705937983251518,
        -0.7242285142793827,
        -0.7468661781502359,
        -0.71438954918125,
        -0.7306599061605548,
        -0.5632822586436356,
        -0.7086947365238239,
        -0.7183243153130627,
        -0.7282999603382143,
        -0.7201542450891435,
        -0.7411898587308637,
        -0.7386126632333823,
        -0.7524581953701728
      ],
      [
        -0.7428455053872938,
        -0.7201524746327351,
        1.0,
        -0.4856029449703839,
        -0.05005739161596465,
        -0.7571476309925571,
        -0.652612046309079,
        -0.7043074934248796,
        -0.47368007196907874,
        -0.70994419057189,
        -0.513283635002902,
        -0.6202425513861312,
        -0.693490603822392,
        -0.7267817346325134,
        -0.6158789926632964,
        -0.7388606607853352
      ],
      [
        -0.6778387014870613,
        -0.705937983251518,
        -0.4856029449703839,
        1.0,
        -0.5111995512299926,
        -0.7360914495900115,
        -0.5636996142772834,
        -0.6686708519870679,
        -0.169447420896708,
        -0.663193957492134,
        -0.2728652068845851,
        -0.4025190360795123,
        -0.6754613043237987,
        -0.6861060799505463,
        -0.6113003250779783,
        -0.7176984704520181
      ],
      [
        -0.7268472973883114,
        -0.7242285142793827,
        -0.05005739161596465,
        -0.5111995512299926,
        1.0,
        -0.7532177325183469,
        -0.6185758133194347,
        -0.7039289801743625,
        -0.4940023699019312,
        -0.7027591105026332,
        -0.5380896147181821,
        -0.5636210374005854,
        -0.6899583697897977,
        -0.7202654619957842,
        -0.6322930831971907,
        -0.732244227450164
      ],
      [
        -0.7181216746707663,
        -0.7468661781502359,
        -0.7571476309925571,
        -0.7360914495900115,
        -0.7532177325183469,
        1.0,
        -0.7335570681703355,
        -0.7348798440077341,
        -0.7522407813224383,
        -0.6370962537979148,
        -0.7503915316336311,
        -0.7422187205079702,
        -0.7415287887331874,
        -0.7479230061356905,
        -0.750366623620394,
        -0.7578900888716787
      ],
      [
        -0.660824337581551,
        -0.71438954918125,
        -0.652612046309079,
        -0.5636996142772834,
        -0.6185758133194347,
        -0.7335570681703355,
        1.0,
        -0.7033855311342396,
        -0.5648275750149231,
        -0.7128546854870413,
        -0.5508518447982027,
        -0.5592947207677448,
        -0.69634458058831,
        -0.7040148450970082,
        -0.6601717005825571,
        -0.7473237620166877
      ],
      [
        -0.7073657059201689,
        -0.7306599061605548,
        -0.7043074934248796,
        -0.6686708519870679,
        -0.7039289801743625,
        -0.7348798440077341,
        -0.7033855311342396,
        1.0,
        -0.6703541890398534,
        -0.4635364180569426,
        -0.6795985839446994,
        -0.7027288033441945,
        -0.4953794375281403,
        -0.6723232335895118,
        -0.7314738134961956,
        -0.746862504435526
      ],
      [
        -0.7028804486910303,
        -0.5632822586436356,
        -0.47368007196907874,
        -0.169447420896708,
        -0.4940023699019312,
        -0.7522407813224383,
        -0.5648275750149231,
        -0.6703541890398534,
        1.0,
        -0.6608018760320935,
        -0.3368751109852006,
        -0.43653834495102817,
        -0.6551153570919545,
        -0.6843898823300923,
        -0.6027833424736321,
        -0.6848798620614429
      ],
      [
        -0.6835727387312962,
        -0.7086947365238239,
        -0.70994419057189,
        -0.663193957492134,
        -0.7027591105026332,
        -0.6370962537979148,
        -0.7128546854870413,
        -0.4635364180569426,
        -0.6608018760320935,
        1.0,
        -0.6949304360394232,
        -0.7096831413480895,
        -0.6479995541506338,
        -0.7079444087570714,
        -0.7281762627874163,
        -0.745894980982424
      ],
      [
        -0.7270511180756787,
        -0.7183243153130627,
        -0.513283635002902,
        -0.2728652068845851,
        -0.5380896147181821,
        -0.7503915316336311,
        -0.5508518447982027,
        -0.6795985839446994,
        -0.3368751109852006,
        -0.6949304360394232,
        1.0,
        -0.35957984643183366,
        -0.6957714285963422,
        -0.7138310162489867,
        -0.6166235744124587,
        -0.7367283596174072
      ],
      [
        -0.7232483009313009,
        -0.7282999603382143,
        -0.6202425513861312,
        -0.4025190360795123,
        -0.5636210374005854,
        -0.7422187205079702,
        -0.5592947207677448,
        -0.7027288033441945,
        -0.43653834495102817,
        -0.7096831413480895,
        -0.35957984643183366,
        1.0,
        -0.6928508810117948,
        -0.698276536570121,
        -0.6262278023566447,
        -0.7060983033369652
      ],
      [
        -0.666937632948565,
        -0.7201542450891435,
        -0.693490603822392,
        -0.6754613043237987,
        -0.6899583697897977,
        -0.7415287887331874,
        -0.69634458058831,
        -0.4953794375281403,
        -0.6551153570919545,
        -0.6479995541506338,
        -0.6957714285963422,
        -0.6928508810117948,
        1.0,
        -0.6909324850253907,
        -0.7206258461850131,
        -0.603407568947808
      ],
      [
        -0.7276937735584934,
        -0.7411898587308637,
        -0.7267817346325134,
        -0.6861060799505463,
        -0.7202654619957842,
        -0.7479230061356905,
        -0.7040148450970082,
        -0.6723232335895118,
        -0.6843898823300923,
        -0.7079444087570714,
        -0.7138310162489867,
        -0.698276536570121,
        -0.6909324850253907,
        1.0,
        -0.7406848878111659,
        -0.7560815552465304
      ],
      [
        -0.7240410506716388,
        -0.7386126632333823,
        -0.6158789926632964,
        -0.6113003250779783,
        -0.6322930831971907,
        -0.750366623620394,
        -0.6601717005825571,
        -0.7314738134961956,
        -0.6027833424736321,
        -0.7281762627874163,
        -0.6166235744124587,
        -0.6262278023566447,
        -0.7206258461850131,
        -0.7406848878111659,
        1.0,
        -0.7490776454048844
      ],
      [
        -0.75091239460265,
        -0.7524581953701728,
        -0.7388606607853352,
        -0.7176984704520181,
        -0.732244227450164,
        -0.7578900888716787,
        -0.7473237620166877,
        -0.746862504435526,
        -0.6848798620614429,
        -0.745894980982424,
        -0.7367283596174072,
        -0.7060983033369652,
        -0.603407568947808,
        -0.7560815552465304,
        -0.7490776454048844,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        32,
        1,
        10,
        22,
        1,
        2,
        4,
        1,
        7,
        4,
        4,
        2,
        10,
        2,
        8,
        3
      ],
      "2020-02": [
        53,
        3,
        7,
        27,
        3,
        0,
        6,
        4,
        8,
        8,
        3,
        1,
        13,
        2,
        9,
        3
      ],
      "2020-03": [
        49,
        9,
        14,
        28,
        8,
        0,
        8,
        5,
        4,
        6,
        2,
        2,
        13,
        3,
        3,
        2
      ],
      "2020-04": [
        70,
        8,
        6,
        25,
        4,
        2,
        16,
        5,
        9,
        8,
        3,
        3,
        17,
        2,
        2,
        6
      ],
      "2020-05": [
        46,
        6,
        9,
        20,
        6,
        2,
        14,
        2,
        13,
        1,
        2,
        1,
        12,
        5,
        6,
        3
      ],
      "2020-06": [
        56,
        7,
        12,
        44,
        7,
        1,
        9,
        7,
        26,
        7,
        5,
        0,
        20,
        2,
        8,
        6
      ],
      "2020-07": [
        51,
        5,
        13,
        21,
        4,
        1,
        12,
        5,
        6,
        4,
        5,
        1,
        12,
        2,
        5,
        1
      ],
      "2020-08": [
        28,
        3,
        5,
        14,
        7,
        0,
        9,
        3,
        5,
        1,
        3,
        3,
        13,
        3,
        4,
        5
      ],
      "2020-09": [
        30,
        3,
        11,
        15,
        5,
        1,
        8,
        3,
        5,
        5,
        3,
        3,
        7,
        2,
        6,
        4
      ],
      "2020-10": [
        59,
        3,
        16,
        29,
        3,
        1,
        7,
        3,
        10,
        8,
        4,
        0,
        14,
        1,
        6,
        6
      ],
      "2020-11": [
        31,
        5,
        9,
        25,
        4,
        0,
        11,
        2,
        8,
        8,
        3,
        4,
        9,
        3,
        4,
        1
      ],
      "2020-12": [
        38,
        1,
        3,
        19,
        2,
        2,
        11,
        6,
        8,
        4,
        1,
        3,
        9,
        3,
        3,
        5
      ],
      "2021-01": [
        30,
        4,
        2,
        19,
        1,
        0,
        6,
        8,
        7,
        4,
        2,
        2,
        10,
        2,
        2,
        3
      ],
      "2021-02": [
        53,
        4,
        10,
        16,
        4,
        3,
        5,
        3,
        10,
        5,
        3,
        1,
        15,
        3,
        6,
        3
      ],
      "2021-03": [
        31,
        7,
        8,
        21,
        4,
        2,
        9,
        3,
        9,
        6,
        3,
        2,
        7,
        6,
        5,
        3
      ],
      "2021-04": [
        60,
        3,
        9,
        10,
        4,
        0,
        7,
        2,
        5,
        5,
        0,
        3,
        9,
        1,
        6,
        3
      ],
      "2021-05": [
        28,
        8,
        12,
        23,
        7,
        0,
        8,
        5,
        5,
        6,
        2,
        3,
        7,
        3,
        5,
        4
      ],
      "2021-06": [
        39,
        8,
        16,
        14,
        7,
        1,
        11,
        7,
        11,
        4,
        3,
        4,
        17,
        0,
        9,
        1
      ],
      "2021-07": [
        31,
        3,
        9,
        15,
        4,
        5,
        12,
        4,
        5,
        3,
        1,
        1,
        6,
        2,
        5,
        2
      ],
      "2021-08": [
        30,
        4,
        6,
        11,
        4,
        4,
        8,
        1,
        2,
        6,
        0,
        0,
        4,
        3,
        6,
        6
      ],
      "2021-09": [
        37,
        3,
        13,
        18,
        5,
        0,
        6,
        3,
        7,
        11,
        1,
        1,
        8,
        1,
        3,
        1
      ],
      "2021-10": [
        51,
        3,
        11,
        10,
        2,
        2,
        4,
        3,
        8,
        5,
        0,
        0,
        11,
        2,
        10,
        2
      ],
      "2021-11": [
        30,
        2,
        10,
        15,
        6,
        1,
        8,
        3,
        5,
        7,
        2,
        0,
        9,
        2,
        6,
        2
      ],
      "2021-12": [
        33,
        2,
        7,
        18,
        1,
        1,
        8,
        3,
        3,
        7,
        1,
        1,
        5,
        1,
        3,
        3
      ],
      "2022-01": [
        38,
        3,
        11,
        11,
        3,
        0,
        6,
        2,
        5,
        4,
        3,
        0,
        14,
        1,
        4,
        5
      ],
      "2022-02": [
        40,
        5,
        10,
        19,
        7,
        2,
        7,
        2,
        6,
        6,
        2,
        0,
        10,
        4,
        1,
        0
      ],
      "2022-03": [
        45,
        5,
        12,
        18,
        7,
        0,
        9,
        3,
        8,
        6,
        1,
        1,
        7,
        4,
        9,
        2
      ],
      "2022-04": [
        55,
        7,
        12,
        18,
        4,
        8,
        7,
        1,
        9,
        10,
        1,
        3,
        18,
        4,
        3,
        2
      ],
      "2022-05": [
        36,
        4,
        20,
        23,
        5,
        3,
        7,
        5,
        10,
        9,
        2,
        0,
        10,
        0,
        9,
        4
      ],
      "2022-06": [
        34,
        8,
        14,
        26,
        5,
        4,
        8,
        2,
        10,
        6,
        2,
        0,
        14,
        2,
        4,
        5
      ],
      "2022-07": [
        29,
        2,
        13,
        12,
        4,
        0,
        9,
        4,
        5,
        2,
        2,
        1,
        7,
        1,
        6,
        4
      ],
      "2022-08": [
        39,
        8,
        10,
        17,
        3,
        1,
        3,
        4,
        6,
        5,
        0,
        3,
        7,
        3,
        8,
        1
      ],
      "2022-09": [
        28,
        6,
        6,
        19,
        6,
        3,
        7,
        3,
        6,
        3,
        2,
        3,
        8,
        2,
        5,
        2
      ],
      "2022-10": [
        45,
        3,
        15,
        20,
        4,
        1,
        8,
        2,
        5,
        6,
        1,
        3,
        11,
        2,
        10,
        1
      ],
      "2022-11": [
        46,
        5,
        18,
        14,
        4,
        0,
        8,
        4,
        3,
        8,
        0,
        2,
        13,
        1,
        5,
        3
      ],
      "2022-12": [
        28,
        2,
        10,
        13,
        6,
        1,
        6,
        0,
        8,
        1,
        0,
        3,
        9,
        2,
        3,
        2
      ],
      "2023-01": [
        28,
        4,
        7,
        17,
        6,
        1,
        8,
        0,
        10,
        4,
        0,
        0,
        3,
        2,
        5,
        2
      ],
      "2023-02": [
        36,
        5,
        16,
        18,
        4,
        4,
        11,
        1,
        4,
        11,
        3,
        4,
        15,
        0,
        11,
        4
      ],
      "2023-03": [
        46,
        9,
        15,
        23,
        7,
        2,
        8,
        4,
        4,
        8,
        1,
        0,
        4,
        1,
        3,
        1
      ],
      "2023-04": [
        50,
        6,
        22,
        26,
        4,
        2,
        6,
        2,
        7,
        6,
        2,
        3,
        9,
        1,
        10,
        1
      ],
      "2023-05": [
        53,
        9,
        26,
        28,
        1,
        5,
        13,
        4,
        11,
        6,
        1,
        2,
        7,
        3,
        10,
        3
      ],
      "2023-06": [
        31,
        9,
        14,
        18,
        11,
        3,
        4,
        1,
        5,
        8,
        2,
        1,
        8,
        0,
        7,
        2
      ],
      "2023-07": [
        22,
        2,
        14,
        13,
        2,
        6,
        5,
        1,
        4,
        5,
        3,
        2,
        11,
        0,
        6,
        6
      ],
      "2023-08": [
        27,
        6,
        19,
        19,
        2,
        1,
        6,
        2,
        8,
        6,
        1,
        5,
        6,
        1,
        3,
        4
      ],
      "2023-09": [
        21,
        3,
        16,
        14,
        7,
        6,
        6,
        4,
        12,
        4,
        3,
        2,
        9,
        0,
        1,
        1
      ],
      "2023-10": [
        34,
        2,
        14,
        15,
        8,
        5,
        10,
        3,
        8,
        8,
        1,
        0,
        14,
        3,
        12,
        2
      ],
      "2023-11": [
        28,
        5,
        18,
        23,
        4,
        1,
        6,
        1,
        7,
        3,
        1,
        2,
        9,
        0,
        5,
        0
      ],
      "2023-12": [
        39,
        4,
        15,
        16,
        7,
        2,
        8,
        5,
        7,
        3,
        1,
        5,
        15,
        2,
        7,
        7
      ],
      "2024-01": [
        55,
        1,
        20,
        16,
        7,
        6,
        9,
        0,
        3,
        5,
        1,
        1,
        11,
        1,
        6,
        5
      ],
      "2024-02": [
        66,
        9,
        22,
        33,
        7,
        11,
        5,
        2,
        9,
        6,
        1,
        2,
        9,
        5,
        5,
        1
      ],
      "2024-03": [
        41,
        1,
        14,
        15,
        3,
        9,
        13,
        2,
        4,
        4,
        3,
        0,
        8,
        2,
        10,
        4
      ],
      "2024-04": [
        58,
        3,
        22,
        8,
        7,
        11,
        4,
        3,
        5,
        7,
        2,
        4,
        10,
        0,
        15,
        1
      ],
      "2024-05": [
        50,
        6,
        17,
        24,
        7,
        10,
        7,
        0,
        9,
        8,
        4,
        1,
        11,
        2,
        12,
        6
      ],
      "2024-06": [
        50,
        2,
        23,
        17,
        4,
        13,
        3,
        3,
        7,
        6,
        2,
        5,
        14,
        1,
        9,
        9
      ],
      "2024-07": [
        41,
        5,
        20,
        17,
        7,
        8,
        6,
        8,
        9,
        2,
        2,
        3,
        15,
        1,
        7,
        5
      ],
      "2024-08": [
        34,
        2,
        23,
        16,
        8,
        5,
        5,
        1,
        5,
        4,
        1,
        3,
        8,
        2,
        5,
        3
      ],
      "2024-09": [
        28,
        2,
        14,
        24,
        8,
        6,
        5,
        3,
        10,
        7,
        0,
        1,
        8,
        0,
        7,
        1
      ],
      "2024-10": [
        44,
        2,
        21,
        21,
        5,
        9,
        9,
        5,
        15,
        5,
        1,
        2,
        10,
        2,
        6,
        2
      ],
      "2024-11": [
        52,
        6,
        23,
        20,
        3,
        4,
        6,
        1,
        6,
        7,
        0,
        3,
        8,
        2,
        7,
        3
      ],
      "2024-12": [
        43,
        1,
        18,
        19,
        7,
        10,
        4,
        2,
        3,
        6,
        1,
        1,
        11,
        2,
        12,
        1
      ],
      "2025-01": [
        61,
        2,
        12,
        12,
        7,
        13,
        4,
        2,
        9,
        1,
        1,
        3,
        6,
        1,
        7,
        1
      ],
      "2025-02": [
        35,
        6,
        18,
        7,
        6,
        9,
        3,
        2,
        7,
        5,
        0,
        4,
        5,
        1,
        6,
        0
      ],
      "2025-03": [
        41,
        5,
        23,
        9,
        5,
        9,
        8,
        1,
        5,
        3,
        0,
        4,
        4,
        0,
        1,
        3
      ],
      "2025-04": [
        53,
        8,
        12,
        12,
        2,
        13,
        15,
        1,
        2,
        4,
        1,
        2,
        4,
        0,
        7,
        5
      ],
      "2025-05": [
        60,
        8,
        27,
        14,
        6,
        17,
        10,
        3,
        9,
        9,
        2,
        1,
        8,
        1,
        6,
        6
      ],
      "2025-06": [
        38,
        5,
        30,
        17,
        5,
        6,
        5,
        5,
        4,
        7,
        2,
        1,
        6,
        1,
        9,
        4
      ],
      "2025-07": [
        41,
        3,
        16,
        16,
        6,
        6,
        2,
        3,
        8,
        6,
        0,
        3,
        9,
        1,
        4,
        4
      ],
      "2025-08": [
        34,
        5,
        18,
        10,
        6,
        8,
        6,
        2,
        4,
        6,
        1,
        5,
        8,
        0,
        5,
        5
      ],
      "2025-09": [
        18,
        0,
        7,
        3,
        1,
        3,
        1,
        1,
        2,
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Enhanced Opposition Differential Evolution Algorithm for Multimodal Optimization",
          "year": "2022-08",
          "abstract": "Most of the real-world problems are multimodal in nature that consists of\nmultiple optimum values. Multimodal optimization is defined as the process of\nfinding multiple global and local optima (as opposed to a single solution) of a\nfunction. It enables a user to switch between different solutions as per the\nneed while still maintaining the optimal system performance. Classical\ngradient-based methods fail for optimization problems in which the objective\nfunctions are either discontinuous or non-differentiable. Evolutionary\nAlgorithms (EAs) are able to find multiple solutions within a population in a\nsingle algorithmic run as compared to classical optimization techniques that\nneed multiple restarts and multiple runs to find different solutions. Hence,\nseveral EAs have been proposed to solve such kinds of problems. However,\nDifferential Evolution (DE) algorithm is a population-based heuristic method\nthat can solve such optimization problems, and it is simple to implement. The\npotential challenge in Multi-Modal Optimization Problems (MMOPs) is to search\nthe function space efficiently to locate most of the peaks accurately. The\noptimization problem could be to minimize or maximize a given objective\nfunction and we aim to solve the maximization problems on multimodal functions\nin this study. Hence, we have proposed an algorithm known as Enhanced\nOpposition Differential Evolution (EODE) algorithm to solve the MMOPs. The\nproposed algorithm has been tested on IEEE Congress on Evolutionary Computation\n(CEC) 2013 benchmark functions, and it achieves competitive results compared to\nthe existing state-of-the-art approaches.",
          "arxiv_id": "2208.11066v1"
        },
        {
          "title": "An Effective and Efficient Evolutionary Algorithm for Many-Objective Optimization",
          "year": "2022-05",
          "abstract": "In evolutionary multiobjective optimization, effectiveness refers to how an\nevolutionary algorithm performs in terms of converging its solutions into the\nPareto front and also diversifying them over the front. This is not an easy\njob, particularly for optimization problems with more than three objectives,\ndubbed many-objective optimization problems. In such problems, classic\nPareto-based algorithms fail to provide sufficient selection pressure towards\nthe Pareto front, whilst recently developed algorithms, such as\ndecomposition-based ones, may struggle to maintain a set of well-distributed\nsolutions on certain problems (e.g., those with irregular Pareto fronts).\nAnother issue in some many-objective optimizers is rapidly increasing\ncomputational requirement with the number of objectives, such as\nhypervolume-based algorithms and shift-based density estimation (SDE) methods.\nIn this paper, we aim to address this problem and develop an effective and\nefficient evolutionary algorithm (E3A) that can handle various many-objective\nproblems. In E3A, inspired by SDE, a novel population maintenance method is\nproposed to select high-quality solutions in the environmental selection\nprocedure. We conduct extensive experiments and show that E3A performs better\nthan 11 state-of-the-art many-objective evolutionary algorithms in quickly\nfinding a set of well-converged and well-diversified solutions.",
          "arxiv_id": "2205.15884v2"
        },
        {
          "title": "Multi-objective beetle antennae search algorithm",
          "year": "2020-02",
          "abstract": "In engineering optimization problems, multiple objectives with a large number\nof variables under highly nonlinear constraints are usually required to be\nsimultaneously optimized. Significant computing effort are required to find the\nPareto front of a nonlinear multi-objective optimization problem. Swarm\nintelligence based metaheuristic algorithms have been successfully applied to\nsolve multi-objective optimization problems. Recently, an individual\nintelligence based algorithm called beetle antennae search algorithm was\nproposed. This algorithm was proved to be more computationally efficient.\nTherefore, we extended this algorithm to solve multi-objective optimization\nproblems. The proposed multi-objective beetle antennae search algorithm is\ntested using four well-selected benchmark functions and its performance is\ncompared with other multi-objective optimization algorithms. The results show\nthat the proposed multi-objective beetle antennae search algorithm has higher\ncomputational efficiency with satisfactory accuracy.",
          "arxiv_id": "2002.10090v2"
        }
      ],
      "1": [
        {
          "title": "Accelerating Model-Based Reinforcement Learning with State-Space World Models",
          "year": "2025-02",
          "abstract": "Reinforcement learning (RL) is a powerful approach for robot learning.\nHowever, model-free RL (MFRL) requires a large number of environment\ninteractions to learn successful control policies. This is due to the noisy RL\ntraining updates and the complexity of robotic systems, which typically involve\nhighly non-linear dynamics and noisy sensor signals. In contrast, model-based\nRL (MBRL) not only trains a policy but simultaneously learns a world model that\ncaptures the environment's dynamics and rewards. The world model can either be\nused for planning, for data collection, or to provide first-order policy\ngradients for training. Leveraging a world model significantly improves sample\nefficiency compared to model-free RL. However, training a world model alongside\nthe policy increases the computational complexity, leading to longer training\ntimes that are often intractable for complex real-world scenarios. In this\nwork, we propose a new method for accelerating model-based RL using state-space\nworld models. Our approach leverages state-space models (SSMs) to parallelize\nthe training of the dynamics model, which is typically the main computational\nbottleneck. Additionally, we propose an architecture that provides privileged\ninformation to the world model during training, which is particularly relevant\nfor partially observable environments. We evaluate our method in several\nreal-world agile quadrotor flight tasks, involving complex dynamics, for both\nfully and partially observable environments. We demonstrate a significant\nspeedup, reducing the world model training time by up to 10 times, and the\noverall MBRL training time by up to 4 times. This benefit comes without\ncompromising performance, as our method achieves similar sample efficiency and\ntask rewards to state-of-the-art MBRL methods.",
          "arxiv_id": "2502.20168v1"
        },
        {
          "title": "SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning",
          "year": "2025-04",
          "abstract": "We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.",
          "arxiv_id": "2504.02654v1"
        },
        {
          "title": "Diversity Through Exclusion (DTE): Niche Identification for Reinforcement Learning through Value-Decomposition",
          "year": "2023-02",
          "abstract": "Many environments contain numerous available niches of variable value, each\nassociated with a different local optimum in the space of behaviors (policy\nspace). In such situations it is often difficult to design a learning process\ncapable of evading distraction by poor local optima long enough to stumble upon\nthe best available niche. In this work we propose a generic reinforcement\nlearning (RL) algorithm that performs better than baseline deep Q-learning\nalgorithms in such environments with multiple variably-valued niches. The\nalgorithm we propose consists of two parts: an agent architecture and a\nlearning rule. The agent architecture contains multiple sub-policies. The\nlearning rule is inspired by fitness sharing in evolutionary computation and\napplied in reinforcement learning using Value-Decomposition-Networks in a novel\nmanner for a single-agent's internal population. It can concretely be\nunderstood as adding an extra loss term where one policy's experience is also\nused to update all the other policies in a manner that decreases their value\nestimates for the visited states. In particular, when one sub-policy visits a\nparticular state frequently this decreases the value predicted for other\nsub-policies for going to that state. Further, we introduce an artificial\nchemistry inspired platform where it is easy to create tasks with multiple\nrewarding strategies utilizing different resources (i.e. multiple niches). We\nshow that agents trained this way can escape poor-but-attractive local optima\nto instead converge to harder-to-discover higher value strategies in both the\nartificial chemistry environments and in simpler illustrative environments.",
          "arxiv_id": "2302.01180v2"
        }
      ],
      "2": [
        {
          "title": "Direct Training High-Performance Deep Spiking Neural Networks: A Review of Theories and Methods",
          "year": "2024-05",
          "abstract": "Spiking neural networks (SNNs) offer a promising energy-efficient alternative\nto artificial neural networks (ANNs), in virtue of their high biological\nplausibility, rich spatial-temporal dynamics, and event-driven computation. The\ndirect training algorithms based on the surrogate gradient method provide\nsufficient flexibility to design novel SNN architectures and explore the\nspatial-temporal dynamics of SNNs. According to previous studies, the\nperformance of models is highly dependent on their sizes. Recently, direct\ntraining deep SNNs have achieved great progress on both neuromorphic datasets\nand large-scale static datasets. Notably, transformer-based SNNs show\ncomparable performance with their ANN counterparts. In this paper, we provide a\nnew perspective to summarize the theories and methods for training deep SNNs\nwith high performance in a systematic and comprehensive way, including theory\nfundamentals, spiking neuron models, advanced SNN models and residual\narchitectures, software frameworks and neuromorphic hardware, applications, and\nfuture trends. The reviewed papers are collected at\nhttps://github.com/zhouchenlin2096/Awesome-Spiking-Neural-Networks",
          "arxiv_id": "2405.04289v2"
        },
        {
          "title": "Training Energy-Efficient Deep Spiking Neural Networks with Single-Spike Hybrid Input Encoding",
          "year": "2021-07",
          "abstract": "Spiking Neural Networks (SNNs) have emerged as an attractive alternative to\ntraditional deep learning frameworks, since they provide higher computational\nefficiency in event driven neuromorphic hardware. However, the state-of-the-art\n(SOTA) SNNs suffer from high inference latency, resulting from inefficient\ninput encoding and training techniques. The most widely used input coding\nschemes, such as Poisson based rate-coding, do not leverage the temporal\nlearning capabilities of SNNs. This paper presents a training framework for\nlow-latency energy-efficient SNNs that uses a hybrid encoding scheme at the\ninput layer in which the analog pixel values of an image are directly applied\nduring the first timestep and a novel variant of spike temporal coding is used\nduring subsequent timesteps. In particular, neurons in every hidden layer are\nrestricted to fire at most once per image which increases activation sparsity.\nTo train these hybrid-encoded SNNs, we propose a variant of the gradient\ndescent based spike timing dependent back propagation (STDB) mechanism using a\nnovel cross entropy loss function based on both the output neurons' spike time\nand membrane potential. The resulting SNNs have reduced latency and high\nactivation sparsity, yielding significant improvements in computational\nefficiency. In particular, we evaluate our proposed training scheme on image\nclassification tasks from CIFAR-10 and CIFAR-100 datasets on several VGG\narchitectures. We achieve top-1 accuracy of $66.46$\\% with $5$ timesteps on the\nCIFAR-100 dataset with ${\\sim}125\\times$ less compute energy than an equivalent\nstandard ANN. Additionally, our proposed SNN performs $5$-$300\\times$ faster\ninference compared to other state-of-the-art rate or temporally coded SNN\nmodels.",
          "arxiv_id": "2107.12374v1"
        },
        {
          "title": "Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks",
          "year": "2021-02",
          "abstract": "Spiking neural networks (SNNs) are biology-inspired artificial neural\nnetworks (ANNs) that comprise of spiking neurons to process asynchronous\ndiscrete signals. While more efficient in power consumption and inference speed\non the neuromorphic hardware, SNNs are usually difficult to train directly from\nscratch with spikes due to the discreteness. As an alternative, many efforts\nhave been devoted to converting conventional ANNs into SNNs by copying the\nweights from ANNs and adjusting the spiking threshold potential of neurons in\nSNNs. Researchers have designed new SNN architectures and conversion algorithms\nto diminish the conversion error. However, an effective conversion should\naddress the difference between the SNN and ANN architectures with an efficient\napproximation \\DSK{of} the loss function, which is missing in the field. In\nthis work, we analyze the conversion error by recursive reduction to layer-wise\nsummation and propose a novel strategic pipeline that transfers the weights to\nthe target SNN by combining threshold balance and soft-reset mechanisms. This\npipeline enables almost no accuracy loss between the converted SNNs and\nconventional ANNs with only $\\sim1/10$ of the typical SNN simulation time. Our\nmethod is promising to get implanted onto embedded platforms with better\nsupport of SNNs with limited energy and memory.",
          "arxiv_id": "2103.00476v1"
        }
      ],
      "3": [
        {
          "title": "Consensus Function from an $L_p^q-$norm Regularization Term for its Use as Adaptive Activation Functions in Neural Networks",
          "year": "2022-06",
          "abstract": "The design of a neural network is usually carried out by defining the number\nof layers, the number of neurons per layer, their connections or synapses, and\nthe activation function that they will execute. The training process tries to\noptimize the weights assigned to those connections, together with the biases of\nthe neurons, to better fit the training data. However, the definition of the\nactivation functions is, in general, determined in the design process and not\nmodified during the training, meaning that their behavior is unrelated to the\ntraining data set. In this paper we propose the definition and utilization of\nan implicit, parametric, non-linear activation function that adapts its shape\nduring the training process. This fact increases the space of parameters to\noptimize within the network, but it allows a greater flexibility and\ngeneralizes the concept of neural networks. Furthermore, it simplifies the\narchitectural design since the same activation function definition can be\nemployed in each neuron, letting the training process to optimize their\nparameters and, thus, their behavior. Our proposed activation function comes\nfrom the definition of the consensus variable from the optimization of a linear\nunderdetermined problem with an $L_p^q$ regularization term, via the\nAlternating Direction Method of Multipliers (ADMM). We define the neural\nnetworks using this type of activation functions as $pq-$networks. Preliminary\nresults show that the use of these neural networks with this type of adaptive\nactivation functions reduces the error in regression and classification\nexamples, compared to equivalent regular feedforward neural networks with fixed\nactivation functions.",
          "arxiv_id": "2206.15017v1"
        },
        {
          "title": "Deeper Learning with CoLU Activation",
          "year": "2021-12",
          "abstract": "In neural networks, non-linearity is introduced by activation functions. One\ncommonly used activation function is Rectified Linear Unit (ReLU). ReLU has\nbeen a popular choice as an activation but has flaws. State-of-the-art\nfunctions like Swish and Mish are now gaining attention as a better choice as\nthey combat many flaws presented by other activation functions. CoLU is an\nactivation function similar to Swish and Mish in properties. It is defined as\nf(x)=x/(1-xe^-(x+e^x)). It is smooth, continuously differentiable, unbounded\nabove, bounded below, non-saturating, and non-monotonic. Based on experiments\ndone with CoLU with different activation functions, it is observed that CoLU\nusually performs better than other functions on deeper neural networks. While\ntraining different neural networks on MNIST on an incrementally increasing\nnumber of convolutional layers, CoLU retained the highest accuracy for more\nlayers. On a smaller network with 8 convolutional layers, CoLU had the highest\nmean accuracy, closely followed by ReLU. On VGG-13 trained on Fashion-MNIST,\nCoLU had a 4.20% higher accuracy than Mish and 3.31% higher accuracy than ReLU.\nOn ResNet-9 trained on Cifar-10, CoLU had 0.05% higher accuracy than Swish,\n0.09% higher accuracy than Mish, and 0.29% higher accuracy than ReLU. It is\nobserved that activation functions may behave better than other activation\nfunctions based on different factors including the number of layers, types of\nlayers, number of parameters, learning rate, optimizer, etc. Further research\ncan be done on these factors and activation functions for more optimal\nactivation functions and more knowledge on their behavior.",
          "arxiv_id": "2112.12078v1"
        },
        {
          "title": "Data-aware customization of activation functions reduces neural network error",
          "year": "2023-01",
          "abstract": "Activation functions play critical roles in neural networks, yet current\noff-the-shelf neural networks pay little attention to the specific choice of\nactivation functions used. Here we show that data-aware customization of\nactivation functions can result in striking reductions in neural network error.\nWe first give a simple linear algebraic explanation of the role of activation\nfunctions in neural networks; then, through connection with the\nDiaconis-Shahshahani Approximation Theorem, we propose a set of criteria for\ngood activation functions. As a case study, we consider regression tasks with a\npartially exchangeable target function, \\emph{i.e.} $f(u,v,w)=f(v,u,w)$ for\n$u,v\\in \\mathbb{R}^d$ and $w\\in \\mathbb{R}^k$, and prove that for such a target\nfunction, using an even activation function in at least one of the layers\nguarantees that the prediction preserves partial exchangeability for best\nperformance. Since even activation functions are seldom used in practice, we\ndesigned the ``seagull'' even activation function $\\log(1+x^2)$ according to\nour criteria. Empirical testing on over two dozen 9-25 dimensional examples\nwith different local smoothness, curvature, and degree of exchangeability\nrevealed that a simple substitution with the ``seagull'' activation function in\nan already-refined neural network can lead to an order-of-magnitude reduction\nin error. This improvement was most pronounced when the activation function\nsubstitution was applied to the layer in which the exchangeable variables are\nconnected for the first time. While the improvement is greatest for\nlow-dimensional data, experiments on the CIFAR10 image classification dataset\nshowed that use of ``seagull'' can reduce error even for high-dimensional\ncases. These results collectively highlight the potential of customizing\nactivation functions as a general approach to improve neural network\nperformance.",
          "arxiv_id": "2301.06635v1"
        }
      ],
      "4": [
        {
          "title": "DFSynthesizer: Dataflow-based Synthesis of Spiking Neural Networks to Neuromorphic Hardware",
          "year": "2021-08",
          "abstract": "Spiking Neural Networks (SNN) are an emerging computation model, which uses\nevent-driven activation and bio-inspired learning algorithms. SNN-based\nmachine-learning programs are typically executed on tile- based neuromorphic\nhardware platforms, where each tile consists of a computation unit called\ncrossbar, which maps neurons and synapses of the program. However, synthesizing\nsuch programs on an off-the-shelf neuromorphic hardware is challenging. This is\nbecause of the inherent resource and latency limitations of the hardware, which\nimpact both model performance, e.g., accuracy, and hardware performance, e.g.,\nthroughput. We propose DFSynthesizer, an end-to-end framework for synthesizing\nSNN-based machine learning programs to neuromorphic hardware. The proposed\nframework works in four steps. First, it analyzes a machine-learning program\nand generates SNN workload using representative data. Second, it partitions the\nSNN workload and generates clusters that fit on crossbars of the target\nneuromorphic hardware. Third, it exploits the rich semantics of Synchronous\nDataflow Graph (SDFG) to represent a clustered SNN program, allowing for\nperformance analysis in terms of key hardware constraints such as number of\ncrossbars, dimension of each crossbar, buffer space on tiles, and tile\ncommunication bandwidth. Finally, it uses a novel scheduling algorithm to\nexecute clusters on crossbars of the hardware, guaranteeing hardware\nperformance. We evaluate DFSynthesizer with 10 commonly used machine-learning\nprograms. Our results demonstrate that DFSynthesizer provides much tighter\nperformance guarantee compared to current mapping approaches.",
          "arxiv_id": "2108.02023v1"
        },
        {
          "title": "Thermal-Aware Compilation of Spiking Neural Networks to Neuromorphic Hardware",
          "year": "2020-10",
          "abstract": "Hardware implementation of neuromorphic computing can significantly improve\nperformance and energy efficiency of machine learning tasks implemented with\nspiking neural networks (SNNs), making these hardware platforms particularly\nsuitable for embedded systems and other energy-constrained environments. We\nobserve that the long bitlines and wordlines in a crossbar of the hardware\ncreate significant current variations when propagating spikes through its\nsynaptic elements, which are typically designed with non-volatile memory (NVM).\nSuch current variations create a thermal gradient within each crossbar of the\nhardware, depending on the machine learning workload and the mapping of neurons\nand synapses of the workload to these crossbars. \\mr{This thermal gradient\nbecomes significant at scaled technology nodes and it increases the leakage\npower in the hardware leading to an increase in the energy consumption.} We\npropose a novel technique to map neurons and synapses of SNN-based machine\nlearning workloads to neuromorphic hardware. We make two novel contributions.\nFirst, we formulate a detailed thermal model for a crossbar in a neuromorphic\nhardware incorporating workload dependency, where the temperature of each\nNVM-based synaptic cell is computed considering the thermal contributions from\nits neighboring cells. Second, we incorporate this thermal model in the mapping\nof neurons and synapses of SNN-based workloads using a hill-climbing heuristic.\nThe objective is to reduce the thermal gradient in crossbars. We evaluate our\nneuron and synapse mapping technique using 10 machine learning workloads for a\nstate-of-the-art neuromorphic hardware. We demonstrate an average 11.4K\nreduction in the average temperature of each crossbar in the hardware, leading\nto a 52% reduction in the leakage power consumption (11% lower total energy\nconsumption) compared to a performance-oriented SNN mapping technique.",
          "arxiv_id": "2010.04773v2"
        },
        {
          "title": "Bridging Quantized Artificial Neural Networks and Neuromorphic Hardware",
          "year": "2025-05",
          "abstract": "Neuromorphic hardware aims to leverage distributed computing and event-driven\ncircuit design to achieve an energy-efficient AI system. The name\n\"neuromorphic\" is derived from its spiking and local computing nature, which\nmimics the fundamental activity of an animal's nervous system. In neuromorphic\nhardware, neurons, i.e., computing cores use single-bit, event-driven data\n(called spikes) for inter-communication, which differs substantially from\nconventional hardware. To leverage the advantages of neuromorphic hardware and\nimplement a computing model, the conventional approach is to build spiking\nneural networks (SNNs). SNNs replace the nonlinearity part of artificial neural\nnetworks (ANNs) in the realm of deep learning with spiking neurons, where the\nspiking neuron mimics the basic behavior of bio-neurons. However, there is\nstill a performance gap between SNNs and their ANN counterparts. In this paper,\nwe explore a new way to map computing models onto neuromorphic hardware. We\npropose a Spiking-Driven ANN (SDANN) framework that directly implements\nquantized ANN on hardware, eliminating the need for tuning the trainable\nparameters or any performance degradation. With the power of quantized ANN, our\nSDANN ensures a lower bound of implementation performance on neuromorphic\nhardware. To address the limitation of bit width support on hardware, we\npropose bias calibration and scaled integration methods. Experiments on various\ntasks demonstrate that our SDANN achieves exactly the same accuracy as the\nquantized ANN. Beyond toy examples and software implementation, we successfully\ndeployed and validated our spiking models on real neuromorphic hardware,\ndemonstrating the feasibility of the SDANN framework.",
          "arxiv_id": "2505.12221v2"
        }
      ],
      "5": [
        {
          "title": "Evolving Code with A Large Language Model",
          "year": "2024-01",
          "abstract": "Algorithms that use Large Language Models (LLMs) to evolve code arrived on\nthe Genetic Programming (GP) scene very recently. We present LLM GP, a\nformalized LLM-based evolutionary algorithm designed to evolve code. Like GP,\nit uses evolutionary operators, but its designs and implementations of those\noperators radically differ from GP's because they enlist an LLM, using\nprompting and the LLM's pre-trained pattern matching and sequence completion\ncapability. We also present a demonstration-level variant of LLM GP and share\nits code. By addressing algorithms that range from the formal to hands-on, we\ncover design and LLM-usage considerations as well as the scientific challenges\nthat arise when using an LLM for genetic programming.",
          "arxiv_id": "2401.07102v1"
        },
        {
          "title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
          "year": "2024-04",
          "abstract": "Mathematical equations have been unreasonably effective in describing complex\nnatural phenomena across various scientific disciplines. However, discovering\nsuch insightful equations from data presents significant challenges due to the\nnecessity of navigating extremely large combinatorial hypothesis spaces.\nCurrent methods of equation discovery, commonly known as symbolic regression\ntechniques, largely focus on extracting equations from data alone, often\nneglecting the domain-specific prior knowledge that scientists typically depend\non. They also employ limited representations such as expression trees,\nconstraining the search space and expressiveness of equations. To bridge this\ngap, we introduce LLM-SR, a novel approach that leverages the extensive\nscientific knowledge and robust code generation capabilities of Large Language\nModels (LLMs) to discover scientific equations from data. Specifically, LLM-SR\ntreats equations as programs with mathematical operators and combines LLMs'\nscientific priors with evolutionary search over equation programs. The LLM\niteratively proposes new equation skeleton hypotheses, drawing from its domain\nknowledge, which are then optimized against data to estimate parameters. We\nevaluate LLM-SR on four benchmark problems across diverse scientific domains\n(e.g., physics, biology), which we carefully designed to simulate the discovery\nprocess and prevent LLM recitation. Our results demonstrate that LLM-SR\ndiscovers physically accurate equations that significantly outperform\nstate-of-the-art symbolic regression baselines, particularly in out-of-domain\ntest settings. We also show that LLM-SR's incorporation of scientific priors\nenables more efficient equation space exploration than the baselines. Code and\ndata are available: https://github.com/deep-symbolic-mathematics/LLM-SR",
          "arxiv_id": "2404.18400v3"
        },
        {
          "title": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression",
          "year": "2025-05",
          "abstract": "Large language models (LLMs) have revolutionized algorithm development, yet\ntheir application in symbolic regression, where algorithms automatically\ndiscover symbolic expressions from data, remains constrained and is typically\ndesigned manually by human experts. In this paper, we propose a meta learning\nframework that enables LLMs to automatically design selection operators for\nevolutionary symbolic regression algorithms. We first identify two key\nlimitations in existing LLM-based algorithm evolution techniques: a lack of\nsemantic guidance and code bloat. The absence of semantic awareness can lead to\nineffective exchange of useful code components, and bloat results in\nunnecessarily complex components, both of which can reduce the interpretability\nof the designed algorithm or hinder evolutionary learning progress. To address\nthese issues, we enhance the LLM-based evolution framework for meta symbolic\nregression with two key innovations: a complementary, semantics-aware selection\noperator and bloat control. Additionally, we embed domain knowledge into the\nprompt, enabling the LLM to generate more effective and contextually relevant\nselection operators. Our experimental results on symbolic regression benchmarks\nshow that LLMs can devise selection operators that outperform nine\nexpert-designed baselines, achieving state-of-the-art performance. Moreover,\nthe evolved operator can further improve the state-of-the-art symbolic\nregression algorithm, achieving the best performance among 26 symbolic\nregression and machine learning algorithms across 116 regression datasets. This\ndemonstrates that LLMs can exceed expert-level algorithm design for symbolic\nregression.",
          "arxiv_id": "2505.18602v2"
        }
      ],
      "6": [
        {
          "title": "A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism",
          "year": "2024-07",
          "abstract": "Neural architecture search (NAS) enables researchers to automatically explore\nvast search spaces and find efficient neural networks. But NAS suffers from a\nkey bottleneck, i.e., numerous architectures need to be evaluated during the\nsearch process, which requires a lot of computing resources and time. In order\nto improve the efficiency of NAS, a series of methods have been proposed to\nreduce the evaluation time of neural architectures. However, they are not\nefficient enough and still only focus on the accuracy of architectures. In\naddition to the classification accuracy, more efficient and smaller network\narchitectures are required in real-world applications. To address the above\nproblems, we propose the SMEM-NAS, a pairwise comparison relation-assisted\nmulti-objective evolutionary algorithm based on a multi-population mechanism.\nIn the SMEM-NAS, a surrogate model is constructed based on pairwise comparison\nrelations to predict the accuracy ranking of architectures, rather than the\nabsolute accuracy. Moreover, two populations cooperate with each other in the\nsearch process, i.e., a main population guides the evolution, while a vice\npopulation expands the diversity. Our method aims to provide high-performance\nmodels that take into account multiple optimization objectives. We conduct a\nseries of experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets to\nverify its effectiveness. With only a single GPU searching for 0.17 days,\ncompetitive architectures can be found by SMEM-NAS which achieves 78.91%\naccuracy with the MAdds of 570M on the ImageNet. This work makes a significant\nadvance in the important field of NAS. Our code is publicly available at\nhttps://github.com/ccz-enas/SMEM-NAS.",
          "arxiv_id": "2407.15600v2"
        },
        {
          "title": "Few-shot Neural Architecture Search",
          "year": "2020-06",
          "abstract": "Efficient evaluation of a network architecture drawn from a large search\nspace remains a key challenge in Neural Architecture Search (NAS). Vanilla NAS\nevaluates each architecture by training from scratch, which gives the true\nperformance but is extremely time-consuming. Recently, one-shot NAS\nsubstantially reduces the computation cost by training only one supernetwork,\na.k.a. supernet, to approximate the performance of every architecture in the\nsearch space via weight-sharing. However, the performance estimation can be\nvery inaccurate due to the co-adaption among operations. In this paper, we\npropose few-shot NAS that uses multiple supernetworks, called sub-supernet,\neach covering different regions of the search space to alleviate the undesired\nco-adaption. Compared to one-shot NAS, few-shot NAS improves the accuracy of\narchitecture evaluation with a small increase of evaluation cost. With only up\nto 7 sub-supernets, few-shot NAS establishes new SoTAs: on ImageNet, it finds\nmodels that reach 80.5% top-1 accuracy at 600 MB FLOPS and 77.5% top-1 accuracy\nat 238 MFLOPS; on CIFAR10, it reaches 98.72% top-1 accuracy without using extra\ndata or transfer learning. In Auto-GAN, few-shot NAS outperforms the previously\npublished results by up to 20%. Extensive experiments show that few-shot NAS\nsignificantly improves various one-shot methods, including 4 gradient-based and\n6 search-based methods on 3 different tasks in NasBench-201 and\nNasBench1-shot-1.",
          "arxiv_id": "2006.06863v9"
        },
        {
          "title": "ADWPNAS: Architecture-Driven Weight Prediction for Neural Architecture Search",
          "year": "2020-03",
          "abstract": "How to discover and evaluate the true strength of models quickly and\naccurately is one of the key challenges in Neural Architecture Search (NAS). To\ncope with this problem, we propose an Architecture-Driven Weight Prediction\n(ADWP) approach for neural architecture search (NAS). In our approach, we first\ndesign an architecture-intensive search space and then train a HyperNetwork by\ninputting stochastic encoding architecture parameters. In the trained\nHyperNetwork, weights of convolution kernels can be well predicted for neural\narchitectures in the search space. Consequently, the target architectures can\nbe evaluated efficiently without any finetuning, thus enabling us to search\nfortheoptimalarchitectureinthespaceofgeneralnetworks (macro-search). Through\nreal experiments, we evaluate the performance of the models discovered by the\nproposed AD-WPNAS and results show that one search procedure can be completed\nin 4.0 GPU hours on CIFAR-10. Moreover, the discovered model obtains a test\nerror of 2.41% with only 1.52M parameters which is superior to the best\nexisting models.",
          "arxiv_id": "2003.01335v1"
        }
      ],
      "7": [
        {
          "title": "Black-box adversarial attacks using Evolution Strategies",
          "year": "2021-04",
          "abstract": "In the last decade, deep neural networks have proven to be very powerful in\ncomputer vision tasks, starting a revolution in the computer vision and machine\nlearning fields. However, deep neural networks, usually, are not robust to\nperturbations of the input data. In fact, several studies showed that slightly\nchanging the content of the images can cause a dramatic decrease in the\naccuracy of the attacked neural network. Several methods able to generate\nadversarial samples make use of gradients, which usually are not available to\nan attacker in real-world scenarios. As opposed to this class of attacks,\nanother class of adversarial attacks, called black-box adversarial attacks,\nemerged, which does not make use of information on the gradients, being more\nsuitable for real-world attack scenarios. In this work, we compare three\nwell-known evolution strategies on the generation of black-box adversarial\nattacks for image classification tasks. While our results show that the\nattacked neural networks can be, in most cases, easily fooled by all the\nalgorithms under comparison, they also show that some black-box optimization\nalgorithms may be better in \"harder\" setups, both in terms of attack success\nrate and efficiency (i.e., number of queries).",
          "arxiv_id": "2104.15064v1"
        },
        {
          "title": "Multi-objective Search of Robust Neural Architectures against Multiple Types of Adversarial Attacks",
          "year": "2021-01",
          "abstract": "Many existing deep learning models are vulnerable to adversarial examples\nthat are imperceptible to humans. To address this issue, various methods have\nbeen proposed to design network architectures that are robust to one particular\ntype of adversarial attacks. It is practically impossible, however, to predict\nbeforehand which type of attacks a machine learn model may suffer from. To\naddress this challenge, we propose to search for deep neural architectures that\nare robust to five types of well-known adversarial attacks using a\nmulti-objective evolutionary algorithm. To reduce the computational cost, a\nnormalized error rate of a randomly chosen attack is calculated as the\nrobustness for each newly generated neural architecture at each generation. All\nnon-dominated network architectures obtained by the proposed method are then\nfully trained against randomly chosen adversarial attacks and tested on two\nwidely used datasets. Our experimental results demonstrate the superiority of\noptimized neural architectures found by the proposed approach over\nstate-of-the-art networks that are widely used in the literature in terms of\nthe classification accuracy under different adversarial attacks.",
          "arxiv_id": "2101.06507v1"
        },
        {
          "title": "Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding",
          "year": "2024-10",
          "abstract": "An adversarial example is a modified input image designed to cause a Machine\nLearning (ML) model to make a mistake; these perturbations are often invisible\nor subtle to human observers and highlight vulnerabilities in a model's ability\nto generalize from its training data. Several adversarial attacks can create\nsuch examples, each with a different perspective, effectiveness, and\nperceptibility of changes. Conversely, defending against such adversarial\nattacks improves the robustness of ML models in image processing and other\ndomains of deep learning. Most defence mechanisms require either a level of\nmodel awareness, changes to the model, or access to a comprehensive set of\nadversarial examples during training, which is impractical. Another option is\nto use an auxiliary model in a preprocessing manner without changing the\nprimary model. This study presents a practical and effective solution -- using\npredictive coding networks (PCnets) as an auxiliary step for adversarial\ndefence. By seamlessly integrating PCnets into feed-forward networks as a\npreprocessing step, we substantially bolster resilience to adversarial\nperturbations. Our experiments on MNIST and CIFAR10 demonstrate the remarkable\neffectiveness of PCnets in mitigating adversarial examples with about 82% and\n65% improvements in robustness, respectively. The PCnet, trained on a small\nsubset of the dataset, leverages its generative nature to effectively counter\nadversarial efforts, reverting perturbed images closer to their original forms.\nThis innovative approach holds promise for enhancing the security and\nreliability of neural network classifiers in the face of the escalating threat\nof adversarial attacks.",
          "arxiv_id": "2411.00222v1"
        }
      ],
      "8": [
        {
          "title": "Counter-Current Learning: A Biologically Plausible Dual Network Approach for Deep Learning",
          "year": "2024-09",
          "abstract": "Despite its widespread use in neural networks, error backpropagation has\nfaced criticism for its lack of biological plausibility, suffering from issues\nsuch as the backward locking problem and the weight transport problem. These\nlimitations have motivated researchers to explore more biologically plausible\nlearning algorithms that could potentially shed light on how biological neural\nsystems adapt and learn. Inspired by the counter-current exchange mechanisms\nobserved in biological systems, we propose counter-current learning (CCL), a\nbiologically plausible framework for credit assignment in neural networks. This\nframework employs a feedforward network to process input data and a feedback\nnetwork to process targets, with each network enhancing the other through\nanti-parallel signal propagation. By leveraging the more informative signals\nfrom the bottom layer of the feedback network to guide the updates of the top\nlayer of the feedforward network and vice versa, CCL enables the simultaneous\ntransformation of source inputs to target outputs and the dynamic mutual\ninfluence of these transformations. Experimental results on MNIST,\nFashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons and\nconvolutional neural networks demonstrate that CCL achieves comparable\nperformance to other biologically plausible algorithms while offering a more\nbiologically realistic learning mechanism. Furthermore, we showcase the\napplicability of our approach to an autoencoder task, underscoring its\npotential for unsupervised representation learning. Our work presents a\ndirection for biologically inspired and plausible learning algorithms, offering\nan alternative mechanism of learning and adaptation in neural networks.",
          "arxiv_id": "2409.19841v2"
        },
        {
          "title": "Biological learning in key-value memory networks",
          "year": "2021-10",
          "abstract": "In neuroscience, classical Hopfield networks are the standard biologically\nplausible model of long-term memory, relying on Hebbian plasticity for storage\nand attractor dynamics for recall. In contrast, memory-augmented neural\nnetworks in machine learning commonly use a key-value mechanism to store and\nread out memories in a single step. Such augmented networks achieve impressive\nfeats of memory compared to traditional variants, yet their biological\nrelevance is unclear. We propose an implementation of basic key-value memory\nthat stores inputs using a combination of biologically plausible three-factor\nplasticity rules. The same rules are recovered when network parameters are\nmeta-learned. Our network performs on par with classical Hopfield networks on\nautoassociative memory tasks and can be naturally extended to continual recall,\nheteroassociative memory, and sequence learning. Our results suggest a\ncompelling alternative to the classical Hopfield network as a model of\nbiological long-term memory.",
          "arxiv_id": "2110.13976v1"
        },
        {
          "title": "Unsupervised representation learning with Hebbian synaptic and structural plasticity in brain-like feedforward neural networks",
          "year": "2024-06",
          "abstract": "Neural networks that can capture key principles underlying brain computation\noffer exciting new opportunities for developing artificial intelligence and\nbrain-like computing algorithms. Such networks remain biologically plausible\nwhile leveraging localized forms of synaptic learning rules and modular network\narchitecture found in the neocortex. Compared to backprop-driven deep learning\napproches, they provide more suitable models for deployment of neuromorphic\nhardware and have greater potential for scalability on large-scale computing\nclusters. The development of such brain-like neural networks depends on having\na learning procedure that can build effective internal representations from\ndata. In this work, we introduce and evaluate a brain-like neural network model\ncapable of unsupervised representation learning. It builds on the Bayesian\nConfidence Propagation Neural Network (BCPNN), which has earlier been\nimplemented as abstract as well as biophyscially detailed recurrent attractor\nneural networks explaining various cortical associative memory phenomena. Here\nwe developed a feedforward BCPNN model to perform representation learning by\nincorporating a range of brain-like attributes derived from neocortical\ncircuits such as cortical columns, divisive normalization, Hebbian synaptic\nplasticity, structural plasticity, sparse activity, and sparse patchy\nconnectivity. The model was tested on a diverse set of popular machine learning\nbenchmarks: grayscale images (MNIST, F-MNIST), RGB natural images (SVHN,\nCIFAR-10), QSAR (MUV, HIV), and malware detection (EMBER). The performance of\nthe model when using a linear classifier to predict the class labels fared\ncompetitively with conventional multi-layer perceptrons and other\nstate-of-the-art brain-like neural networks.",
          "arxiv_id": "2406.04733v2"
        }
      ],
      "9": [
        {
          "title": "Convolution-enhanced Evolving Attention Networks",
          "year": "2022-12",
          "abstract": "Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations , wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention.",
          "arxiv_id": "2212.08330v2"
        },
        {
          "title": "Multi-task Language Modeling for Improving Speech Recognition of Rare Words",
          "year": "2020-11",
          "abstract": "End-to-end automatic speech recognition (ASR) systems are increasingly\npopular due to their relative architectural simplicity and competitive\nperformance. However, even though the average accuracy of these systems may be\nhigh, the performance on rare content words often lags behind hybrid ASR\nsystems. To address this problem, second-pass rescoring is often applied\nleveraging upon language modeling. In this paper, we propose a second-pass\nsystem with multi-task learning, utilizing semantic targets (such as intent and\nslot prediction) to improve speech recognition performance. We show that our\nrescoring model trained with these additional tasks outperforms the baseline\nrescoring model, trained with only the language modeling task, by 1.4% on a\ngeneral test and by 2.6% on a rare word test set in terms of word-error-rate\nrelative (WERR). Our best ASR system with multi-task LM shows 4.6% WERR\ndeduction compared with RNN Transducer only ASR baseline for rare words\nrecognition.",
          "arxiv_id": "2011.11715v4"
        },
        {
          "title": "From English to More Languages: Parameter-Efficient Model Reprogramming for Cross-Lingual Speech Recognition",
          "year": "2023-01",
          "abstract": "In this work, we propose a new parameter-efficient learning framework based\non neural model reprogramming for cross-lingual speech recognition, which can\n\\textbf{re-purpose} well-trained English automatic speech recognition (ASR)\nmodels to recognize the other languages. We design different auxiliary neural\narchitectures focusing on learnable pre-trained feature enhancement that, for\nthe first time, empowers model reprogramming on ASR. Specifically, we\ninvestigate how to select trainable components (i.e., encoder) of a\nconformer-based RNN-Transducer, as a frozen pre-trained backbone. Experiments\non a seven-language multilingual LibriSpeech speech (MLS) task show that model\nreprogramming only requires 4.2% (11M out of 270M) to 6.8% (45M out of 660M) of\nits original trainable parameters from a full ASR model to perform competitive\nresults in a range of 11.9% to 8.1% WER averaged across different languages. In\naddition, we discover different setups to make large-scale pre-trained ASR\nsucceed in both monolingual and multilingual speech recognition. Our methods\noutperform existing ASR tuning architectures and their extension with\nself-supervised losses (e.g., w2v-bert) in terms of lower WER and better\ntraining efficiency.",
          "arxiv_id": "2301.07851v1"
        }
      ],
      "10": [
        {
          "title": "RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices",
          "year": "2020-07",
          "abstract": "Mobile devices are becoming an important carrier for deep learning tasks, as\nthey are being equipped with powerful, high-end mobile CPUs and GPUs. However,\nit is still a challenging task to execute 3D Convolutional Neural Networks\n(CNNs) targeting for real-time performance, besides high inference accuracy.\nThe reason is more complex model structure and higher model dimensionality\noverwhelm the available computation/storage resources on mobile devices. A\nnatural way may be turning to deep learning weight pruning techniques. However,\nthe direct generalization of existing 2D CNN weight pruning methods to 3D CNNs\nis not ideal for fully exploiting mobile parallelism while achieving high\ninference accuracy.\n  This paper proposes RT3D, a model compression and mobile acceleration\nframework for 3D CNNs, seamlessly integrating neural network weight pruning and\ncompiler code generation techniques. We propose and investigate two structured\nsparsity schemes i.e., the vanilla structured sparsity and kernel group\nstructured (KGS) sparsity that are mobile acceleration friendly. The vanilla\nsparsity removes whole kernel groups, while KGS sparsity is a more fine-grained\nstructured sparsity that enjoys higher flexibility while exploiting full\non-device parallelism. We propose a reweighted regularization pruning algorithm\nto achieve the proposed sparsity schemes. The inference time speedup due to\nsparsity is approaching the pruning rate of the whole model FLOPs (floating\npoint operations). RT3D demonstrates up to 29.1$\\times$ speedup in end-to-end\ninference time comparing with current mobile frameworks supporting 3D CNNs,\nwith moderate 1%-1.5% accuracy loss. The end-to-end inference time for 16 video\nframes could be within 150 ms, when executing representative C3D and R(2+1)D\nmodels on a cellphone. For the first time, real-time execution of 3D CNNs is\nachieved on off-the-shelf mobiles.",
          "arxiv_id": "2007.09835v2"
        },
        {
          "title": "EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks",
          "year": "2020-06",
          "abstract": "Dropout is a well-known regularization method by sampling a sub-network from\na larger deep neural network and training different sub-networks on different\nsubsets of the data. Inspired by the dropout concept, we propose EDropout as an\nenergy-based framework for pruning neural networks in classification tasks. In\nthis approach, a set of binary pruning state vectors (population) represents a\nset of corresponding sub-networks from an arbitrary provided original neural\nnetwork. An energy loss function assigns a scalar energy loss value to each\npruning state. The energy-based model stochastically evolves the population to\nfind states with lower energy loss. The best pruning state is then selected and\napplied to the original network. Similar to dropout, the kept weights are\nupdated using backpropagation in a probabilistic model. The energy-based model\nagain searches for better pruning states and the cycle continuous. Indeed, this\nprocedure is in fact switching between the energy model, which manages the\npruning states, and the probabilistic model, which updates the temporarily\nunpruned weights, in each iteration. The population can dynamically converge to\na pruning state. This can be interpreted as dropout leading to pruning the\nnetwork. From an implementation perspective, EDropout can prune typical neural\nnetworks without modification of the network architecture. We evaluated the\nproposed method on different flavours of ResNets, AlexNet, and SqueezeNet on\nthe Kuzushiji, Fashion, CIFAR-10, CIFAR-100, and Flowers datasets, and compared\nthe pruning rate and classification performance of the models. On average the\nnetworks trained with EDropout achieved a pruning rate of more than $50\\%$ of\nthe trainable parameters with approximately $<5\\%$ and $<1\\%$ drop of Top-1 and\nTop-5 classification accuracy, respectively.",
          "arxiv_id": "2006.04270v5"
        },
        {
          "title": "Integrating Pruning with Quantization for Efficient Deep Neural Networks Compression",
          "year": "2025-09",
          "abstract": "Deep Neural Networks (DNNs) have achieved significant advances in a wide\nrange of applications. However, their deployment on resource-constrained\ndevices remains a challenge due to the large number of layers and parameters,\nwhich result in considerable computational and memory demands. To address this\nissue, pruning and quantization are two widely used compression techniques,\ncommonly applied individually in most studies to reduce model size and enhance\nprocessing speed. Nevertheless, combining these two techniques can yield even\ngreater compression benefits. Effectively integrating pruning and quantization\nto harness their complementary advantages poses a challenging task, primarily\ndue to their potential impact on model accuracy and the complexity of jointly\noptimizing both processes. In this paper, we propose two approaches that\nintegrate similarity-based filter pruning with Adaptive Power-of-Two (APoT)\nquantization to achieve higher compression efficiency while preserving model\naccuracy. In the first approach, pruning and quantization are applied\nsimultaneously during training. In the second approach, pruning is performed\nfirst to remove less important parameters, followed by quantization of the\npruned model using low-bit representations. Experimental results demonstrate\nthat our proposed approaches achieve effective model compression with minimal\naccuracy degradation, making them well-suited for deployment on devices with\nlimited computational resources.",
          "arxiv_id": "2509.04244v1"
        }
      ],
      "11": [
        {
          "title": "Towards Optimally Weighted Physics-Informed Neural Networks in Ocean Modelling",
          "year": "2021-06",
          "abstract": "The carbon pump of the world's ocean plays a vital role in the biosphere and\nclimate of the earth, urging improved understanding of the functions and\ninfluences of the ocean for climate change analyses. State-of-the-art\ntechniques are required to develop models that can capture the complexity of\nocean currents and temperature flows. This work explores the benefits of using\nphysics-informed neural networks (PINNs) for solving partial differential\nequations related to ocean modeling; such as the Burgers, wave, and\nadvection-diffusion equations. We explore the trade-offs of using data vs.\nphysical models in PINNs for solving partial differential equations. PINNs\naccount for the deviation from physical laws in order to improve learning and\ngeneralization. We observed how the relative weight between the data and\nphysical model in the loss function influence training results, where small\ndata sets benefit more from the added physics information.",
          "arxiv_id": "2106.08747v1"
        },
        {
          "title": "Discovering Physics-Informed Neural Networks Model for Solving Partial Differential Equations through Evolutionary Computation",
          "year": "2024-05",
          "abstract": "In recent years, the researches about solving partial differential equations\n(PDEs) based on artificial neural network have attracted considerable\nattention. In these researches, the neural network models are usually designed\ndepend on human experience or trial and error. Despite the emergence of several\nmodel searching methods, these methods primarily concentrate on optimizing the\nhyperparameters of fully connected neural network model based on the framework\nof physics-informed neural networks (PINNs), and the corresponding search\nspaces are relatively restricted, thereby limiting the exploration of superior\nmodels. This article proposes an evolutionary computation method aimed at\ndiscovering the PINNs model with higher approximation accuracy and faster\nconvergence rate. In addition to searching the numbers of layers and neurons\nper hidden layer, this method concurrently explores the optimal shortcut\nconnections between the layers and the novel parametric activation functions\nexpressed by the binary trees. In evolution, the strategy about dynamic\npopulation size and training epochs (DPSTE) is adopted, which significantly\nincreases the number of models to be explored and facilitates the discovery of\nmodels with fast convergence rate. In experiments, the performance of different\nmodels that are searched through Bayesian optimization, random search and\nevolution is compared in solving Klein-Gordon, Burgers, and Lam\\'e equations.\nThe experimental results affirm that the models discovered by the proposed\nevolutionary computation method generally exhibit superior approximation\naccuracy and convergence rate, and these models also show commendable\ngeneralization performance with respect to the source term, initial and\nboundary conditions, equation coefficient and computational domain. The\ncorresponding code is available at\nhttps://github.com/MathBon/Discover-PINNs-Model.",
          "arxiv_id": "2405.11208v1"
        },
        {
          "title": "A Dimension-Augmented Physics-Informed Neural Network (DaPINN) with High Level Accuracy and Efficiency",
          "year": "2022-10",
          "abstract": "Physics-informed neural networks (PINNs) have been widely applied in\ndifferent fields due to their effectiveness in solving partial differential\nequations (PDEs). However, the accuracy and efficiency of PINNs need to be\nconsiderably improved for scientific and commercial use. To address this issue,\nwe systematically propose a novel dimension-augmented physics-informed neural\nnetwork (DaPINN), which simultaneously and significantly improves the accuracy\nand efficiency of the PINN. In the DaPINN model, we introduce inductive bias in\nthe neural network to enhance network generalizability by adding a special\nregularization term to the loss function. Furthermore, we manipulate the\nnetwork input dimension by inserting additional sample features and\nincorporating the expanded dimensionality in the loss function. Moreover, we\nverify the effectiveness of power series augmentation, Fourier series\naugmentation and replica augmentation, in both forward and backward problems.\nIn most experiments, the error of DaPINN is 1$\\sim$2 orders of magnitude lower\nthan that of PINN. The results show that the DaPINN outperforms the original\nPINN in terms of both accuracy and efficiency with a reduced dependence on the\nnumber of sample points. We also discuss the complexity of the DaPINN and its\ncompatibility with other methods.",
          "arxiv_id": "2210.13212v1"
        }
      ],
      "12": [
        {
          "title": "Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning",
          "year": "2020-08",
          "abstract": "Time-series forecasting is one of the most active research topics in\nartificial intelligence. Applications in real-world time series should consider\ntwo factors for achieving reliable predictions: modeling dynamic dependencies\namong multiple variables and adjusting the model's intrinsic hyperparameters. A\nstill open gap in that literature is that statistical and ensemble learning\napproaches systematically present lower predictive performance than deep\nlearning methods. They generally disregard the data sequence aspect entangled\nwith multivariate data represented in more than one time series. Conversely,\nthis work presents a novel neural network architecture for time-series\nforecasting that combines the power of graph evolution with deep recurrent\nlearning on distinct data distributions; we named our method Recurrent Graph\nEvolution Neural Network (ReGENN). The idea is to infer multiple multivariate\nrelationships between co-occurring time-series by assuming that the temporal\ndata depends not only on inner variables and intra-temporal relationships\n(i.e., observations from itself) but also on outer variables and inter-temporal\nrelationships (i.e., observations from other-selves). An extensive set of\nexperiments was conducted comparing ReGENN with dozens of ensemble methods and\nclassical statistical ones, showing sound improvement of up to 64.87% over the\ncompeting algorithms. Furthermore, we present an analysis of the intermediate\nweights arising from ReGENN, showing that by looking at inter and\nintra-temporal relationships simultaneously, time-series forecasting is majorly\nimproved if paying attention to how multiple multivariate data synchronously\nevolve.",
          "arxiv_id": "2008.12833v4"
        },
        {
          "title": "MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time Series",
          "year": "2022-05",
          "abstract": "In this paper, we introduce Masked Anomaly Detection (MAD), a general\nself-supervised learning task for multivariate time series anomaly detection.\nWith the increasing availability of sensor data from industrial systems, being\nable to detecting anomalies from streams of multivariate time series data is of\nsignificant importance. Given the scarcity of anomalies in real-world\napplications, the majority of literature has been focusing on modeling\nnormality. The learned normal representations can empower anomaly detection as\nthe model has learned to capture certain key underlying data regularities. A\ntypical formulation is to learn a predictive model, i.e., use a window of time\nseries data to predict future data values. In this paper, we propose an\nalternative self-supervised learning task. By randomly masking a portion of the\ninputs and training a model to estimate them using the remaining ones, MAD is\nan improvement over the traditional left-to-right next step prediction (NSP)\ntask. Our experimental results demonstrate that MAD can achieve better anomaly\ndetection rates over traditional NSP approaches when using exactly the same\nneural network (NN) base models, and can be modified to run as fast as NSP\nmodels during test time on the same hardware, thus making it an ideal upgrade\nfor many existing NSP-based NN anomaly detection models.",
          "arxiv_id": "2205.02100v1"
        },
        {
          "title": "Online Evolutionary Neural Architecture Search for Multivariate Non-Stationary Time Series Forecasting",
          "year": "2023-02",
          "abstract": "Time series forecasting (TSF) is one of the most important tasks in data\nscience given the fact that accurate time series (TS) predictive models play a\nmajor role across a wide variety of domains including finance, transportation,\nhealth care, and power systems. Real-world utilization of machine learning (ML)\ntypically involves (pre-)training models on collected, historical data and then\napplying them to unseen data points. However, in real-world applications, time\nseries data streams are usually non-stationary and trained ML models usually,\nover time, face the problem of data or concept drift.\n  To address this issue, models must be periodically retrained or redesigned,\nwhich takes significant human and computational resources. Additionally,\nhistorical data may not even exist to re-train or re-design model with. As a\nresult, it is highly desirable that models are designed and trained in an\nonline fashion. This work presents the Online NeuroEvolution-based Neural\nArchitecture Search (ONE-NAS) algorithm, which is a novel neural architecture\nsearch method capable of automatically designing and dynamically training\nrecurrent neural networks (RNNs) for online forecasting tasks. Without any\npre-training, ONE-NAS utilizes populations of RNNs that are continuously\nupdated with new network structures and weights in response to new multivariate\ninput data. ONE-NAS is tested on real-world, large-scale multivariate wind\nturbine data as well as the univariate Dow Jones Industrial Average (DJIA)\ndataset. Results demonstrate that ONE-NAS outperforms traditional statistical\ntime series forecasting methods, including online linear regression, fixed long\nshort-term memory (LSTM) and gated recurrent unit (GRU) models trained online,\nas well as state-of-the-art, online ARIMA strategies.",
          "arxiv_id": "2302.10347v1"
        }
      ],
      "13": [
        {
          "title": "Deep Learning Neural Network for Lung Cancer Classification: Enhanced Optimization Function",
          "year": "2022-08",
          "abstract": "Background and Purpose: Convolutional neural network is widely used for image\nrecognition in the medical area at nowadays. However, overall accuracy in\npredicting lung tumor is low and the processing time is high as the error\noccurred while reconstructing the CT image. The aim of this work is to increase\nthe overall prediction accuracy along with reducing processing time by using\nmultispace image in pooling layer of convolution neural network. Methodology:\nThe proposed method has the autoencoder system to improve the overall accuracy,\nand to predict lung cancer by using multispace image in pooling layer of\nconvolution neural network and Adam Algorithm for optimization. First, the CT\nimages were pre-processed by feeding image to the convolution filter and down\nsampled by using max pooling. Then, features are extracted using the\nautoencoder model based on convolutional neural network and multispace image\nreconstruction technique is used to reduce error while reconstructing the image\nwhich then results improved accuracy to predict lung nodule. Finally, the\nreconstructed images are taken as input for SoftMax classifier to classify the\nCT images. Results: The state-of-art and proposed solutions were processed in\nPython Tensor Flow and It provides significant increase in accuracy in\nclassification of lung cancer to 99.5 from 98.9 and decrease in processing time\nfrom 10 frames/second to 12 seconds/second. Conclusion: The proposed solution\nprovides high classification accuracy along with less processing time compared\nto the state of art. For future research, large dataset can be implemented, and\nlow pixel image can be processed to evaluate the classification",
          "arxiv_id": "2208.06353v1"
        },
        {
          "title": "CT-LungNet: A Deep Learning Framework for Precise Lung Tissue Segmentation in 3D Thoracic CT Scans",
          "year": "2022-12",
          "abstract": "Segmentation of lung tissue in computed tomography (CT) images is a precursor\nto most pulmonary image analysis applications. Semantic segmentation methods\nusing deep learning have exhibited top-tier performance in recent years,\nhowever designing accurate and robust segmentation models for lung tissue is\nchallenging due to the variations in shape, size, and orientation.\nAdditionally, medical image artifacts and noise can affect lung tissue\nsegmentation and degrade the accuracy of downstream analysis. The practicality\nof current deep learning methods for lung tissue segmentation is limited as\nthey require significant computational resources and may not be easily\ndeployable in clinical settings. This paper presents a fully automatic method\nthat identifies the lungs in three-dimensional (3D) pulmonary CT images using\ndeep networks and transfer learning. We introduce (1) a novel 2.5-dimensional\nimage representation from consecutive CT slices that succinctly represents\nvolumetric information and (2) a U-Net architecture equipped with pre-trained\nInceptionV3 blocks to segment 3D CT scans while maintaining the number of\nlearnable parameters as low as possible. Our method was quantitatively assessed\nusing one public dataset, LUNA16, for training and testing and two public\ndatasets, namely, VESSEL12 and CRPF, only for testing. Due to the low number of\nlearnable parameters, our method achieved high generalizability to the unseen\nVESSEL12 and CRPF datasets while obtaining superior performance over Luna16\ncompared to existing methods (Dice coefficients of 99.7, 99.1, and 98.8 over\nLUNA16, VESSEL12, and CRPF datasets, respectively). We made our method publicly\naccessible via a graphical user interface at medvispy.ee.kntu.ac.ir.",
          "arxiv_id": "2212.13971v4"
        },
        {
          "title": "Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography",
          "year": "2022-03",
          "abstract": "Research studies of artificial intelligence models in medical imaging have\nbeen hampered by poor generalization. This problem has been especially\nconcerning over the last year with numerous applications of deep learning for\nCOVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for\nobjective evaluation of these models. In this work utilizing the VITs, we\ncreated the CVIT-COVID dataset including 180 virtually imaged computed\ntomography (CT) images from simulated COVID-19 and normal phantom models under\ndifferent COVID-19 morphology and imaging properties. We evaluated the\nperformance of an open-source, deep-learning model from the University of\nWaterloo trained with multi-institutional data and an in-house model trained\nwith the open clinical dataset called MosMed. We further validated the model's\nperformance against open clinical data of 305 CT images to understand virtual\nvs. real clinical data performance. The open-source model was published with\nnearly perfect performance on the original Waterloo dataset but showed a\nconsistent performance drop in external testing on another clinical dataset\n(AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model\nachieved an AUC of 0.87 while testing on the internal test set (MosMed test\nset). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on\nclinical and our simulated CVIT-COVID dataset. The VIT framework offered\ncontrol over imaging conditions, allowing us to show there was no change in\nperformance as CT exposure was changed from 28.5 to 57 mAs. The VIT framework\nalso provided voxel-level ground truth, revealing that performance of in-house\nmodel was much higher at AUC=0.87 for diffuse COVID-19 infection size >2.65%\nlung volume versus AUC=0.52 for focal disease with <2.65% volume. The virtual\nimaging framework enabled these uniquely rigorous analyses of model\nperformance.",
          "arxiv_id": "2203.03074v1"
        }
      ],
      "14": [
        {
          "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy",
          "year": "2020-05",
          "abstract": "There has been a surge of recent interest in learning representations for\ngraph-structured data. Graph representation learning methods have generally\nfallen into three main categories, based on the availability of labeled data.\nThe first, network embedding (such as shallow graph embedding or graph\nauto-encoders), focuses on learning unsupervised representations of relational\nstructure. The second, graph regularized neural networks, leverages graphs to\naugment neural network losses with a regularization objective for\nsemi-supervised learning. The third, graph neural networks, aims to learn\ndifferentiable functions over discrete topologies with arbitrary structure.\nHowever, despite the popularity of these areas there has been surprisingly\nlittle work on unifying the three paradigms. Here, we aim to bridge the gap\nbetween graph neural networks, network embedding and graph regularization\nmodels. We propose a comprehensive taxonomy of representation learning methods\nfor graph-structured data, aiming to unify several disparate bodies of work.\nSpecifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which\ngeneralizes popular algorithms for semi-supervised learning on graphs (e.g.\nGraphSage, Graph Convolutional Networks, Graph Attention Networks), and\nunsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc)\ninto a single consistent approach. To illustrate the generality of this\napproach, we fit over thirty existing methods into this framework. We believe\nthat this unifying view both provides a solid foundation for understanding the\nintuition behind these methods, and enables future research in the area.",
          "arxiv_id": "2005.03675v3"
        },
        {
          "title": "SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks",
          "year": "2022-03",
          "abstract": "While (message-passing) graph neural networks have clear limitations in\napproximating permutation-equivariant functions over graphs or general\nrelational data, more expressive, higher-order graph neural networks do not\nscale to large graphs. They either operate on $k$-order tensors or consider all\n$k$-node subgraphs, implying an exponential dependence on $k$ in memory\nrequirements, and do not adapt to the sparsity of the graph. By introducing new\nheuristics for the graph isomorphism problem, we devise a class of universal,\npermutation-equivariant graph networks, which, unlike previous architectures,\noffer a fine-grained control between expressivity and scalability and adapt to\nthe sparsity of the graph. These architectures lead to vastly reduced\ncomputation times compared to standard higher-order graph networks in the\nsupervised node- and graph-level classification and regression regime while\nsignificantly improving over standard graph neural network and graph kernel\narchitectures in terms of predictive performance.",
          "arxiv_id": "2203.13913v3"
        },
        {
          "title": "Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on Graph Semi-Supervised Classification",
          "year": "2020-01",
          "abstract": "Existing graph neural networks may suffer from the \"suspended animation\nproblem\" when the model architecture goes deep. Meanwhile, for some graph\nlearning scenarios, e.g., nodes with text/image attributes or graphs with\nlong-distance node correlations, deep graph neural networks will be necessary\nfor effective graph representation learning. In this paper, we propose a new\ngraph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph\nrepresentation learning and node classification. DIFNET utilizes both neural\ngates and graph residual learning for node hidden state modeling, and includes\nan attention mechanism for node neighborhood information diffusion. Extensive\nexperiments will be done in this paper to compare DIFNET against several\nstate-of-the-art graph neural network models. The experimental results can\nillustrate both the learning performance advantages and effectiveness of\nDIFNET, especially in addressing the \"suspended animation problem\".",
          "arxiv_id": "2001.07922v1"
        }
      ],
      "15": [
        {
          "title": "Learning Reservoir Dynamics with Temporal Self-Modulation",
          "year": "2023-01",
          "abstract": "Reservoir computing (RC) can efficiently process time-series data by\ntransferring the input signal to randomly connected recurrent neural networks\n(RNNs), which are referred to as a reservoir. The high-dimensional\nrepresentation of time-series data in the reservoir significantly simplifies\nsubsequent learning tasks. Although this simple architecture allows fast\nlearning and facile physical implementation, the learning performance is\ninferior to that of other state-of-the-art RNN models. In this paper, to\nimprove the learning ability of RC, we propose self-modulated RC (SM-RC), which\nextends RC by adding a self-modulation mechanism. The self-modulation mechanism\nis realized with two gating variables: an input gate and a reservoir gate. The\ninput gate modulates the input signal, and the reservoir gate modulates the\ndynamical properties of the reservoir. We demonstrated that SM-RC can perform\nattention tasks where input information is retained or discarded depending on\nthe input signal. We also found that a chaotic state emerged as a result of\nlearning in SM-RC. This indicates that self-modulation mechanisms provide RC\nwith qualitatively different information-processing capabilities. Furthermore,\nSM-RC outperformed RC in NARMA and Lorentz model tasks. In particular, SM-RC\nachieved a higher prediction accuracy than RC with a reservoir 10 times larger\nin the Lorentz model tasks. Because the SM-RC architecture only requires two\nadditional gates, it is physically implementable as RC, providing a new\ndirection for realizing edge AI.",
          "arxiv_id": "2301.09235v1"
        },
        {
          "title": "Reservoir Computing Using Complex Systems",
          "year": "2022-12",
          "abstract": "Reservoir Computing is an emerging machine learning framework which is a\nversatile option for utilising physical systems for computation. In this paper,\nwe demonstrate how a single node reservoir, made of a simple electronic\ncircuit, can be employed for computation and explore the available options to\nimprove the computational capability of the physical reservoirs. We build a\nreservoir computing system using a memristive chaotic oscillator as the\nreservoir. We choose two of the available hyperparameters to find the optimal\nworking regime for the reservoir, resulting in two reservoir versions. We\ncompare the performance of both the reservoirs in a set of three non-temporal\ntasks: approximating two non-chaotic polynomials and a chaotic trajectory of\nthe Lorenz time series. We also demonstrate how the dynamics of the physical\nsystem plays a direct role in the reservoir's hyperparameters and hence in the\nreservoir's prediction ability.",
          "arxiv_id": "2212.11141v1"
        },
        {
          "title": "Stochastic Reservoir Computers",
          "year": "2024-05",
          "abstract": "Reservoir computing is a form of machine learning that utilizes nonlinear\ndynamical systems to perform complex tasks in a cost-effective manner when\ncompared to typical neural networks. Many recent advancements in reservoir\ncomputing, in particular quantum reservoir computing, make use of reservoirs\nthat are inherently stochastic. However, the theoretical justification for\nusing these systems has not yet been well established. In this paper, we\ninvestigate the universality of stochastic reservoir computers, in which we use\na stochastic system for reservoir computing using the probabilities of each\nreservoir state as the readout instead of the states themselves. In stochastic\nreservoir computing, the number of distinct states of the entire reservoir\ncomputer can potentially scale exponentially with the size of the reservoir\nhardware, offering the advantage of compact device size. We prove that classes\nof stochastic echo state networks, and therefore the class of all stochastic\nreservoir computers, are universal approximating classes. We also investigate\nthe performance of two practical examples of stochastic reservoir computers in\nclassification and chaotic time series prediction. While shot noise is a\nlimiting factor in the performance of stochastic reservoir computing, we show\nsignificantly improved performance compared to a deterministic reservoir\ncomputer with similar hardware in cases where the effects of noise are small.",
          "arxiv_id": "2405.12382v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T22:19:30Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}