{
  "topics": {
    "data": {
      "0": {
        "name": "0_memory_computing_energy_neural",
        "keywords": [
          [
            "memory",
            0.025061243441827495
          ],
          [
            "computing",
            0.024668252620731277
          ],
          [
            "energy",
            0.021837228644816655
          ],
          [
            "neural",
            0.01939827646991469
          ],
          [
            "hardware",
            0.01918272798552326
          ],
          [
            "networks",
            0.0157901996930718
          ],
          [
            "design",
            0.015788880180849178
          ],
          [
            "optical",
            0.015523416394928087
          ],
          [
            "neuromorphic",
            0.014667971852680093
          ],
          [
            "performance",
            0.014455134137233733
          ]
        ],
        "count": 1797
      },
      "1": {
        "name": "1_data_paper_communication_systems",
        "keywords": [
          [
            "data",
            0.02470944847447628
          ],
          [
            "paper",
            0.016529442091793967
          ],
          [
            "communication",
            0.01552371806038767
          ],
          [
            "systems",
            0.01523457633921072
          ],
          [
            "model",
            0.014951090426939146
          ],
          [
            "models",
            0.01402467501370251
          ],
          [
            "research",
            0.012986650065983766
          ],
          [
            "performance",
            0.0126718553414899
          ],
          [
            "framework",
            0.012406780315683163
          ],
          [
            "challenges",
            0.011466349175700868
          ]
        ],
        "count": 1488
      },
      "2": {
        "name": "2_quantum_Quantum_classical_circuit",
        "keywords": [
          [
            "quantum",
            0.10059192057169496
          ],
          [
            "Quantum",
            0.04282713373513534
          ],
          [
            "classical",
            0.026331253851260283
          ],
          [
            "circuit",
            0.023144702033477085
          ],
          [
            "computing",
            0.021498671689411004
          ],
          [
            "circuits",
            0.020291654531322523
          ],
          [
            "quantum computing",
            0.01861500648032261
          ],
          [
            "qubit",
            0.018474890739415457
          ],
          [
            "algorithm",
            0.017767525143521756
          ],
          [
            "algorithms",
            0.017214879871631294
          ]
        ],
        "count": 1113
      }
    },
    "correlations": [
      [
        1.0,
        -0.5365537648891101,
        -0.7171350681059259
      ],
      [
        -0.5365537648891101,
        1.0,
        -0.7232650697546716
      ],
      [
        -0.7171350681059259,
        -0.7232650697546716,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        19,
        2,
        10
      ],
      "2020-02": [
        16,
        3,
        10
      ],
      "2020-03": [
        24,
        7,
        5
      ],
      "2020-04": [
        18,
        3,
        12
      ],
      "2020-05": [
        22,
        1,
        12
      ],
      "2020-06": [
        23,
        6,
        12
      ],
      "2020-07": [
        20,
        5,
        12
      ],
      "2020-08": [
        21,
        2,
        8
      ],
      "2020-09": [
        21,
        5,
        16
      ],
      "2020-10": [
        18,
        0,
        12
      ],
      "2020-11": [
        21,
        9,
        9
      ],
      "2020-12": [
        22,
        3,
        8
      ],
      "2021-01": [
        15,
        1,
        10
      ],
      "2021-02": [
        23,
        2,
        5
      ],
      "2021-03": [
        28,
        4,
        10
      ],
      "2021-04": [
        16,
        6,
        8
      ],
      "2021-05": [
        33,
        3,
        13
      ],
      "2021-06": [
        24,
        9,
        14
      ],
      "2021-07": [
        29,
        3,
        13
      ],
      "2021-08": [
        20,
        4,
        10
      ],
      "2021-09": [
        27,
        4,
        19
      ],
      "2021-10": [
        23,
        4,
        18
      ],
      "2021-11": [
        29,
        7,
        11
      ],
      "2021-12": [
        38,
        3,
        9
      ],
      "2022-01": [
        18,
        1,
        9
      ],
      "2022-02": [
        21,
        2,
        10
      ],
      "2022-03": [
        28,
        7,
        15
      ],
      "2022-04": [
        28,
        9,
        8
      ],
      "2022-05": [
        29,
        5,
        15
      ],
      "2022-06": [
        25,
        4,
        12
      ],
      "2022-07": [
        19,
        3,
        10
      ],
      "2022-08": [
        21,
        6,
        10
      ],
      "2022-09": [
        18,
        2,
        16
      ],
      "2022-10": [
        16,
        3,
        19
      ],
      "2022-11": [
        40,
        3,
        10
      ],
      "2022-12": [
        19,
        2,
        13
      ],
      "2023-01": [
        25,
        3,
        13
      ],
      "2023-02": [
        22,
        7,
        15
      ],
      "2023-03": [
        20,
        3,
        11
      ],
      "2023-04": [
        17,
        4,
        8
      ],
      "2023-05": [
        37,
        6,
        26
      ],
      "2023-06": [
        33,
        5,
        14
      ],
      "2023-07": [
        40,
        5,
        16
      ],
      "2023-08": [
        28,
        3,
        21
      ],
      "2023-09": [
        55,
        15,
        36
      ],
      "2023-10": [
        28,
        6,
        26
      ],
      "2023-11": [
        28,
        6,
        26
      ],
      "2023-12": [
        26,
        1,
        24
      ],
      "2024-01": [
        38,
        11,
        18
      ],
      "2024-02": [
        39,
        6,
        27
      ],
      "2024-03": [
        61,
        12,
        23
      ],
      "2024-04": [
        64,
        24,
        30
      ],
      "2024-05": [
        52,
        24,
        26
      ],
      "2024-06": [
        60,
        29,
        25
      ],
      "2024-07": [
        62,
        28,
        31
      ],
      "2024-08": [
        56,
        16,
        27
      ],
      "2024-09": [
        71,
        27,
        25
      ],
      "2024-10": [
        73,
        25,
        24
      ],
      "2024-11": [
        74,
        25,
        25
      ],
      "2024-12": [
        57,
        27,
        19
      ],
      "2025-01": [
        58,
        28,
        22
      ],
      "2025-02": [
        60,
        24,
        22
      ],
      "2025-03": [
        74,
        31,
        25
      ],
      "2025-04": [
        70,
        30,
        34
      ],
      "2025-05": [
        91,
        29,
        30
      ],
      "2025-06": [
        85,
        29,
        24
      ],
      "2025-07": [
        84,
        33,
        32
      ],
      "2025-08": [
        87,
        23,
        31
      ],
      "2025-09": [
        41,
        10,
        11
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Neuromorphic spintronics accelerated by an unconventional data-driven Thiele equation approach",
          "year": "2023-01",
          "abstract": "We design a neural network based on a single spin-torque vortex\nnano-oscillator (STVO) multiplexed in time. The behavior of the STVO is\nsimulated with an improved ultra-fast and quantitative model based on the\nThiele equation approach. Different mathematical and numerical adaptations are\nbrought to the model in order to increase the accuracy and the speed of the\nsimulations. We demonstrate the high added value and adaptability of such a\nneural network through the resolution of three standard machine learning tasks\nin the framework of reservoir computing. The first one is a task of waveform\n(sines and squares) classification. We show the ability of the system to\neffectively classify waveforms with high accuracy and low root-mean-square\nerror thanks to the intrinsic short-term memory of the device. Given the high\nthroughput of the simulations, two innovative parametric studies on the\nintensity of the input signal and the level of noise in the system are\nperformed to demonstrate the value of our new models. The efficiency of our\nsystem is then tested during a speech recognition task on the TI-46 dataset and\nshows the agreement between the new models and the corresponding experimental\nmeasurements. Finally, we use our STVO-based neural network to perform image\nrecognition on the MNIST dataset. State-of-the-art performances are\ndemonstrated, and the interest of using the STVO dynamics as an activation\nfunction is highlighted. These results support and facilitate the future\ndevelopment of neuromorphic STVO-based hardware for energy-efficient machine\nlearning.",
          "arxiv_id": "2301.11025v2"
        },
        {
          "title": "Low Power In-Memory Implementation of Ternary Neural Networks with Resistive RAM-Based Synapse",
          "year": "2020-05",
          "abstract": "The design of systems implementing low precision neural networks with\nemerging memories such as resistive random access memory (RRAM) is a major lead\nfor reducing the energy consumption of artificial intelligence (AI). Multiple\nworks have for example proposed in-memory architectures to implement low power\nbinarized neural networks. These simple neural networks, where synaptic weights\nand neuronal activations assume binary values, can indeed approach\nstate-of-the-art performance on vision tasks. In this work, we revisit one of\nthese architectures where synapses are implemented in a differential fashion to\nreduce bit errors, and synaptic weights are read using precharge sense\namplifiers. Based on experimental measurements on a hybrid 130 nm CMOS/RRAM\nchip and on circuit simulation, we show that the same memory array architecture\ncan be used to implement ternary weights instead of binary weights, and that\nthis technique is particularly appropriate if the sense amplifier is operated\nin near-threshold regime. We also show based on neural network simulation on\nthe CIFAR-10 image recognition task that going from binary to ternary neural\nnetworks significantly increases neural network performance. These results\nhighlight that AI circuits function may sometimes be revisited when operated in\nlow power regimes.",
          "arxiv_id": "2005.01973v1"
        },
        {
          "title": "Single chip photonic deep neural network with accelerated training",
          "year": "2022-08",
          "abstract": "As deep neural networks (DNNs) revolutionize machine learning, energy\nconsumption and throughput are emerging as fundamental limitations of CMOS\nelectronics. This has motivated a search for new hardware architectures\noptimized for artificial intelligence, such as electronic systolic arrays,\nmemristor crossbar arrays, and optical accelerators. Optical systems can\nperform linear matrix operations at exceptionally high rate and efficiency,\nmotivating recent demonstrations of low latency linear algebra and optical\nenergy consumption below a photon per multiply-accumulate operation. However,\ndemonstrating systems that co-integrate both linear and nonlinear processing\nunits in a single chip remains a central challenge. Here we introduce such a\nsystem in a scalable photonic integrated circuit (PIC), enabled by several key\nadvances: (i) high-bandwidth and low-power programmable nonlinear optical\nfunction units (NOFUs); (ii) coherent matrix multiplication units (CMXUs); and\n(iii) in situ training with optical acceleration. We experimentally demonstrate\nthis fully-integrated coherent optical neural network (FICONN) architecture for\na 3-layer DNN comprising 12 NOFUs and three CMXUs operating in the telecom\nC-band. Using in situ training on a vowel classification task, the FICONN\nachieves 92.7% accuracy on a test set, which is identical to the accuracy\nobtained on a digital computer with the same number of weights. This work lends\nexperimental evidence to theoretical proposals for in situ training, unlocking\norders of magnitude improvements in the throughput of training data. Moreover,\nthe FICONN opens the path to inference at nanosecond latency and femtojoule per\noperation energy efficiency.",
          "arxiv_id": "2208.01623v1"
        }
      ],
      "1": [
        {
          "title": "Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions",
          "year": "2025-04",
          "abstract": "Alzheimer's Disease (AD) is marked by significant inter-individual\nvariability in its progression, complicating accurate prognosis and\npersonalized care planning. This heterogeneity underscores the critical need\nfor predictive models capable of forecasting patient-specific disease\ntrajectories. Artificial Intelligence (AI) offers powerful tools to address\nthis challenge by analyzing complex, multi-modal, and longitudinal patient\ndata. This paper provides a comprehensive survey of AI methodologies applied to\npersonalized AD progression prediction. We review key approaches including\nstate-space models for capturing temporal dynamics, deep learning techniques\nlike Recurrent Neural Networks for sequence modeling, Graph Neural Networks\n(GNNs) for leveraging network structures, and the emerging concept of AI-driven\ndigital twins for individualized simulation. Recognizing that data limitations\noften impede progress, we examine common challenges such as high\ndimensionality, missing data, and dataset imbalance. We further discuss\nAI-driven mitigation strategies, with a specific focus on synthetic data\ngeneration using Variational Autoencoders (VAEs) and Generative Adversarial\nNetworks (GANs) to augment and balance datasets. The survey synthesizes the\nstrengths and limitations of current approaches, emphasizing the trend towards\nmultimodal integration and the persistent need for model interpretability and\ngeneralizability. Finally, we identify critical open challenges, including\nrobust external validation, clinical integration, and ethical considerations,\nand outline promising future research directions such as hybrid models, causal\ninference, and federated learning. This review aims to consolidate current\nknowledge and guide future efforts in developing clinically relevant AI tools\nfor personalized AD prognostication.",
          "arxiv_id": "2504.21189v1"
        },
        {
          "title": "Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation",
          "year": "2025-06",
          "abstract": "Artificial intelligence (AI) is increasingly integrated into modern\nhealthcare, offering powerful support for clinical decision-making. However, in\nreal-world settings, AI systems may experience performance degradation over\ntime, due to factors such as shifting data distributions, changes in patient\ncharacteristics, evolving clinical protocols, and variations in data quality.\nThese factors can compromise model reliability, posing safety concerns and\nincreasing the likelihood of inaccurate predictions or adverse outcomes. This\nreview presents a forward-looking perspective on monitoring and maintaining the\n\"health\" of AI systems in healthcare. We highlight the urgent need for\ncontinuous performance monitoring, early degradation detection, and effective\nself-correction mechanisms. The paper begins by reviewing common causes of\nperformance degradation at both data and model levels. We then summarize key\ntechniques for detecting data and model drift, followed by an in-depth look at\nroot cause analysis. Correction strategies are further reviewed, ranging from\nmodel retraining to test-time adaptation. Our survey spans both traditional\nmachine learning models and state-of-the-art large language models (LLMs),\noffering insights into their strengths and limitations. Finally, we discuss\nongoing technical challenges and propose future research directions. This work\naims to guide the development of reliable, robust medical AI systems capable of\nsustaining safe, long-term deployment in dynamic clinical settings.",
          "arxiv_id": "2506.17442v1"
        },
        {
          "title": "LoRa Communication for Agriculture 4.0: Opportunities, Challenges, and Future Directions",
          "year": "2024-09",
          "abstract": "The emerging field of smart agriculture leverages the Internet of Things\n(IoT) to revolutionize farming practices. This paper investigates the\ntransformative potential of Long Range (LoRa) technology as a key enabler of\nlong-range wireless communication for agricultural IoT systems. By reviewing\nexisting literature, we identify a gap in research specifically focused on\nLoRa's prospects and challenges from a communication perspective in smart\nagriculture. We delve into the details of LoRa-based agricultural networks,\ncovering network architecture design, Physical Layer (PHY) considerations\ntailored to the agricultural environment, and channel modeling techniques that\naccount for soil characteristics. The paper further explores relaying and\nrouting mechanisms that address the challenges of extending network coverage\nand optimizing data transmission in vast agricultural landscapes. Transitioning\nto practical aspects, we discuss sensor deployment strategies and energy\nmanagement techniques, offering insights for real-world deployments. A\ncomparative analysis of LoRa with other wireless communication technologies\nemployed in agricultural IoT applications highlights its strengths and\nweaknesses in this context. Furthermore, the paper outlines several future\nresearch directions to leverage the potential of LoRa-based agriculture 4.0.\nThese include advancements in channel modeling for diverse farming\nenvironments, novel relay routing algorithms, integrating emerging sensor\ntechnologies like hyper-spectral imaging and drone-based sensing, on-device\nArtificial Intelligence (AI) models, and sustainable solutions. This survey can\nguide researchers, technologists, and practitioners to understand, implement,\nand propel smart agriculture initiatives using LoRa technology.",
          "arxiv_id": "2409.11200v1"
        }
      ],
      "2": [
        {
          "title": "A Quantum Algorithm Based Heuristic to Hide Sensitive Itemsets",
          "year": "2024-02",
          "abstract": "Quantum devices use qubits to represent information, which allows them to\nexploit important properties from quantum physics, specifically superposition\nand entanglement. As a result, quantum computers have the potential to\noutperform the most advanced classical computers. In recent years, quantum\nalgorithms have shown hints of this promise, and many algorithms have been\nproposed for the quantum domain. There are two key hurdles to solving difficult\nreal-world problems on quantum computers. The first is on the hardware front --\nthe number of qubits in the most advanced quantum systems is too small to make\nthe solution of large problems practical. The second involves the algorithms\nthemselves -- as quantum computers use qubits, the algorithms that work there\nare fundamentally different from those that work on traditional computers. As a\nresult of these constraints, research has focused on developing approaches to\nsolve small versions of problems as proofs of concept -- recognizing that it\nwould be possible to scale these up once quantum devices with enough qubits\nbecome available. Our objective in this paper is along the same lines. We\npresent a quantum approach to solve a well-studied problem in the context of\ndata sharing. This heuristic uses the well-known Quantum Approximate\nOptimization Algorithm (QAOA). We present results on experiments involving\nsmall datasets to illustrate how the problem could be solved using quantum\nalgorithms. The results show that the method has potential and provide answers\nclose to optimal. At the same time, we realize there are opportunities for\nimproving the method further.",
          "arxiv_id": "2402.08055v1"
        },
        {
          "title": "QuBEC: Boosting Equivalence Checking for Quantum Circuits with QEC Embedding",
          "year": "2023-09",
          "abstract": "Quantum computing has proven to be capable of accelerating many algorithms by\nperforming tasks that classical computers cannot. Currently, Noisy Intermediate\nScale Quantum (NISQ) machines struggle from scalability and noise issues to\nrender a commercial quantum computer. However, the physical and software\nimprovements of a quantum computer can efficiently control quantum gate noise.\nAs the complexity of quantum algorithms and implementation increases, software\ncontrol of quantum circuits may lead to a more intricate design. Consequently,\nthe verification of quantum circuits becomes crucial in ensuring the\ncorrectness of the compilation, along with other processes, including quantum\nerror correction and assertions, that can increase the fidelity of quantum\ncircuits. In this paper, we propose a Decision Diagram-based quantum\nequivalence checking approach, QuBEC, that requires less latency compared to\nexisting techniques, while accounting for circuits with quantum error\ncorrection redundancy. Our proposed methodology reduces verification time on\ncertain benchmark circuits by up to $271.49 \\times$, while the number of\nDecision Diagram nodes required is reduced by up to $798.31 \\times$, compared\nto state-of-the-art strategies. The proposed QuBEC framework can contribute to\nthe advancement of quantum computing by enabling faster and more efficient\nverification of quantum circuits, paving the way for the development of larger\nand more complex quantum algorithms.",
          "arxiv_id": "2309.10728v1"
        },
        {
          "title": "CutQC: Using Small Quantum Computers for Large Quantum Circuit Evaluations",
          "year": "2020-12",
          "abstract": "Quantum computing (QC) is a new paradigm offering the potential of\nexponential speedups over classical computing for certain computational\nproblems. Each additional qubit doubles the size of the computational state\nspace available to a QC algorithm. This exponential scaling underlies QC's\npower, but today's Noisy Intermediate-Scale Quantum (NISQ) devices face\nsignificant engineering challenges in scalability. The set of quantum circuits\nthat can be reliably run on NISQ devices is limited by their noisy operations\nand low qubit counts.\n  This paper introduces CutQC, a scalable hybrid computing approach that\ncombines classical computers and quantum computers to enable evaluation of\nquantum circuits that cannot be run on classical or quantum computers alone.\nCutQC cuts large quantum circuits into smaller subcircuits, allowing them to be\nexecuted on smaller quantum devices. Classical postprocessing can then\nreconstruct the output of the original circuit. This approach offers\nsignificant runtime speedup compared with the only viable current\nalternative--purely classical simulations--and demonstrates evaluation of\nquantum circuits that are larger than the limit of QC or classical simulation.\nFurthermore, in real-system runs, CutQC achieves much higher quantum circuit\nevaluation fidelity using small prototype quantum computers than the\nstate-of-the-art large NISQ devices achieve. Overall, this hybrid approach\nallows users to leverage classical and quantum computing resources to evaluate\nquantum programs far beyond the reach of either one alone.",
          "arxiv_id": "2012.02333v3"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T21:41:19Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}