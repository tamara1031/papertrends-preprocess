{
  "topics": {
    "data": {
      "0": {
        "name": "0_user_recommendation_item_users",
        "keywords": [
          [
            "user",
            0.02227594093735886
          ],
          [
            "recommendation",
            0.021905606259648748
          ],
          [
            "item",
            0.015381424722099444
          ],
          [
            "users",
            0.013625564135346751
          ],
          [
            "model",
            0.013465875855832045
          ],
          [
            "systems",
            0.013078565853943186
          ],
          [
            "items",
            0.012945314161232617
          ],
          [
            "recommender",
            0.012239274022730116
          ],
          [
            "models",
            0.011019566593617388
          ],
          [
            "learning",
            0.010501105066529116
          ]
        ],
        "count": 5661
      },
      "1": {
        "name": "1_RAG_retrieval_LLMs_knowledge",
        "keywords": [
          [
            "RAG",
            0.0336193889049765
          ],
          [
            "retrieval",
            0.021535259211386333
          ],
          [
            "LLMs",
            0.017992104830796617
          ],
          [
            "knowledge",
            0.016304757595658963
          ],
          [
            "question",
            0.015816725183453822
          ],
          [
            "Retrieval",
            0.01548512278745884
          ],
          [
            "generation",
            0.01361537572154691
          ],
          [
            "language",
            0.013560841830591292
          ],
          [
            "Generation",
            0.013063764081016187
          ],
          [
            "QA",
            0.012736567577637527
          ]
        ],
        "count": 937
      },
      "2": {
        "name": "2_news_topic_social_media",
        "keywords": [
          [
            "news",
            0.017794609538001445
          ],
          [
            "topic",
            0.016946521751611064
          ],
          [
            "social",
            0.015032792827905829
          ],
          [
            "media",
            0.01486078672641057
          ],
          [
            "data",
            0.014575558533741772
          ],
          [
            "detection",
            0.012799601429119198
          ],
          [
            "topics",
            0.01277295017520386
          ],
          [
            "social media",
            0.012203923381277739
          ],
          [
            "analysis",
            0.011898847741142065
          ],
          [
            "sentiment",
            0.011743535357175927
          ]
        ],
        "count": 935
      },
      "3": {
        "name": "3_retrieval_models_query_ranking",
        "keywords": [
          [
            "retrieval",
            0.030866299655372614
          ],
          [
            "models",
            0.021183177121461155
          ],
          [
            "query",
            0.017176994965439
          ],
          [
            "ranking",
            0.017161502045984895
          ],
          [
            "document",
            0.01557845167904445
          ],
          [
            "model",
            0.014393058823382978
          ],
          [
            "dense",
            0.014175548358181
          ],
          [
            "training",
            0.014067032163271044
          ],
          [
            "documents",
            0.01276328717581907
          ],
          [
            "Retrieval",
            0.01203992294274367
          ]
        ],
        "count": 890
      },
      "4": {
        "name": "4_image_retrieval_video_modal",
        "keywords": [
          [
            "image",
            0.02987097557499199
          ],
          [
            "retrieval",
            0.025360423715332536
          ],
          [
            "video",
            0.02126837183905303
          ],
          [
            "modal",
            0.01856805608844542
          ],
          [
            "text",
            0.017492758945281964
          ],
          [
            "images",
            0.015029614427538704
          ],
          [
            "visual",
            0.013611273611789524
          ],
          [
            "Retrieval",
            0.01237829737566836
          ],
          [
            "methods",
            0.011262664048572953
          ],
          [
            "learning",
            0.010788760298067244
          ]
        ],
        "count": 625
      },
      "5": {
        "name": "5_medical_clinical_biomedical_literature",
        "keywords": [
          [
            "medical",
            0.022295396982142154
          ],
          [
            "clinical",
            0.021052776808960918
          ],
          [
            "biomedical",
            0.013223975068610457
          ],
          [
            "literature",
            0.012711198964547555
          ],
          [
            "models",
            0.01217886127093313
          ],
          [
            "data",
            0.011529551749910653
          ],
          [
            "research",
            0.011366865597962615
          ],
          [
            "scientific",
            0.011059788251431762
          ],
          [
            "COVID",
            0.010484347121986945
          ],
          [
            "patient",
            0.010378065745943464
          ]
        ],
        "count": 565
      },
      "6": {
        "name": "6_music_audio_Music_musical",
        "keywords": [
          [
            "music",
            0.06831267639712234
          ],
          [
            "audio",
            0.03691703118281658
          ],
          [
            "Music",
            0.029388422837069172
          ],
          [
            "musical",
            0.015412997370487763
          ],
          [
            "song",
            0.012454674659377163
          ],
          [
            "dataset",
            0.012140171877275669
          ],
          [
            "songs",
            0.011392648138034924
          ],
          [
            "model",
            0.01118923223911158
          ],
          [
            "Audio",
            0.010931677482089003
          ],
          [
            "learning",
            0.01008908524397632
          ]
        ],
        "count": 415
      },
      "7": {
        "name": "7_entity_entities_NER_relation",
        "keywords": [
          [
            "entity",
            0.029643198465552714
          ],
          [
            "entities",
            0.02827285550617796
          ],
          [
            "NER",
            0.020112019333676498
          ],
          [
            "relation",
            0.019355394366344245
          ],
          [
            "Entity",
            0.01867891625753747
          ],
          [
            "knowledge",
            0.01814041480114219
          ],
          [
            "graph",
            0.014819509437385813
          ],
          [
            "extraction",
            0.014570512845602512
          ],
          [
            "models",
            0.014084358527879667
          ],
          [
            "Knowledge",
            0.01290396460835254
          ]
        ],
        "count": 316
      },
      "8": {
        "name": "8_conversational_search_Conversational_dialogue",
        "keywords": [
          [
            "conversational",
            0.03873662996734411
          ],
          [
            "search",
            0.026173786702728765
          ],
          [
            "Conversational",
            0.021640175148649247
          ],
          [
            "dialogue",
            0.02045428847304162
          ],
          [
            "conversational search",
            0.02009612429823251
          ],
          [
            "user",
            0.018912794118656158
          ],
          [
            "query",
            0.01579337492183176
          ],
          [
            "information",
            0.015187137329411831
          ],
          [
            "retrieval",
            0.014618625546692117
          ],
          [
            "questions",
            0.013476292729889294
          ]
        ],
        "count": 273
      },
      "9": {
        "name": "9_privacy_federated_data_attacks",
        "keywords": [
          [
            "privacy",
            0.04158254906838605
          ],
          [
            "federated",
            0.027644057351974567
          ],
          [
            "data",
            0.024815187540625467
          ],
          [
            "attacks",
            0.023601552809005884
          ],
          [
            "recommendation",
            0.023449384125219252
          ],
          [
            "attack",
            0.022900575603518953
          ],
          [
            "Federated",
            0.02190897733197807
          ],
          [
            "user",
            0.021662678282471818
          ],
          [
            "recommender",
            0.019146135647919327
          ],
          [
            "systems",
            0.018319984711514647
          ]
        ],
        "count": 247
      },
      "10": {
        "name": "10_search_data_index_query",
        "keywords": [
          [
            "search",
            0.0333666149930004
          ],
          [
            "data",
            0.021702792957700542
          ],
          [
            "index",
            0.019984025719682604
          ],
          [
            "query",
            0.01922384039732294
          ],
          [
            "vector",
            0.01771265339752521
          ],
          [
            "ANNS",
            0.017346140635817284
          ],
          [
            "graph",
            0.01729357064542736
          ],
          [
            "Search",
            0.016241089895601444
          ],
          [
            "nearest",
            0.014977665008773502
          ],
          [
            "Approximate",
            0.014670875634468039
          ]
        ],
        "count": 214
      },
      "11": {
        "name": "11_quantum_PIR_privacy_problem",
        "keywords": [
          [
            "quantum",
            0.035415193233499
          ],
          [
            "PIR",
            0.02631772635858639
          ],
          [
            "privacy",
            0.023865517303898583
          ],
          [
            "problem",
            0.01945432082747573
          ],
          [
            "information",
            0.018524498237802375
          ],
          [
            "messages",
            0.018356522467885827
          ],
          [
            "Private",
            0.018147260264060914
          ],
          [
            "scheme",
            0.01749121607225045
          ],
          [
            "servers",
            0.016648153085313474
          ],
          [
            "data",
            0.015378597447103123
          ]
        ],
        "count": 152
      },
      "12": {
        "name": "12_graph_node_networks_graphs",
        "keywords": [
          [
            "graph",
            0.044583842350942246
          ],
          [
            "node",
            0.0307859787540134
          ],
          [
            "networks",
            0.026207771151868915
          ],
          [
            "graphs",
            0.025537559191190645
          ],
          [
            "Graph",
            0.022357307065282807
          ],
          [
            "nodes",
            0.02158555052794201
          ],
          [
            "network",
            0.0192900864464661
          ],
          [
            "Networks",
            0.013607069871564927
          ],
          [
            "GNNs",
            0.013499030304443846
          ],
          [
            "temporal",
            0.013121494413467145
          ]
        ],
        "count": 151
      },
      "13": {
        "name": "13_legal_case_Legal_legal case",
        "keywords": [
          [
            "legal",
            0.11087644387714138
          ],
          [
            "case",
            0.050372927212964054
          ],
          [
            "Legal",
            0.03845145774495136
          ],
          [
            "legal case",
            0.027446006027042443
          ],
          [
            "retrieval",
            0.027017277065849905
          ],
          [
            "law",
            0.024855704716025075
          ],
          [
            "cases",
            0.020926014386957414
          ],
          [
            "case retrieval",
            0.020295715623993363
          ],
          [
            "Case",
            0.016518049537659407
          ],
          [
            "documents",
            0.015725768538835158
          ]
        ],
        "count": 142
      },
      "14": {
        "name": "14_citation_papers_research_paper",
        "keywords": [
          [
            "citation",
            0.040097412702570716
          ],
          [
            "papers",
            0.03294621069514334
          ],
          [
            "research",
            0.024640503887154098
          ],
          [
            "paper",
            0.024257308770401945
          ],
          [
            "scientific",
            0.022015318040255756
          ],
          [
            "recommendation",
            0.01631514157590551
          ],
          [
            "Citation",
            0.015930628655912177
          ],
          [
            "citations",
            0.015463751365388717
          ],
          [
            "academic",
            0.014881410698965005
          ],
          [
            "citation recommendation",
            0.01330129941128995
          ]
        ],
        "count": 133
      }
    },
    "correlations": [
      [
        1.0,
        -0.7195592579244892,
        -0.7334171303834525,
        -0.6867703091637503,
        -0.7324436797554168,
        -0.7305747877215409,
        -0.7390861584003773,
        -0.7210178162301788,
        -0.5548524032314759,
        -0.06338419440866289,
        -0.7104145410415728,
        -0.7553971895581598,
        -0.5814593153816283,
        -0.7351938179580123,
        -0.624729758546855
      ],
      [
        -0.7195592579244892,
        1.0,
        -0.7434596989964009,
        -0.44369614991523626,
        -0.6778489454202246,
        -0.38879176309923,
        -0.755872966913713,
        -0.7106704822315564,
        -0.7117590102458567,
        -0.7101688013447565,
        -0.7289546468185908,
        -0.7603403931263124,
        -0.7249269914474243,
        -0.6998277235995982,
        -0.6750690938810581
      ],
      [
        -0.7334171303834525,
        -0.7434596989964009,
        1.0,
        -0.7345544232667636,
        -0.7389887434563664,
        -0.5913917142665482,
        -0.7593589236185824,
        -0.7334476466968163,
        -0.745946889211323,
        -0.7253916638232257,
        -0.731111345893084,
        -0.758008439281427,
        -0.737332171704221,
        -0.7410641064479673,
        -0.6901015558020299
      ],
      [
        -0.6867703091637503,
        -0.44369614991523626,
        -0.7345544232667636,
        1.0,
        -0.5825669369426848,
        -0.4992893394345498,
        -0.7447748485198125,
        -0.7004293841368244,
        -0.6974847308768222,
        -0.6911280359101795,
        -0.6907784056497366,
        -0.7539162760187026,
        -0.7134640577013112,
        -0.683213435954761,
        -0.640298023162226
      ],
      [
        -0.7324436797554168,
        -0.6778489454202246,
        -0.7389887434563664,
        -0.5825669369426848,
        1.0,
        -0.7313413767617916,
        -0.7393470530595904,
        -0.720923942999342,
        -0.7396102893534703,
        -0.7305910678046504,
        -0.7114142161879966,
        -0.7600069511655505,
        -0.7357422578677446,
        -0.6888936408617834,
        -0.6947479782478851
      ],
      [
        -0.7305747877215409,
        -0.38879176309923,
        -0.5913917142665482,
        -0.4992893394345498,
        -0.7313413767617916,
        1.0,
        -0.7607744630446434,
        -0.7138650679523191,
        -0.7345174479455141,
        -0.7232561593820787,
        -0.7318116886682613,
        -0.7590333196340311,
        -0.7443599144695436,
        -0.7326913926477534,
        -0.7102746635576795
      ],
      [
        -0.7390861584003773,
        -0.755872966913713,
        -0.7593589236185824,
        -0.7447748485198125,
        -0.7393470530595904,
        -0.7607744630446434,
        1.0,
        -0.7561939909868295,
        -0.748089446609566,
        -0.7403998026692091,
        -0.7512785689080301,
        -0.7655764556207769,
        -0.7543231252588176,
        -0.7539480828651219,
        -0.7459119506123326
      ],
      [
        -0.7210178162301788,
        -0.7106704822315564,
        -0.7334476466968163,
        -0.7004293841368244,
        -0.720923942999342,
        -0.7138650679523191,
        -0.7561939909868295,
        1.0,
        -0.7319861300652263,
        -0.7178055611099088,
        -0.7206141149014356,
        -0.7612242614442793,
        -0.6594952993236722,
        -0.7334525696051657,
        -0.6892836179777171
      ],
      [
        -0.5548524032314759,
        -0.7117590102458567,
        -0.745946889211323,
        -0.6974847308768222,
        -0.7396102893534703,
        -0.7345174479455141,
        -0.748089446609566,
        -0.7319861300652263,
        1.0,
        -0.5953218184180905,
        -0.5911858158032346,
        -0.7514298119656998,
        -0.7276367551584453,
        -0.7452640638936456,
        -0.7047578902145462
      ],
      [
        -0.06338419440866289,
        -0.7101688013447565,
        -0.7253916638232257,
        -0.6911280359101795,
        -0.7305910678046504,
        -0.7232561593820787,
        -0.7403998026692091,
        -0.7178055611099088,
        -0.5953218184180905,
        1.0,
        -0.4335057645916513,
        -0.7013227564416719,
        -0.6418795379675069,
        -0.7272692340930179,
        -0.6325271122071866
      ],
      [
        -0.7104145410415728,
        -0.7289546468185908,
        -0.731111345893084,
        -0.6907784056497366,
        -0.7114142161879966,
        -0.7318116886682613,
        -0.7512785689080301,
        -0.7206141149014356,
        -0.5911858158032346,
        -0.4335057645916513,
        1.0,
        -0.7520905578556935,
        -0.6880818715974413,
        -0.7322030049765624,
        -0.6795456047578368
      ],
      [
        -0.7553971895581598,
        -0.7603403931263124,
        -0.758008439281427,
        -0.7539162760187026,
        -0.7600069511655505,
        -0.7590333196340311,
        -0.7655764556207769,
        -0.7612242614442793,
        -0.7514298119656998,
        -0.7013227564416719,
        -0.7520905578556935,
        1.0,
        -0.7602327719654336,
        -0.7512581691415909,
        -0.7580171208299548
      ],
      [
        -0.5814593153816283,
        -0.7249269914474243,
        -0.737332171704221,
        -0.7134640577013112,
        -0.7357422578677446,
        -0.7443599144695436,
        -0.7543231252588176,
        -0.6594952993236722,
        -0.7276367551584453,
        -0.6418795379675069,
        -0.6880818715974413,
        -0.7602327719654336,
        1.0,
        -0.7436777482319901,
        -0.6409137583752633
      ],
      [
        -0.7351938179580123,
        -0.6998277235995982,
        -0.7410641064479673,
        -0.683213435954761,
        -0.6888936408617834,
        -0.7326913926477534,
        -0.7539480828651219,
        -0.7334525696051657,
        -0.7452640638936456,
        -0.7272692340930179,
        -0.7322030049765624,
        -0.7512581691415909,
        -0.7436777482319901,
        1.0,
        -0.7181483925687909
      ],
      [
        -0.624729758546855,
        -0.6750690938810581,
        -0.6901015558020299,
        -0.640298023162226,
        -0.6947479782478851,
        -0.7102746635576795,
        -0.7459119506123326,
        -0.6892836179777171,
        -0.7047578902145462,
        -0.6325271122071866,
        -0.6795456047578368,
        -0.7580171208299548,
        -0.6409137583752633,
        -0.7181483925687909,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        45,
        1,
        8,
        12,
        8,
        3,
        3,
        7,
        4,
        9,
        2,
        3,
        9,
        3,
        24
      ],
      "2020-02": [
        29,
        0,
        5,
        13,
        10,
        1,
        2,
        7,
        2,
        6,
        3,
        1,
        6,
        5,
        21
      ],
      "2020-03": [
        31,
        1,
        10,
        5,
        9,
        1,
        4,
        9,
        2,
        8,
        0,
        0,
        11,
        4,
        13
      ],
      "2020-04": [
        40,
        5,
        23,
        22,
        12,
        5,
        2,
        12,
        6,
        22,
        1,
        2,
        7,
        4,
        29
      ],
      "2020-05": [
        49,
        1,
        23,
        19,
        12,
        6,
        2,
        18,
        11,
        16,
        3,
        0,
        13,
        8,
        44
      ],
      "2020-06": [
        50,
        2,
        18,
        12,
        5,
        2,
        7,
        7,
        4,
        16,
        5,
        1,
        8,
        4,
        32
      ],
      "2020-07": [
        51,
        1,
        22,
        14,
        9,
        7,
        14,
        11,
        1,
        23,
        7,
        0,
        13,
        8,
        22
      ],
      "2020-08": [
        35,
        2,
        20,
        11,
        5,
        3,
        13,
        11,
        4,
        25,
        8,
        3,
        9,
        2,
        26
      ],
      "2020-09": [
        46,
        1,
        16,
        18,
        5,
        2,
        9,
        7,
        2,
        17,
        2,
        1,
        8,
        5,
        22
      ],
      "2020-10": [
        51,
        6,
        17,
        17,
        7,
        7,
        9,
        10,
        3,
        18,
        3,
        2,
        16,
        11,
        35
      ],
      "2020-11": [
        42,
        2,
        12,
        15,
        7,
        2,
        3,
        6,
        3,
        12,
        2,
        0,
        9,
        5,
        23
      ],
      "2020-12": [
        50,
        2,
        8,
        15,
        7,
        3,
        1,
        12,
        1,
        13,
        3,
        0,
        13,
        3,
        21
      ],
      "2021-01": [
        42,
        1,
        15,
        12,
        6,
        4,
        6,
        8,
        5,
        7,
        4,
        1,
        10,
        4,
        26
      ],
      "2021-02": [
        52,
        0,
        9,
        17,
        5,
        4,
        3,
        11,
        6,
        20,
        5,
        3,
        10,
        5,
        19
      ],
      "2021-03": [
        35,
        0,
        7,
        16,
        7,
        1,
        3,
        8,
        0,
        11,
        7,
        0,
        7,
        1,
        23
      ],
      "2021-04": [
        43,
        3,
        11,
        22,
        9,
        5,
        3,
        12,
        11,
        4,
        3,
        0,
        13,
        6,
        20
      ],
      "2021-05": [
        59,
        1,
        10,
        16,
        5,
        0,
        10,
        6,
        6,
        22,
        7,
        1,
        16,
        11,
        27
      ],
      "2021-06": [
        54,
        4,
        13,
        23,
        6,
        1,
        4,
        12,
        1,
        20,
        5,
        1,
        14,
        4,
        35
      ],
      "2021-07": [
        37,
        1,
        10,
        9,
        2,
        1,
        7,
        4,
        1,
        15,
        3,
        0,
        11,
        6,
        19
      ],
      "2021-08": [
        58,
        2,
        6,
        25,
        8,
        4,
        12,
        12,
        1,
        13,
        3,
        0,
        11,
        6,
        15
      ],
      "2021-09": [
        71,
        2,
        11,
        16,
        6,
        0,
        8,
        12,
        7,
        16,
        4,
        0,
        16,
        6,
        30
      ],
      "2021-10": [
        54,
        2,
        8,
        12,
        12,
        1,
        5,
        8,
        5,
        16,
        8,
        2,
        14,
        8,
        34
      ],
      "2021-11": [
        35,
        0,
        8,
        20,
        5,
        2,
        3,
        12,
        4,
        14,
        3,
        0,
        14,
        2,
        20
      ],
      "2021-12": [
        50,
        2,
        8,
        21,
        9,
        3,
        3,
        7,
        3,
        16,
        3,
        0,
        16,
        8,
        26
      ],
      "2022-01": [
        37,
        2,
        6,
        18,
        11,
        1,
        3,
        7,
        7,
        21,
        10,
        1,
        13,
        7,
        20
      ],
      "2022-02": [
        46,
        0,
        3,
        17,
        5,
        0,
        6,
        7,
        1,
        15,
        3,
        1,
        17,
        6,
        28
      ],
      "2022-03": [
        39,
        3,
        5,
        18,
        5,
        3,
        2,
        5,
        3,
        17,
        4,
        0,
        15,
        3,
        27
      ],
      "2022-04": [
        65,
        4,
        16,
        27,
        14,
        2,
        7,
        11,
        11,
        22,
        4,
        0,
        16,
        4,
        35
      ],
      "2022-05": [
        57,
        2,
        5,
        26,
        7,
        0,
        4,
        18,
        6,
        25,
        7,
        4,
        17,
        8,
        22
      ],
      "2022-06": [
        47,
        4,
        5,
        13,
        10,
        3,
        2,
        4,
        3,
        19,
        5,
        1,
        10,
        4,
        25
      ],
      "2022-07": [
        42,
        3,
        10,
        20,
        6,
        2,
        6,
        6,
        1,
        13,
        4,
        1,
        14,
        7,
        19
      ],
      "2022-08": [
        45,
        2,
        8,
        30,
        6,
        1,
        3,
        11,
        5,
        26,
        3,
        1,
        18,
        7,
        26
      ],
      "2022-09": [
        57,
        3,
        9,
        15,
        17,
        1,
        7,
        4,
        1,
        18,
        5,
        0,
        12,
        7,
        23
      ],
      "2022-10": [
        60,
        7,
        10,
        28,
        15,
        1,
        10,
        11,
        4,
        20,
        6,
        0,
        17,
        6,
        27
      ],
      "2022-11": [
        40,
        0,
        11,
        19,
        8,
        3,
        5,
        8,
        3,
        16,
        4,
        2,
        11,
        6,
        21
      ],
      "2022-12": [
        44,
        5,
        3,
        20,
        5,
        3,
        7,
        7,
        0,
        16,
        4,
        2,
        10,
        3,
        23
      ],
      "2023-01": [
        40,
        1,
        6,
        19,
        4,
        0,
        6,
        3,
        4,
        12,
        3,
        1,
        4,
        6,
        22
      ],
      "2023-02": [
        53,
        1,
        7,
        22,
        12,
        0,
        3,
        11,
        5,
        15,
        4,
        1,
        15,
        4,
        32
      ],
      "2023-03": [
        41,
        6,
        4,
        15,
        7,
        1,
        6,
        9,
        4,
        17,
        3,
        0,
        11,
        4,
        17
      ],
      "2023-04": [
        58,
        9,
        4,
        32,
        11,
        0,
        3,
        8,
        9,
        27,
        7,
        1,
        27,
        7,
        35
      ],
      "2023-05": [
        83,
        24,
        12,
        45,
        11,
        1,
        7,
        15,
        14,
        31,
        11,
        1,
        20,
        14,
        35
      ],
      "2023-06": [
        71,
        18,
        6,
        27,
        10,
        2,
        10,
        11,
        4,
        25,
        5,
        0,
        13,
        6,
        28
      ],
      "2023-07": [
        63,
        16,
        5,
        22,
        9,
        3,
        5,
        7,
        3,
        22,
        3,
        0,
        17,
        7,
        26
      ],
      "2023-08": [
        99,
        17,
        3,
        21,
        13,
        2,
        11,
        7,
        5,
        37,
        8,
        0,
        18,
        3,
        33
      ],
      "2023-09": [
        61,
        10,
        5,
        21,
        9,
        4,
        13,
        11,
        4,
        29,
        3,
        1,
        16,
        4,
        19
      ],
      "2023-10": [
        62,
        25,
        7,
        24,
        7,
        4,
        6,
        16,
        7,
        18,
        10,
        0,
        16,
        10,
        25
      ],
      "2023-11": [
        50,
        16,
        9,
        34,
        9,
        2,
        10,
        2,
        2,
        22,
        5,
        0,
        14,
        10,
        23
      ],
      "2023-12": [
        55,
        32,
        4,
        22,
        8,
        3,
        6,
        10,
        3,
        26,
        6,
        3,
        11,
        7,
        15
      ],
      "2024-01": [
        52,
        31,
        14,
        25,
        13,
        4,
        8,
        13,
        10,
        33,
        5,
        1,
        18,
        7,
        28
      ],
      "2024-02": [
        84,
        60,
        7,
        33,
        17,
        7,
        7,
        7,
        7,
        27,
        4,
        0,
        18,
        7,
        38
      ],
      "2024-03": [
        73,
        40,
        6,
        27,
        18,
        2,
        6,
        9,
        11,
        24,
        4,
        1,
        25,
        15,
        35
      ],
      "2024-04": [
        67,
        46,
        8,
        34,
        8,
        0,
        7,
        11,
        6,
        22,
        4,
        0,
        17,
        5,
        19
      ],
      "2024-05": [
        76,
        52,
        8,
        40,
        15,
        2,
        11,
        15,
        8,
        25,
        8,
        0,
        18,
        10,
        25
      ],
      "2024-06": [
        70,
        64,
        11,
        31,
        17,
        3,
        4,
        12,
        3,
        34,
        3,
        0,
        29,
        8,
        24
      ],
      "2024-07": [
        76,
        47,
        9,
        26,
        15,
        5,
        6,
        7,
        4,
        16,
        3,
        0,
        13,
        7,
        29
      ],
      "2024-08": [
        84,
        55,
        8,
        38,
        12,
        5,
        13,
        11,
        3,
        21,
        8,
        0,
        23,
        4,
        25
      ],
      "2024-09": [
        84,
        68,
        9,
        23,
        9,
        4,
        12,
        8,
        2,
        29,
        10,
        0,
        17,
        10,
        30
      ],
      "2024-10": [
        82,
        90,
        11,
        35,
        17,
        3,
        8,
        12,
        12,
        28,
        8,
        1,
        17,
        6,
        35
      ],
      "2024-11": [
        62,
        63,
        4,
        27,
        8,
        3,
        13,
        16,
        5,
        23,
        6,
        1,
        8,
        3,
        18
      ],
      "2024-12": [
        75,
        86,
        5,
        32,
        19,
        1,
        9,
        8,
        3,
        27,
        4,
        0,
        17,
        13,
        21
      ],
      "2025-01": [
        62,
        84,
        3,
        26,
        11,
        5,
        9,
        5,
        4,
        20,
        9,
        1,
        16,
        9,
        17
      ],
      "2025-02": [
        73,
        102,
        6,
        33,
        16,
        1,
        4,
        8,
        6,
        22,
        7,
        1,
        18,
        4,
        33
      ],
      "2025-03": [
        67,
        87,
        5,
        29,
        14,
        4,
        7,
        5,
        5,
        16,
        4,
        1,
        10,
        2,
        26
      ],
      "2025-04": [
        85,
        106,
        10,
        42,
        10,
        2,
        8,
        10,
        8,
        29,
        4,
        0,
        10,
        10,
        16
      ],
      "2025-05": [
        103,
        140,
        4,
        37,
        19,
        1,
        9,
        15,
        7,
        19,
        8,
        3,
        21,
        15,
        28
      ],
      "2025-06": [
        74,
        106,
        0,
        21,
        11,
        4,
        10,
        11,
        5,
        15,
        6,
        3,
        21,
        9,
        33
      ],
      "2025-07": [
        91,
        90,
        4,
        35,
        11,
        2,
        15,
        6,
        5,
        31,
        8,
        1,
        19,
        5,
        26
      ],
      "2025-08": [
        120,
        111,
        11,
        38,
        22,
        2,
        12,
        15,
        11,
        36,
        10,
        1,
        26,
        12,
        30
      ],
      "2025-09": [
        30,
        31,
        4,
        11,
        5,
        1,
        9,
        6,
        2,
        12,
        3,
        0,
        7,
        3,
        13
      ]
    },
    "papers": {
      "0": [
        {
          "title": "LLM2Rec: Large Language Models Are Powerful Embedding Models for Sequential Recommendation",
          "year": "2025-06",
          "abstract": "Sequential recommendation aims to predict users' future interactions by\nmodeling collaborative filtering (CF) signals from historical behaviors of\nsimilar users or items. Traditional sequential recommenders predominantly rely\non ID-based embeddings, which capture CF signals through high-order\nco-occurrence patterns. However, these embeddings depend solely on past\ninteractions, lacking transferable knowledge to generalize to unseen domains.\nRecent advances in large language models (LLMs) have motivated text-based\nrecommendation approaches that derive item representations from textual\ndescriptions. While these methods enhance generalization, they fail to encode\nCF signals-i.e., latent item correlations and preference patterns-crucial for\neffective recommendation. We argue that an ideal embedding model should\nseamlessly integrate CF signals with rich semantic representations to improve\nboth in-domain and out-of-domain recommendation performance.\n  To this end, we propose LLM2Rec, a novel embedding model tailored for\nsequential recommendation, integrating the rich semantic understanding of LLMs\nwith CF awareness. Our approach follows a two-stage training framework: (1)\nCollaborative Supervised Fine-tuning, which adapts LLMs to infer item\nrelationships based on historical interactions, and (2) Item-level Embedding\nModeling, which refines these specialized LLMs into structured item embedding\nmodels that encode both semantic and collaborative information. Extensive\nexperiments on real-world datasets demonstrate that LLM2Rec effectively\nimproves recommendation quality across both in-domain and out-of-domain\nsettings. Our findings highlight the potential of leveraging LLMs to build more\nrobust, generalizable embedding models for sequential recommendation. Our codes\nare available at https://github.com/HappyPointer/LLM2Rec.",
          "arxiv_id": "2506.21579v1"
        },
        {
          "title": "Text Matching Improves Sequential Recommendation by Reducing Popularity Biases",
          "year": "2023-08",
          "abstract": "This paper proposes Text mAtching based SequenTial rEcommendation model\n(TASTE), which maps items and users in an embedding space and recommends items\nby matching their text representations. TASTE verbalizes items and user-item\ninteractions using identifiers and attributes of items. To better characterize\nuser behaviors, TASTE additionally proposes an attention sparsity method, which\nenables TASTE to model longer user-item interactions by reducing the\nself-attention computations during encoding. Our experiments show that TASTE\noutperforms the state-of-the-art methods on widely used sequential\nrecommendation datasets. TASTE alleviates the cold start problem by\nrepresenting long-tail items using full-text modeling and bringing the benefits\nof pretrained language models to recommendation systems. Our further analyses\nillustrate that TASTE significantly improves the recommendation accuracy by\nreducing the popularity bias of previous item id based recommendation models\nand returning more appropriate and text-relevant items to satisfy users. All\ncodes are available at https://github.com/OpenMatch/TASTE.",
          "arxiv_id": "2308.14029v1"
        },
        {
          "title": "Mutual Harmony: Sequential Recommendation with Dual Contrastive Network",
          "year": "2022-09",
          "abstract": "With the outbreak of today's streaming data, the sequential recommendation is\na promising solution to achieve time-aware personalized modeling. It aims to\ninfer the next interacted item of a given user based on the historical item\nsequence. Some recent works tend to improve the sequential recommendation via\nrandom masking on the historical item so as to generate self-supervised\nsignals. But such approaches will indeed result in sparser item sequence and\nunreliable signals. Besides, the existing sequential recommendation models are\nonly user-centric, i.e., based on the historical items by chronological order\nto predict the probability of candidate items, which ignores whether the items\nfrom a provider can be successfully recommended. Such user-centric\nrecommendation will make it impossible for the provider to expose their new\nitems, failing to consider the accordant interactions between user and item\ndimensions. In this paper, we propose a novel Dual Contrastive Network (DCN) to\nachieve mutual harmony between user and item provider, generating ground-truth\nself-supervised signals for sequential recommendation by auxiliary\nuser-sequence from an item-centric dimension. Specifically, we propose dual\nrepresentation contrastive learning to refine the representation learning by\nminimizing the Euclidean distance between the representations of a given\nuser/item and historical items/users of them. Before the second contrastive\nlearning module, we perform the next user prediction to capture the trends of\nitems preferred by certain types of users and provide personalized exploration\nopportunities for item providers. Finally, we further propose dual interest\ncontrastive learning to self-supervise the dynamic interest from the next\nitem/user prediction and static interest of matching probability. Experiments\non four benchmark datasets verify the effectiveness of our proposed method.",
          "arxiv_id": "2209.08446v4"
        }
      ],
      "1": [
        {
          "title": "Parametric Retrieval Augmented Generation",
          "year": "2025-01",
          "abstract": "Retrieval-augmented generation (RAG) techniques have emerged as a promising\nsolution to enhance the reliability of large language models (LLMs) by\naddressing issues like hallucinations, outdated knowledge, and domain\nadaptation. In particular, existing RAG methods append relevant documents\nretrieved from external corpus or databases to the input of LLMs to guide their\ngeneration process, which we refer to as the in-context knowledge injection\nmethod. While this approach is simple and often effective, it has inherent\nlimitations. Firstly, increasing the context length and number of relevant\ndocuments can lead to higher computational overhead and degraded performance,\nespecially in complex reasoning tasks. More importantly, in-context knowledge\ninjection operates primarily at the input level, but LLMs store their internal\nknowledge in their parameters. This gap fundamentally limits the capacity of\nin-context methods. To this end, we introduce Parametric retrieval-augmented\ngeneration (Parametric RAG), a new RAG paradigm that integrates external\nknowledge directly into the parameters of feed-forward networks (FFN) of an LLM\nthrough document parameterization. This approach not only saves online\ncomputational costs by eliminating the need to inject multiple documents into\nthe LLMs' input context, but also deepens the integration of external knowledge\ninto the parametric knowledge space of the LLM. Experimental results\ndemonstrate that Parametric RAG substantially enhances both the effectiveness\nand efficiency of knowledge augmentation in LLMs. Also, it can be combined with\nin-context RAG methods to achieve even better performance.\n  We have open-sourced all the code, data, and models in the following\nanonymized GitHub link: https://github.com/oneal2000/PRAG",
          "arxiv_id": "2501.15915v1"
        },
        {
          "title": "MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation",
          "year": "2024-12",
          "abstract": "Large Language Models (LLMs) are becoming essential tools for various natural\nlanguage processing tasks but often suffer from generating outdated or\nincorrect information. Retrieval-Augmented Generation (RAG) addresses this\nissue by incorporating external, real-time information retrieval to ground LLM\nresponses. However, the existing RAG systems frequently struggle with the\nquality of retrieval documents, as irrelevant or noisy documents degrade\nperformance, increase computational overhead, and undermine response\nreliability. To tackle this problem, we propose Multi-Agent Filtering\nRetrieval-Augmented Generation (MAIN-RAG), a training-free RAG framework that\nleverages multiple LLM agents to collaboratively filter and score retrieved\ndocuments. Specifically, MAIN-RAG introduces an adaptive filtering mechanism\nthat dynamically adjusts the relevance filtering threshold based on score\ndistributions, effectively minimizing noise while maintaining high recall of\nrelevant documents. The proposed approach leverages inter-agent consensus to\nensure robust document selection without requiring additional training data or\nfine-tuning. Experimental results across four QA benchmarks demonstrate that\nMAIN-RAG consistently outperforms traditional RAG approaches, achieving a 2-11%\nimprovement in answer accuracy while reducing the number of irrelevant\nretrieved documents. Quantitative analysis further reveals that our approach\nachieves superior response consistency and answer accuracy over baseline\nmethods, offering a competitive and practical alternative to training-based\nsolutions.",
          "arxiv_id": "2501.00332v1"
        },
        {
          "title": "Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking",
          "year": "2025-08",
          "abstract": "Retrieval-augmented generation (RAG) is critical for reducing hallucinations\nand incorporating external knowledge into Large Language Models (LLMs).\nHowever, advanced RAG systems face a trade-off between performance and\nefficiency. Multi-round RAG approaches achieve strong reasoning but incur\nexcessive LLM calls and token costs, while Graph RAG methods suffer from\ncomputationally expensive, error-prone graph construction and retrieval\nredundancy. To address these challenges, we propose T$^2$RAG, a novel framework\nthat operates on a simple, graph-free knowledge base of atomic triplets.\nT$^2$RAG leverages an LLM to decompose questions into searchable triplets with\nplaceholders, which it then iteratively resolves by retrieving evidence from\nthe triplet database. Empirical results show that T$^2$RAG significantly\noutperforms state-of-the-art multi-round and Graph RAG methods, achieving an\naverage performance gain of up to 11\\% across six datasets while reducing\nretrieval costs by up to 45\\%. Our code is available at\nhttps://github.com/rockcor/T2RAG",
          "arxiv_id": "2508.02435v1"
        }
      ],
      "2": [
        {
          "title": "A Pipeline for Graph-Based Monitoring of the Changes in the Information Space of Russian Social Media during the Lockdown",
          "year": "2021-10",
          "abstract": "With the COVID-19 outbreak and the subsequent lockdown, social media became a\nvital communication tool. The sudden outburst of online activity influenced\ninformation spread and consumption patterns. It increases the relevance of\nstudying the dynamics of social networks and developing data processing\npipelines that allow a comprehensive analysis of social media data in the\ntemporal dimension. This paper scopes the weekly dynamics of the information\nspace represented by Russian social media (Twitter and Livejournal) during a\ncritical period (massive COVID-19 outbreak and first governmental measures).\nThe approach is twofold: a) build the time series of topic similarity\nindicators by identifying COVID-related topics in each week and measuring user\ncontribution to the topic space, and b) cluster user activity and display\nuser-topic relationships on graphs in a dashboard application. The paper\ndescribes the development of the pipeline, explains the choices made and\nprovides a case study of the adaptation to virus control measures. The results\nconfirm that social processes and behaviour in response to pandemic-triggered\nchanges can be successfully traced in social media. Moreover, the adaptation\ntrends revealed by psychological and sociological studies are reflected in our\ndata and can be explored using the proposed method.",
          "arxiv_id": "2110.13626v1"
        },
        {
          "title": "Leveraging Natural Language Processing to Mine Issues on Twitter During the COVID-19 Pandemic",
          "year": "2020-10",
          "abstract": "The recent global outbreak of the coronavirus disease (COVID-19) has spread\nto all corners of the globe. The international travel ban, panic buying, and\nthe need for self-quarantine are among the many other social challenges brought\nabout in this new era. Twitter platforms have been used in various public\nhealth studies to identify public opinion about an event at the local and\nglobal scale. To understand the public concerns and responses to the pandemic,\na system that can leverage machine learning techniques to filter out irrelevant\ntweets and identify the important topics of discussion on social media\nplatforms like Twitter is needed. In this study, we constructed a system to\nidentify the relevant tweets related to the COVID-19 pandemic throughout\nJanuary 1st, 2020 to April 30th, 2020, and explored topic modeling to identify\nthe most discussed topics and themes during this period in our data set.\nAdditionally, we analyzed the temporal changes in the topics with respect to\nthe events that occurred during this pandemic. We found out that eight topics\nwere sufficient to identify the themes in our corpus. These topics depicted a\ntemporal trend. The dominant topics vary over time and align with the events\nrelated to the COVID-19 pandemic.",
          "arxiv_id": "2011.00377v2"
        },
        {
          "title": "Detecting Topic and Sentiment Dynamics Due to COVID-19 Pandemic Using Social Media",
          "year": "2020-07",
          "abstract": "The outbreak of the novel Coronavirus Disease (COVID-19) has greatly\ninfluenced people's daily lives across the globe. Emergent measures and\npolicies (e.g., lockdown, social distancing) have been taken by governments to\ncombat this highly infectious disease. However, people's mental health is also\nat risk due to the long-time strict social isolation rules. Hence, monitoring\npeople's mental health across various events and topics will be extremely\nnecessary for policy makers to make the appropriate decisions. On the other\nhand, social media have been widely used as an outlet for people to publish and\nshare their personal opinions and feelings. The large scale social media posts\n(e.g., tweets) provide an ideal data source to infer the mental health for\npeople during this pandemic period. In this work, we propose a novel framework\nto analyze the topic and sentiment dynamics due to COVID-19 from the massive\nsocial media posts. Based on a collection of 13 million tweets related to\nCOVID-19 over two weeks, we found that the positive sentiment shows higher\nratio than the negative sentiment during the study period. When zooming into\nthe topic-level analysis, we find that different aspects of COVID-19 have been\nconstantly discussed and show comparable sentiment polarities. Some topics like\n``stay safe home\" are dominated with positive sentiment. The others such as\n``people death\" are consistently showing negative sentiment. Overall, the\nproposed framework shows insightful findings based on the analysis of the\ntopic-level sentiment dynamics.",
          "arxiv_id": "2007.02304v1"
        }
      ],
      "3": [
        {
          "title": "ScalingNote: Scaling up Retrievers with Large Language Models for Real-World Dense Retrieval",
          "year": "2024-11",
          "abstract": "Dense retrieval in most industries employs dual-tower architectures to\nretrieve query-relevant documents. Due to online deployment requirements,\nexisting real-world dense retrieval systems mainly enhance performance by\ndesigning negative sampling strategies, overlooking the advantages of scaling\nup. Recently, Large Language Models (LLMs) have exhibited superior performance\nthat can be leveraged for scaling up dense retrieval. However, scaling up\nretrieval models significantly increases online query latency. To address this\nchallenge, we propose ScalingNote, a two-stage method to exploit the scaling\npotential of LLMs for retrieval while maintaining online query latency. The\nfirst stage is training dual towers, both initialized from the same LLM, to\nunlock the potential of LLMs for dense retrieval. Then, we distill only the\nquery tower using mean squared error loss and cosine similarity to reduce\nonline costs. Through theoretical analysis and comprehensive offline and online\nexperiments, we show the effectiveness and efficiency of ScalingNote. Our\ntwo-stage scaling method outperforms end-to-end models and verifies the scaling\nlaw of dense retrieval with LLMs in industrial scenarios, enabling\ncost-effective scaling of dense retrieval systems. Our online method\nincorporating ScalingNote significantly enhances the relevance between\nretrieved documents and queries.",
          "arxiv_id": "2411.15766v1"
        },
        {
          "title": "On Cross-Lingual Retrieval with Multilingual Text Encoders",
          "year": "2021-12",
          "abstract": "In this work we present a systematic empirical study focused on the\nsuitability of the state-of-the-art multilingual encoders for cross-lingual\ndocument and sentence retrieval tasks across a number of diverse language\npairs. We first treat these models as multilingual text encoders and benchmark\ntheir performance in unsupervised ad-hoc sentence- and document-level CLIR. In\ncontrast to supervised language understanding, our results indicate that for\nunsupervised document-level CLIR -- a setup with no relevance judgments for\nIR-specific fine-tuning -- pretrained multilingual encoders on average fail to\nsignificantly outperform earlier models based on CLWEs. For sentence-level\nretrieval, we do obtain state-of-the-art performance: the peak scores, however,\nare met by multilingual encoders that have been further specialized, in a\nsupervised fashion, for sentence understanding tasks, rather than using their\nvanilla 'off-the-shelf' variants. Following these results, we introduce\nlocalized relevance matching for document-level CLIR, where we independently\nscore a query against document sections. In the second part, we evaluate\nmultilingual encoders fine-tuned in a supervised fashion (i.e., we learn to\nrank) on English relevance data in a series of zero-shot language and domain\ntransfer CLIR experiments. Our results show that supervised re-ranking rarely\nimproves the performance of multilingual transformers as unsupervised base\nrankers. Finally, only with in-domain contrastive fine-tuning (i.e., same\ndomain, only language transfer), we manage to improve the ranking quality. We\nuncover substantial empirical differences between cross-lingual retrieval\nresults and results of (zero-shot) cross-lingual transfer for monolingual\nretrieval in target languages, which point to \"monolingual overfitting\" of\nretrieval models trained on monolingual data.",
          "arxiv_id": "2112.11031v1"
        },
        {
          "title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval",
          "year": "2024-04",
          "abstract": "Utilizing large language models (LLMs) for zero-shot document ranking is done\nin one of two ways: (1) prompt-based re-ranking methods, which require no\nfurther training but are only feasible for re-ranking a handful of candidate\ndocuments due to computational costs; and (2) unsupervised contrastive trained\ndense retrieval methods, which can retrieve relevant documents from the entire\ncorpus but require a large amount of paired text data for contrastive training.\nIn this paper, we propose PromptReps, which combines the advantages of both\ncategories: no need for training and the ability to retrieve from the whole\ncorpus. Our method only requires prompts to guide an LLM to generate query and\ndocument representations for effective document retrieval. Specifically, we\nprompt the LLMs to represent a given text using a single word, and then use the\nlast token's hidden states and the corresponding logits associated with the\nprediction of the next token to construct a hybrid document retrieval system.\nThe retrieval system harnesses both dense text embedding and sparse\nbag-of-words representations given by the LLM. Our experimental evaluation on\nthe MSMARCO, TREC deep learning and BEIR zero-shot document retrieval datasets\nillustrates that this simple prompt-based LLM retrieval method can achieve a\nsimilar or higher retrieval effectiveness than state-of-the-art LLM embedding\nmethods that are trained with large amounts of unsupervised data, especially\nwhen using a larger LLM.",
          "arxiv_id": "2404.18424v3"
        }
      ],
      "4": [
        {
          "title": "GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval",
          "year": "2025-05",
          "abstract": "Few-shot cross-modal retrieval focuses on learning cross-modal\nrepresentations with limited training samples, enabling the model to handle\nunseen classes during inference. Unlike traditional cross-modal retrieval\ntasks, which assume that both training and testing data share the same class\ndistribution, few-shot retrieval involves data with sparse representations\nacross modalities. Existing methods often fail to adequately model the\nmulti-peak distribution of few-shot cross-modal data, resulting in two main\nbiases in the latent semantic space: intra-modal bias, where sparse samples\nfail to capture intra-class diversity, and inter-modal bias, where\nmisalignments between image and text distributions exacerbate the semantic gap.\nThese biases hinder retrieval accuracy. To address these issues, we propose a\nnovel method, GCRDP, for few-shot cross-modal retrieval. This approach\neffectively captures the complex multi-peak distribution of data using a\nGaussian Mixture Model (GMM) and incorporates a multi-positive sample\ncontrastive learning mechanism for comprehensive feature modeling.\nAdditionally, we introduce a new strategy for cross-modal semantic alignment,\nwhich constrains the relative distances between image and text feature\ndistributions, thereby improving the accuracy of cross-modal representations.\nWe validate our approach through extensive experiments on four benchmark\ndatasets, demonstrating superior performance over six state-of-the-art methods.",
          "arxiv_id": "2505.13306v1"
        },
        {
          "title": "Object-Aware Query Perturbation for Cross-Modal Image-Text Retrieval",
          "year": "2024-07",
          "abstract": "The pre-trained vision and language (V\\&L) models have substantially improved\nthe performance of cross-modal image-text retrieval. In general, however, V\\&L\nmodels have limited retrieval performance for small objects because of the\nrough alignment between words and the small objects in the image. In contrast,\nit is known that human cognition is object-centric, and we pay more attention\nto important objects, even if they are small. To bridge this gap between the\nhuman cognition and the V\\&L model's capability, we propose a cross-modal\nimage-text retrieval framework based on ``object-aware query perturbation.''\nThe proposed method generates a key feature subspace of the detected objects\nand perturbs the corresponding queries using this subspace to improve the\nobject awareness in the image. In our proposed method, object-aware cross-modal\nimage-text retrieval is possible while keeping the rich expressive power and\nretrieval performance of existing V\\&L models without additional fine-tuning.\nComprehensive experiments on four public datasets show that our method\noutperforms conventional algorithms. Our code is publicly available at\n\\url{https://github.com/NEC-N-SOGI/query-perturbation}.",
          "arxiv_id": "2407.12346v2"
        },
        {
          "title": "Progressive Learning for Image Retrieval with Hybrid-Modality Queries",
          "year": "2022-04",
          "abstract": "Image retrieval with hybrid-modality queries, also known as composing text\nand image for image retrieval (CTI-IR), is a retrieval task where the search\nintention is expressed in a more complex query format, involving both vision\nand text modalities. For example, a target product image is searched using a\nreference product image along with text about changing certain attributes of\nthe reference image as the query. It is a more challenging image retrieval task\nthat requires both semantic space learning and cross-modal fusion. Previous\napproaches that attempt to deal with both aspects achieve unsatisfactory\nperformance. In this paper, we decompose the CTI-IR task into a three-stage\nlearning problem to progressively learn the complex knowledge for image\nretrieval with hybrid-modality queries. We first leverage the semantic\nembedding space for open-domain image-text retrieval, and then transfer the\nlearned knowledge to the fashion-domain with fashion-related pre-training\ntasks. Finally, we enhance the pre-trained model from single-query to\nhybrid-modality query for the CTI-IR task. Furthermore, as the contribution of\nindividual modality in the hybrid-modality query varies for different retrieval\nscenarios, we propose a self-supervised adaptive weighting strategy to\ndynamically determine the importance of image and text in the hybrid-modality\nquery for better retrieval. Extensive experiments show that our proposed model\nsignificantly outperforms state-of-the-art methods in the mean of Recall@K by\n24.9% and 9.5% on the Fashion-IQ and Shoes benchmark datasets respectively.",
          "arxiv_id": "2204.11212v1"
        }
      ],
      "5": [
        {
          "title": "Dynamic Q&A of Clinical Documents with Large Language Models",
          "year": "2024-01",
          "abstract": "Electronic health records (EHRs) house crucial patient data in clinical\nnotes. As these notes grow in volume and complexity, manual extraction becomes\nchallenging. This work introduces a natural language interface using large\nlanguage models (LLMs) for dynamic question-answering on clinical notes. Our\nchatbot, powered by Langchain and transformer-based LLMs, allows users to query\nin natural language, receiving relevant answers from clinical notes.\nExperiments, utilizing various embedding models and advanced LLMs, show Wizard\nVicuna's superior accuracy, albeit with high compute demands. Model\noptimization, including weight quantization, improves latency by approximately\n48 times. Promising results indicate potential, yet challenges such as model\nhallucinations and limited diverse medical case evaluations remain. Addressing\nthese gaps is crucial for unlocking the value in clinical notes and advancing\nAI-driven clinical decision-making.",
          "arxiv_id": "2401.10733v2"
        },
        {
          "title": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines",
          "year": "2025-06",
          "abstract": "Current medical language models, adapted from large language models (LLMs),\ntypically predict ICD code-based diagnosis from electronic health records\n(EHRs) because these labels are readily available. However, ICD codes do not\ncapture the nuanced, context-rich reasoning clinicians use for diagnosis.\nClinicians synthesize diverse patient data and reference clinical practice\nguidelines (CPGs) to make evidence-based decisions. This misalignment limits\nthe clinical utility of existing models. We introduce GARMLE-G, a\nGeneration-Augmented Retrieval framework that grounds medical language model\noutputs in authoritative CPGs. Unlike conventional Retrieval-Augmented\nGeneration based approaches, GARMLE-G enables hallucination-free outputs by\ndirectly retrieving authoritative guideline content without relying on\nmodel-generated text. It (1) integrates LLM predictions with EHR data to create\nsemantically rich queries, (2) retrieves relevant CPG knowledge snippets via\nembedding similarity, and (3) fuses guideline content with model output to\ngenerate clinically aligned recommendations. A prototype system for\nhypertension diagnosis was developed and evaluated on multiple metrics,\ndemonstrating superior retrieval precision, semantic relevance, and clinical\nguideline adherence compared to RAG-based baselines, while maintaining a\nlightweight architecture suitable for localized healthcare deployment. This\nwork provides a scalable, low-cost, and hallucination-free method for grounding\nmedical language models in evidence-based clinical practice, with strong\npotential for broader clinical deployment.",
          "arxiv_id": "2506.21615v1"
        },
        {
          "title": "Neural Language Models with Distant Supervision to Identify Major Depressive Disorder from Clinical Notes",
          "year": "2021-04",
          "abstract": "Major depressive disorder (MDD) is a prevalent psychiatric disorder that is\nassociated with significant healthcare burden worldwide. Phenotyping of MDD can\nhelp early diagnosis and consequently may have significant advantages in\npatient management. In prior research MDD phenotypes have been extracted from\nstructured Electronic Health Records (EHR) or using Electroencephalographic\n(EEG) data with traditional machine learning models to predict MDD phenotypes.\nHowever, MDD phenotypic information is also documented in free-text EHR data,\nsuch as clinical notes. While clinical notes may provide more accurate\nphenotyping information, natural language processing (NLP) algorithms must be\ndeveloped to abstract such information. Recent advancements in NLP resulted in\nstate-of-the-art neural language models, such as Bidirectional Encoder\nRepresentations for Transformers (BERT) model, which is a transformer-based\nmodel that can be pre-trained from a corpus of unsupervised text data and then\nfine-tuned on specific tasks. However, such neural language models have been\nunderutilized in clinical NLP tasks due to the lack of large training datasets.\nIn the literature, researchers have utilized the distant supervision paradigm\nto train machine learning models on clinical text classification tasks to\nmitigate the issue of lacking annotated training data. It is still unknown\nwhether the paradigm is effective for neural language models. In this paper, we\npropose to leverage the neural language models in a distant supervision\nparadigm to identify MDD phenotypes from clinical notes. The experimental\nresults indicate that our proposed approach is effective in identifying MDD\nphenotypes and that the Bio- Clinical BERT, a specific BERT model for clinical\ndata, achieved the best performance in comparison with conventional machine\nlearning models.",
          "arxiv_id": "2104.09644v1"
        }
      ],
      "6": [
        {
          "title": "A Dataset and Baselines for Measuring and Predicting the Music Piece Memorability",
          "year": "2024-05",
          "abstract": "Nowadays, humans are constantly exposed to music, whether through voluntary\nstreaming services or incidental encounters during commercial breaks. Despite\nthe abundance of music, certain pieces remain more memorable and often gain\ngreater popularity. Inspired by this phenomenon, we focus on measuring and\npredicting music memorability. To achieve this, we collect a new music piece\ndataset with reliable memorability labels using a novel interactive\nexperimental procedure. We then train baselines to predict and analyze music\nmemorability, leveraging both interpretable features and audio mel-spectrograms\nas inputs. To the best of our knowledge, we are the first to explore music\nmemorability using data-driven deep learning-based methods. Through a series of\nexperiments and ablation studies, we demonstrate that while there is room for\nimprovement, predicting music memorability with limited data is possible.\nCertain intrinsic elements, such as higher valence, arousal, and faster tempo,\ncontribute to memorable music. As prediction techniques continue to evolve,\nreal-life applications like music recommendation systems and music style\ntransfer will undoubtedly benefit from this new area of research.",
          "arxiv_id": "2405.12847v1"
        },
        {
          "title": "Proceedings of the 5th International Workshop on Reading Music Systems",
          "year": "2023-11",
          "abstract": "The International Workshop on Reading Music Systems (WoRMS) is a workshop\nthat tries to connect researchers who develop systems for reading music, such\nas in the field of Optical Music Recognition, with other researchers and\npractitioners that could benefit from such systems, like librarians or\nmusicologists. The relevant topics of interest for the workshop include, but\nare not limited to: Music reading systems; Optical music recognition; Datasets\nand performance evaluation; Image processing on music scores; Writer\nidentification; Authoring, editing, storing and presentation systems for music\nscores; Multi-modal systems; Novel input-methods for music to produce written\nmusic; Web-based Music Information Retrieval services; Applications and\nprojects; Use-cases related to written music.\n  These are the proceedings of the 5th International Workshop on Reading Music\nSystems, held in Milan, Italy on Nov. 4th 2023.",
          "arxiv_id": "2311.04091v1"
        },
        {
          "title": "What is missing in deep music generation? A study of repetition and structure in popular music",
          "year": "2022-09",
          "abstract": "Structure is one of the most essential aspects of music, and music structure\nis commonly indicated through repetition. However, the nature of repetition and\nstructure in music is still not well understood, especially in the context of\nmusic generation, and much remains to be explored with Music Information\nRetrieval (MIR) techniques. Analyses of two popular music datasets (Chinese and\nAmerican) illustrate important music construction principles: (1) structure\nexists at multiple hierarchical levels, (2) songs use repetition and limited\nvocabulary so that individual songs do not follow general statistics of song\ncollections, (3) structure interacts with rhythm, melody, harmony, and\npredictability, and (4) over the course of a song, repetition is not random,\nbut follows a general trend as revealed by cross-entropy. These and other\nfindings offer challenges as well as opportunities for deep-learning music\ngeneration and suggest new formal music criteria and evaluation methods. Music\nfrom recent music generation systems is analyzed and compared to human-composed\nmusic in our datasets, often revealing striking differences from a structural\nperspective.",
          "arxiv_id": "2209.00182v1"
        }
      ],
      "7": [
        {
          "title": "Entity Context Graph: Learning Entity Representations fromSemi-Structured Textual Sources on the Web",
          "year": "2021-03",
          "abstract": "Knowledge is captured in the form of entities and their relationships and\nstored in knowledge graphs. Knowledge graphs enhance the capabilities of\napplications in many different areas including Web search, recommendation, and\nnatural language understanding. This is mainly because, entities enable\nmachines to understand things that go beyond simple tokens. Many modern\nalgorithms use learned entity embeddings from these structured representations.\nHowever, building a knowledge graph takes time and effort, hence very costly\nand nontrivial. On the other hand, many Web sources describe entities in some\nstructured format and therefore, finding ways to get them into useful entity\nknowledge is advantageous. We propose an approach that processes entity centric\ntextual knowledge sources to learn entity embeddings and in turn avoids the\nneed for a traditional knowledge graph. We first extract triples into the new\nrepresentation format that does not use traditional complex triple extraction\nmethods defined by pre-determined relationship labels. Then we learn entity\nembeddings through this new type of triples. We show that the embeddings\nlearned from our approach are: (i) high quality and comparable to a known\nknowledge graph-based embeddings and can be used to improve them further, (ii)\nbetter than a contextual language model-based entity embeddings, and (iii) easy\nto compute and versatile in domain-specific applications where a knowledge\ngraph is not readily available",
          "arxiv_id": "2103.15950v1"
        },
        {
          "title": "Person Entity Profiling Framework: Identifying, Integrating and Visualizing Online Freely Available Entity-Related Information",
          "year": "2021-10",
          "abstract": "When we consider our CV, it is full of entities that we are or were\nassociated with and that define us in some way(s). Such entities include where\nwe studied, where we worked, who we collaborated with on a project or on a\npaper etc. Entities we are linked to are part of who we are and may reveal\nabout what we are interested in. Hence, we can view any CV as a graph of\ninterlinked entities, where nodes are entities and edges are relations between\nthem. This study proposes a novel entity search framework that in response to a\nreal-time query about an entity, searches, crawls, analyzes and consolidates\nrelevant information that is freely available on the Web about the entity of\ninterest, culminating in the generation a profile of the searched entity.\nUnlike typical entity search settings, in which a ranked list of entities\nrelated to the target entity over a pre-specified relation is processed, we\npresent and visualize rich information about the entity of interest as a typed\nentity-relation graph without an apriori definition of the types of related\nentities and relations. This view is structured and compact, making it easy to\nunderstand as well as interpret. It enables the user to learn not only about\nthe entity in question, but also about related entities, thereby obtaining a\nbetter understanding of the entity in question. We evaluated each of the\nframeworks components separately and then performed an overall evaluation of\nthe framework, its visualization and the interest of users in the results. The\nresults show that the proposed framework performs entity searches, related\nentity identification and relation identification very well and that it\nsatisfies users needs.",
          "arxiv_id": "2110.00759v1"
        },
        {
          "title": "Entity-aware Transformers for Entity Search",
          "year": "2022-05",
          "abstract": "Pre-trained language models such as BERT have been a key ingredient to\nachieve state-of-the-art results on a variety of tasks in natural language\nprocessing and, more recently, also in information retrieval.Recent research\neven claims that BERT is able to capture factual knowledge about entity\nrelations and properties, the information that is commonly obtained from\nknowledge graphs. This paper investigates the following question: Do BERT-based\nentity retrieval models benefit from additional entity information stored in\nknowledge graphs? To address this research question, we map entity embeddings\ninto the same input space as a pre-trained BERT model and inject these entity\nembeddings into the BERT model. This entity-enriched language model is then\nemployed on the entity retrieval task. We show that the entity-enriched BERT\nmodel improves effectiveness on entity-oriented queries over a regular BERT\nmodel, establishing a new state-of-the-art result for the entity retrieval\ntask, with substantial improvements for complex natural language queries and\nqueries requesting a list of entities with a certain property. Additionally, we\nshow that the entity information provided by our entity-enriched model\nparticularly helps queries related to less popular entities. Last, we observe\nempirically that the entity-enriched BERT models enable fine-tuning on limited\ntraining data, which otherwise would not be feasible due to the known\ninstabilities of BERT in few-sample fine-tuning, thereby contributing to\ndata-efficient training of BERT for entity search.",
          "arxiv_id": "2205.00820v1"
        }
      ],
      "8": [
        {
          "title": "Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search",
          "year": "2024-07",
          "abstract": "Conversational search supports multi-turn user-system interactions to solve\ncomplex information needs. Different from the traditional single-turn ad-hoc\nsearch, conversational search encounters a more challenging problem of\ncontext-dependent query understanding with the lengthy and long-tail\nconversational history context. While conversational query rewriting methods\nleverage explicit rewritten queries to train a rewriting model to transform the\ncontext-dependent query into a stand-stone search query, this is usually done\nwithout considering the quality of search results. Conversational dense\nretrieval methods use fine-tuning to improve a pre-trained ad-hoc query\nencoder, but they are limited by the conversational search data available for\ntraining. In this paper, we leverage both rewritten queries and relevance\njudgments in the conversational search data to train a better query\nrepresentation model. The key idea is to align the query representation with\nthose of rewritten queries and relevant documents. The proposed model -- Query\nRepresentation Alignment Conversational Dense Retriever, QRACDR, is tested on\neight datasets, including various settings in conversational search and ad-hoc\nsearch. The results demonstrate the strong performance of QRACDR compared with\nstate-of-the-art methods, and confirm the effectiveness of representation\nalignment.",
          "arxiv_id": "2407.20189v1"
        },
        {
          "title": "Reward-free Policy Imitation Learning for Conversational Search",
          "year": "2023-04",
          "abstract": "Existing conversational search studies mainly focused on asking better\nclarifying questions and/or improving search result quality. These works aim at\nretrieving better responses according to the search context, and their\nperformances are evaluated on either single-turn tasks or multi-turn tasks\nunder naive conversation policy settings. This leaves some questions about\ntheir applicability in real-world multi-turn conversations where realistically,\neach and every action needs to be made by the system itself, and search session\nefficiency is often an important concern of conversational search systems.\nWhile some recent works have identified the need for improving search\nefficiency in conversational search, they mostly require extensive data\nannotations and use hand-crafted rewards or heuristics to train systems that\ncan achieve reasonable performance in a restricted number of turns, which has\nlimited generalizability in practice.\n  In this paper, we propose a reward-free conversation policy imitation\nlearning framework, which can train a conversation policy without annotated\nconversation data or manually designed rewards. The trained conversation policy\ncan be used to guide the conversational retrieval models to balance\nconversational search quality and efficiency. To evaluate the proposed\nconversational search system, we propose a new multi-turn-multi-response\nconversational evaluation metric named Expected Conversational Reciprocal Rank\n(ECRR). ECRR is designed to evaluate entire multi-turn conversational search\nsessions towards comprehensively evaluating both search result quality and\nsearch efficiency.",
          "arxiv_id": "2304.07988v1"
        },
        {
          "title": "Towards Better Understanding of User Satisfaction in Open-Domain Conversational Search",
          "year": "2022-04",
          "abstract": "With the increasing popularity of conversational search, how to evaluate the\nperformance of conversational search systems has become an important question\nin the IR community. Existing works on conversational search evaluation can\nmainly be categorized into two streams: (1) constructing metrics based on\nsemantic similarity (e.g. BLUE, METEOR and BERTScore), or (2) directly\nevaluating the response ranking performance of the system using traditional\nsearch methods (e.g. nDCG, RBP and nERR). However, these methods either ignore\nthe information need of the user or ignore the mixed-initiative property of\nconversational search. This raises the question of how to accurately model user\nsatisfaction in conversational search scenarios. Since explicitly asking users\nto provide satisfaction feedback is difficult, traditional IR studies often\nrely on the Cranfield paradigm (i.e., third-party annotation) and user behavior\nmodeling to estimate user satisfaction in search. However, the feasibility and\neffectiveness of these two approaches have not been fully explored in\nconversational search. In this paper, we dive into the evaluation of\nconversational search from the perspective of user satisfaction. We build a\nnovel conversational search experimental platform and construct a Chinese\nopen-domain conversational search behavior dataset containing rich annotations\nand search behavior data. We also collect third-party satisfaction annotation\nat the session-level and turn-level, to investigate the feasibility of the\nCranfield paradigm in the conversational search scenario. Experimental results\nshow both some consistency and considerable differences between the user\nsatisfaction annotations and third-party annotations. We also propose dialog\ncontinuation or ending behavior models (DCEBM) to capture session-level user\nsatisfaction based on turn-level information.",
          "arxiv_id": "2204.02659v2"
        }
      ],
      "9": [
        {
          "title": "FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling",
          "year": "2022-02",
          "abstract": "Federated learning (FL) is a feasible technique to learn personalized\nrecommendation models from decentralized user data. Unfortunately, federated\nrecommender systems are vulnerable to poisoning attacks by malicious clients.\nExisting recommender system poisoning methods mainly focus on promoting the\nrecommendation chances of target items due to financial incentives. In fact, in\nreal-world scenarios, the attacker may also attempt to degrade the overall\nperformance of recommender systems. However, existing general FL poisoning\nmethods for degrading model performance are either ineffective or not concealed\nin poisoning federated recommender systems. In this paper, we propose a simple\nyet effective and covert poisoning attack method on federated recommendation,\nnamed FedAttack. Its core idea is using globally hardest samples to subvert\nmodel training. More specifically, the malicious clients first infer user\nembeddings based on local user profiles. Next, they choose the candidate items\nthat are most relevant to the user embeddings as hardest negative samples, and\nfind the candidates farthest from the user embeddings as hardest positive\nsamples. The model gradients inferred from these poisoned samples are then\nuploaded to the server for aggregation and model update. Since the behaviors of\nmalicious clients are somewhat similar to users with diverse interests, they\ncannot be effectively distinguished from normal clients by the server.\nExtensive experiments on two benchmark datasets show that FedAttack can\neffectively degrade the performance of various federated recommender systems,\nmeanwhile cannot be effectively detected nor defended by many existing methods.",
          "arxiv_id": "2202.04975v1"
        },
        {
          "title": "User Consented Federated Recommender System Against Personalized Attribute Inference Attack",
          "year": "2023-12",
          "abstract": "Recommender systems can be privacy-sensitive. To protect users' private\nhistorical interactions, federated learning has been proposed in distributed\nlearning for user representations. Using federated recommender (FedRec)\nsystems, users can train a shared recommendation model on local devices and\nprevent raw data transmissions and collections. However, the recommendation\nmodel learned by a common FedRec may still be vulnerable to private information\nleakage risks, particularly attribute inference attacks, which means that the\nattacker can easily infer users' personal attributes from the learned model.\nAdditionally, traditional FedRecs seldom consider the diverse privacy\npreference of users, leading to difficulties in balancing the recommendation\nutility and privacy preservation. Consequently, FedRecs may suffer from\nunnecessary recommendation performance loss due to over-protection and private\ninformation leakage simultaneously. In this work, we propose a novel\nuser-consented federated recommendation system (UC-FedRec) to flexibly satisfy\nthe different privacy needs of users by paying a minimum recommendation\naccuracy price. UC-FedRec allows users to self-define their privacy preferences\nto meet various demands and makes recommendations with user consent.\nExperiments conducted on different real-world datasets demonstrate that our\nframework is more efficient and flexible compared to baselines.",
          "arxiv_id": "2312.16203v1"
        },
        {
          "title": "PipAttack: Poisoning Federated Recommender Systems forManipulating Item Promotion",
          "year": "2021-10",
          "abstract": "Due to the growing privacy concerns, decentralization emerges rapidly in\npersonalized services, especially recommendation. Also, recent studies have\nshown that centralized models are vulnerable to poisoning attacks, compromising\ntheir integrity. In the context of recommender systems, a typical goal of such\npoisoning attacks is to promote the adversary's target items by interfering\nwith the training dataset and/or process. Hence, a common practice is to\nsubsume recommender systems under the decentralized federated learning\nparadigm, which enables all user devices to collaboratively learn a global\nrecommender while retaining all the sensitive data locally. Without exposing\nthe full knowledge of the recommender and entire dataset to end-users, such\nfederated recommendation is widely regarded `safe' towards poisoning attacks.\nIn this paper, we present a systematic approach to backdooring federated\nrecommender systems for targeted item promotion. The core tactic is to take\nadvantage of the inherent popularity bias that commonly exists in data-driven\nrecommenders. As popular items are more likely to appear in the recommendation\nlist, our innovatively designed attack model enables the target item to have\nthe characteristics of popular items in the embedding space. Then, by uploading\ncarefully crafted gradients via a small number of malicious users during the\nmodel update, we can effectively increase the exposure rate of a target\n(unpopular) item in the resulted federated recommender. Evaluations on two\nreal-world datasets show that 1) our attack model significantly boosts the\nexposure rate of the target item in a stealthy way, without harming the\naccuracy of the poisoned recommender; and 2) existing defenses are not\neffective enough, highlighting the need for new defenses against our local\nmodel poisoning attacks to federated recommender systems.",
          "arxiv_id": "2110.10926v1"
        }
      ],
      "10": [
        {
          "title": "Relative NN-Descent: A Fast Index Construction for Graph-Based Approximate Nearest Neighbor Search",
          "year": "2023-10",
          "abstract": "Approximate Nearest Neighbor Search (ANNS) is the task of finding the\ndatabase vector that is closest to a given query vector. Graph-based ANNS is\nthe family of methods with the best balance of accuracy and speed for\nmillion-scale datasets. However, graph-based methods have the disadvantage of\nlong index construction time. Recently, many researchers have improved the\ntradeoff between accuracy and speed during a search. However, there is little\nresearch on accelerating index construction. We propose a fast graph\nconstruction algorithm, Relative NN-Descent (RNN-Descent). RNN-Descent combines\nNN-Descent, an algorithm for constructing approximate K-nearest neighbor graphs\n(K-NN graphs), and RNG Strategy, an algorithm for selecting edges effective for\nsearch. This algorithm allows the direct construction of graph-based indexes\nwithout ANNS. Experimental results demonstrated that the proposed method had\nthe fastest index construction speed, while its search performance is\ncomparable to existing state-of-the-art methods such as NSG. For example, in\nexperiments on the GIST1M dataset, the construction of the proposed method is\n2x faster than NSG. Additionally, it was even faster than the construction\nspeed of NN-Descent.",
          "arxiv_id": "2310.20419v1"
        },
        {
          "title": "CRouting: Reducing Expensive Distance Calls in Graph-Based Approximate Nearest Neighbor Search",
          "year": "2025-08",
          "abstract": "Approximate nearest neighbor search (ANNS) is a crucial problem in\ninformation retrieval and AI applications. Recently, there has been a surge of\ninterest in graph-based ANNS algorithms due to their superior efficiency and\naccuracy. However, the repeated computation of distances in high-dimensional\nspaces constitutes the primary time cost of graph-based methods. To accelerate\nthe search, we propose a novel routing strategy named CRouting, which bypasses\nunnecessary distance computations by exploiting the angle distributions of\nhigh-dimensional vectors. CRouting is designed as a plugin to optimize existing\ngraph-based search with minimal code modifications. Our experiments show that\nCRouting reduces the number of distance computations by up to 41.5% and boosts\nqueries per second by up to 1.48$\\times$ on two predominant graph indexes, HNSW\nand NSG. Code is publicly available at https://github.com/ISCS-ZJU/CRouting.",
          "arxiv_id": "2509.00365v1"
        },
        {
          "title": "ParlayANN: Scalable and Deterministic Parallel Graph-Based Approximate Nearest Neighbor Search Algorithms",
          "year": "2023-05",
          "abstract": "Approximate nearest-neighbor search (ANNS) algorithms are a key part of the\nmodern deep learning stack due to enabling efficient similarity search over\nhigh-dimensional vector space representations (i.e., embeddings) of data. Among\nvarious ANNS algorithms, graph-based algorithms are known to achieve the best\nthroughput-recall tradeoffs. Despite the large scale of modern ANNS datasets,\nexisting parallel graph based implementations suffer from significant\nchallenges to scale to large datasets due to heavy use of locks and other\nsequential bottlenecks, which 1) prevents them from efficiently scaling to a\nlarge number of processors, and 2) results in nondeterminism that is\nundesirable in certain applications.\n  In this paper, we introduce ParlayANN, a library of deterministic and\nparallel graph-based approximate nearest neighbor search algorithms, along with\na set of useful tools for developing such algorithms. In this library, we\ndevelop novel parallel implementations for four state-of-the-art graph-based\nANNS algorithms that scale to billion-scale datasets. Our algorithms are\ndeterministic and achieve high scalability across a diverse set of challenging\ndatasets. In addition to the new algorithmic ideas, we also conduct a detailed\nexperimental study of our new algorithms as well as two existing non-graph\napproaches. Our experimental results both validate the effectiveness of our new\ntechniques, and lead to a comprehensive comparison among ANNS algorithms on\nlarge scale datasets with a list of interesting findings.",
          "arxiv_id": "2305.04359v2"
        }
      ],
      "11": [
        {
          "title": "Multi-Server Private Linear Computation with Joint and Individual Privacy Guarantees",
          "year": "2021-08",
          "abstract": "This paper considers the problem of multi-server Private Linear Computation,\nunder the joint and individual privacy guarantees. In this problem, identical\ncopies of a dataset comprised of $K$ messages are stored on $N$ non-colluding\nservers, and a user wishes to obtain one linear combination of a $D$-subset of\nmessages belonging to the dataset. The goal is to design a scheme for\nperforming the computation such that the total amount of information downloaded\nfrom the servers is minimized, while the privacy of the $D$ messages required\nfor the computation is protected. When joint privacy is required, the\nidentities of all of these $D$ messages must be kept private jointly, and when\nindividual privacy is required, the identity of every one of these $D$ messages\nmust be kept private individually. In this work, we characterize the capacity,\nwhich is defined as the maximum achievable download rate, under both joint and\nindividual privacy requirements. In particular, we show that when joint privacy\nis required the capacity is given by ${(1+1/N+\\dots+1/N^{K-D})^{-1}}$, and when\nindividual privacy is required the capacity is given by\n${(1+1/N+\\dots+1/N^{\\lceil K/D\\rceil-1})^{-1}}$ assuming that $D$ divides $K$,\nor $K\\pmod D$ divides $D$. Our converse proofs are based on reduction from two\nvariants of the multi-server Private Information Retrieval problem in the\npresence of side information. Our achievability schemes build up on our\nrecently proposed schemes for single-server Private Linear Transformation and\nthe multi-server private computation scheme proposed by Sun and Jafar. Using\nsimilar proof techniques, we also establish upper and lower bounds on the\ncapacity for the cases in which the user wants to compute $L$ (potentially more\nthan one) linear combinations.",
          "arxiv_id": "2108.09271v2"
        },
        {
          "title": "The Role of Reusable and Single-Use Side Information in Private Information Retrieval",
          "year": "2022-01",
          "abstract": "This paper introduces the problem of Private Information Retrieval with\nReusable and Single-use Side Information (PIR-RSSI). In this problem, one or\nmore remote servers store identical copies of a set of $K$ messages, and there\nis a user that initially knows $M$ of these messages, and wants to privately\nretrieve one other message from the set of $K$ messages. The objective is to\ndesign a retrieval scheme in which the user downloads the minimum amount of\ninformation from the server(s) while the identity of the message wanted by the\nuser and the identities of an $M_1$-subset of the $M$ messages known by the\nuser (referred to as reusable side information) are protected, but the\nidentities of the remaining $M_2=M-M_1$ messages known by the user (referred to\nas single-use side information) do not need to be protected. The PIR-RSSI\nproblem reduces to the classical Private Information Retrieval (PIR) problem\nwhen ${M_1=M_2=0}$, and reduces to the problem of PIR with Private Side\nInformation or PIR with Side Information when ${M_1\\geq 1,M_2=0}$ or\n${M_1=0,M_2\\geq 1}$, respectively. In this work, we focus on the single-server\nsetting of the PIR-RSSI problem. We characterize the capacity of this setting\nfor the cases of ${M_1=1,M_2\\geq 1}$ and ${M_1\\geq 1,M_2=1}$, where the\ncapacity is defined as the maximum achievable download rate over all PIR-RSSI\nschemes. Our results show that for sufficiently small values of $K$, the\nsingle-use side information messages can help in reducing the download cost\nonly if they are kept private; and for larger values of $K$, the reusable side\ninformation messages cannot help in reducing the download cost.",
          "arxiv_id": "2201.11605v1"
        },
        {
          "title": "Quantum Private Information Retrieval from Coded Storage Systems",
          "year": "2023-12",
          "abstract": "In the era of extensive data growth, robust and efficient mechanisms are\nneeded to store and manage vast amounts of digital information, such as Data\nStorage Systems (DSSs). Concurrently, privacy concerns have arisen, leading to\nthe development of techniques like Private Information Retrieval (PIR) to\nenable data access while preserving privacy. A PIR protocol allows users to\nretrieve information from a database without revealing the specifics of their\nquery or the data they are accessing.\n  With the advent of quantum computing, researchers have explored the potential\nof using quantum systems to enhance privacy in information retrieval. In a\nQuantum Private Information Retrieval (QPIR) protocol, a user can retrieve\ninformation from a database by downloading quantum systems from multiple\nservers, while ensuring that the servers remain oblivious to the specific\ninformation being accessed. This scenario offers a unique advantage by\nleveraging the inherent properties of quantum systems to provide enhanced\nprivacy guarantees and improved communication rates compared to classical PIR\nprotocols.\n  In this thesis we consider the QPIR setting where the queries and the coded\nstorage systems are classical, while the responses from the servers are\nquantum. This problem was treated by Song et al. for replicated storage and\ndifferent collusion patterns. This thesis aims to develop QPIR protocols for\ncoded storage by combining known classical PIR protocols with quantum\ncommunication algorithms, achieving enhanced privacy and communication costs.\nWe consider different storage codes and robustness assumptions, and we prove\nthat the achieved communication cost is always lower than the classical\ncounterparts.",
          "arxiv_id": "2312.07570v1"
        }
      ],
      "12": [
        {
          "title": "Enhancing Node Representations for Real-World Complex Networks with Topological Augmentation",
          "year": "2024-02",
          "abstract": "Graph augmentation methods play a crucial role in improving the performance\nand enhancing generalisation capabilities in Graph Neural Networks (GNNs).\nExisting graph augmentation methods mainly perturb the graph structures, and\nare usually limited to pairwise node relations. These methods cannot fully\naddress the complexities of real-world large-scale networks, which often\ninvolve higher-order node relations beyond only being pairwise. Meanwhile,\nreal-world graph datasets are predominantly modelled as simple graphs, due to\nthe scarcity of data that can be used to form higher-order edges. Therefore,\nreconfiguring the higher-order edges as an integration into graph augmentation\nstrategies lights up a promising research path to address the aforementioned\nissues. In this paper, we present Topological Augmentation (TopoAug), a novel\ngraph augmentation method that builds a combinatorial complex from the original\ngraph by constructing virtual hyperedges directly from the raw data. TopoAug\nthen produces auxiliary node features by extracting information from the\ncombinatorial complex, which are used for enhancing GNN performances on\ndownstream tasks. We design three diverse virtual hyperedge construction\nstrategies to accompany the construction of combinatorial complexes: (1) via\ngraph statistics, (2) from multiple data perspectives, and (3) utilising\nmulti-modality. Furthermore, to facilitate TopoAug evaluation, we provide 23\nnovel real-world graph datasets across various domains including social media,\nbiology, and e-commerce. Our empirical study shows that TopoAug consistently\nand significantly outperforms GNN baselines and other graph augmentation\nmethods, across a variety of application contexts, which clearly indicates that\nit can effectively incorporate higher-order node relations into the graph\naugmentation for real-world complex networks.",
          "arxiv_id": "2402.13033v2"
        },
        {
          "title": "GAIN: Graph Attention & Interaction Network for Inductive Semi-Supervised Learning over Large-scale Graphs",
          "year": "2020-11",
          "abstract": "Graph Neural Networks (GNNs) have led to state-of-the-art performance on a\nvariety of machine learning tasks such as recommendation, node classification\nand link prediction. Graph neural network models generate node embeddings by\nmerging nodes features with the aggregated neighboring nodes information. Most\nexisting GNN models exploit a single type of aggregator (e.g., mean-pooling) to\naggregate neighboring nodes information, and then add or concatenate the output\nof aggregator to the current representation vector of the center node. However,\nusing only a single type of aggregator is difficult to capture the different\naspects of neighboring information and the simple addition or concatenation\nupdate methods limit the expressive capability of GNNs. Not only that, existing\nsupervised or semi-supervised GNN models are trained based on the loss function\nof the node label, which leads to the neglect of graph structure information.\nIn this paper, we propose a novel graph neural network architecture, Graph\nAttention \\& Interaction Network (GAIN), for inductive learning on graphs.\nUnlike the previous GNN models that only utilize a single type of aggregation\nmethod, we use multiple types of aggregators to gather neighboring information\nin different aspects and integrate the outputs of these aggregators through the\naggregator-level attention mechanism. Furthermore, we design a graph\nregularized loss to better capture the topological relationship of the nodes in\nthe graph. Additionally, we first present the concept of graph feature\ninteraction and propose a vector-wise explicit feature interaction mechanism to\nupdate the node embeddings. We conduct comprehensive experiments on two\nnode-classification benchmarks and a real-world financial news dataset. The\nexperiments demonstrate our GAIN model outperforms current state-of-the-art\nperformances on all the tasks.",
          "arxiv_id": "2011.01393v1"
        },
        {
          "title": "Transition Propagation Graph Neural Networks for Temporal Networks",
          "year": "2023-04",
          "abstract": "Researchers of temporal networks (e.g., social networks and transaction\nnetworks) have been interested in mining dynamic patterns of nodes from their\ndiverse interactions.\n  Inspired by recently powerful graph mining methods like skip-gram models and\nGraph Neural Networks (GNNs), existing approaches focus on generating temporal\nnode embeddings sequentially with nodes' sequential interactions.\n  However, the sequential modeling of previous approaches cannot handle the\ntransition structure between nodes' neighbors with limited memorization\ncapacity.\n  Detailedly, an effective method for the transition structures is required to\nboth model nodes' personalized patterns adaptively and capture node dynamics\naccordingly.\n  In this paper, we propose a method, namely Transition Propagation Graph\nNeural Networks (TIP-GNN), to tackle the challenges of encoding nodes'\ntransition structures.\n  The proposed TIP-GNN focuses on the bilevel graph structure in temporal\nnetworks: besides the explicit interaction graph, a node's sequential\ninteractions can also be constructed as a transition graph.\n  Based on the bilevel graph, TIP-GNN further encodes transition structures by\nmulti-step transition propagation and distills information from neighborhoods\nby a bilevel graph convolution.\n  Experimental results over various temporal networks reveal the efficiency of\nour TIP-GNN, with at most 7.2\\% improvements of accuracy on temporal link\nprediction.\n  Extensive ablation studies further verify the effectiveness and limitations\nof the transition propagation module.\n  Our code is available at \\url{https://github.com/doujiang-zheng/TIP-GNN}.",
          "arxiv_id": "2304.07501v1"
        }
      ],
      "13": [
        {
          "title": "SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval",
          "year": "2023-04",
          "abstract": "Legal case retrieval, which aims to find relevant cases for a query case,\nplays a core role in the intelligent legal system. Despite the success that\npre-training has achieved in ad-hoc retrieval tasks, effective pre-training\nstrategies for legal case retrieval remain to be explored. Compared with\ngeneral documents, legal case documents are typically long text sequences with\nintrinsic logical structures. However, most existing language models have\ndifficulty understanding the long-distance dependencies between different\nstructures. Moreover, in contrast to the general retrieval, the relevance in\nthe legal domain is sensitive to key legal elements. Even subtle differences in\nkey legal elements can significantly affect the judgement of relevance.\nHowever, existing pre-trained language models designed for general purposes\nhave not been equipped to handle legal elements.\n  To address these issues, in this paper, we propose SAILER, a new\nStructure-Aware pre-traIned language model for LEgal case Retrieval. It is\nhighlighted in the following three aspects: (1) SAILER fully utilizes the\nstructural information contained in legal case documents and pays more\nattention to key legal elements, similar to how legal experts browse legal case\ndocuments. (2) SAILER employs an asymmetric encoder-decoder architecture to\nintegrate several different pre-training objectives. In this way, rich semantic\ninformation across tasks is encoded into dense vectors. (3) SAILER has powerful\ndiscriminative ability, even without any legal annotation data. It can\ndistinguish legal cases with different charges accurately. Extensive\nexperiments over publicly available legal benchmarks demonstrate that our\napproach can significantly outperform previous state-of-the-art methods in\nlegal case retrieval.",
          "arxiv_id": "2304.11370v1"
        },
        {
          "title": "Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation",
          "year": "2024-06",
          "abstract": "Legal case retrieval for sourcing similar cases is critical in upholding\njudicial fairness. Different from general web search, legal case retrieval\ninvolves processing lengthy, complex, and highly specialized legal documents.\nExisting methods in this domain often overlook the incorporation of legal\nexpert knowledge, which is crucial for accurately understanding and modeling\nlegal cases, leading to unsatisfactory retrieval performance. This paper\nintroduces KELLER, a legal knowledge-guided case reformulation approach based\non large language models (LLMs) for effective and interpretable legal case\nretrieval. By incorporating professional legal knowledge about crimes and law\narticles, we enable large language models to accurately reformulate the\noriginal legal case into concise sub-facts of crimes, which contain the\nessential information of the case. Extensive experiments on two legal case\nretrieval benchmarks demonstrate superior retrieval performance and robustness\non complex legal case queries of KELLER over existing methods.",
          "arxiv_id": "2406.19760v1"
        },
        {
          "title": "Prompt-based Effective Input Reformulation for Legal Case Retrieval",
          "year": "2023-09",
          "abstract": "Legal case retrieval plays an important role for legal practitioners to\neffectively retrieve relevant cases given a query case. Most existing neural\nlegal case retrieval models directly encode the whole legal text of a case to\ngenerate a case representation, which is then utilised to conduct a nearest\nneighbour search for retrieval. Although these straightforward methods have\nachieved improvement over conventional statistical methods in retrieval\naccuracy, two significant challenges are identified in this paper: (1) Legal\nfeature alignment: the usage of the whole case text as the input will generally\nincorporate redundant and noisy information because, from the legal\nperspective, the determining factor of relevant cases is the alignment of key\nlegal features instead of whole text matching; (2) Legal context preservation:\nfurthermore, since the existing text encoding models usually have an input\nlength limit shorter than the case, the whole case text needs to be truncated\nor divided into paragraphs, which leads to the loss of the global context of\nlegal information. In this paper, a novel legal case retrieval framework,\nPromptCase, is proposed to tackle these challenges. Firstly, legal facts and\nlegal issues are identified and formally defined as the key features\nfacilitating legal case retrieval based on a thorough study of the definition\nof relevant cases from a legal perspective. Secondly, with the determining\nlegal features, a prompt-based encoding scheme is designed to conduct an\neffective encoding with language models. Extensive zero-shot experiments have\nbeen conducted on two benchmark datasets in legal case retrieval, which\ndemonstrate the superior retrieval effectiveness of the proposed PromptCase.\nThe code has been released on https://github.com/yanran-tang/PromptCase.",
          "arxiv_id": "2309.02962v1"
        }
      ],
      "14": [
        {
          "title": "Recommending Multiple Positive Citations for Manuscript via Content-Dependent Modeling and Multi-Positive Triplet",
          "year": "2021-11",
          "abstract": "Considering the rapidly increasing number of academic papers, searching for\nand citing appropriate references has become a non-trial task during the wiring\nof papers. Recommending a handful of candidate papers to a manuscript before\npublication could ease the burden of the authors, and help the reviewers to\ncheck the completeness of the cited resources. Conventional approaches on\ncitation recommendation generally consider recommending one ground-truth\ncitation for a query context from an input manuscript, but lack of\nconsideration on co-citation recommendations. However, a piece of context often\nneeds to be supported by two or more co-citation pairs. Here, we propose a\nnovel scientific paper modeling for citation recommendations, namely\nMulti-Positive BERT Model for Citation Recommendation (MP-BERT4CR), complied\nwith a series of Multi-Positive Triplet objectives to recommend multiple\npositive citations for a query context. The proposed approach has the following\nadvantages: First, the proposed multi-positive objectives are effective to\nrecommend multiple positive candidates. Second, we adopt noise distributions\nwhich are built based on the historical co-citation frequencies, so that\nMP-BERT4CR is not only effective on recommending high-frequent co-citation\npairs; but also the performances on retrieving the low-frequent ones are\nsignificantly improved. Third, we propose a dynamic context sampling strategy\nwhich captures the ``macro-scoped'' citing intents from a manuscript and\nempowers the citation embeddings to be content-dependent, which allow the\nalgorithm to further improve the performances. Single and multiple positive\nrecommendation experiments testified that MP-BERT4CR delivered significant\nimprovements. In addition, MP-BERT4CR are also effective in retrieving the full\nlist of co-citations, and historically low-frequent co-citation pairs compared\nwith the prior works.",
          "arxiv_id": "2111.12899v1"
        },
        {
          "title": "Benchmark for Evaluation and Analysis of Citation Recommendation Models",
          "year": "2024-12",
          "abstract": "Citation recommendation systems have attracted much academic interest,\nresulting in many studies and implementations. These systems help authors\nautomatically generate proper citations by suggesting relevant references based\non the text they have written. However, the methods used in citation\nrecommendation differ across various studies and implementations. Some\napproaches focus on the overall content of papers, while others consider the\ncontext of the citation text. Additionally, the datasets used in these studies\ninclude different aspects of papers, such as metadata, citation context, or\neven the full text of the paper in various formats and structures. The\ndiversity in models, datasets, and evaluation metrics makes it challenging to\nassess and compare citation recommendation methods effectively. To address this\nissue, a standardized dataset and evaluation metrics are needed to evaluate\nthese models consistently. Therefore, we propose developing a benchmark\nspecifically designed to analyze and compare citation recommendation models.\nThis benchmark will evaluate the performance of models on different features of\nthe citation context and provide a comprehensive evaluation of the models\nacross all these tasks, presenting the results in a standardized way. By\ncreating a benchmark with standardized evaluation metrics, researchers and\npractitioners in the field of citation recommendation will have a common\nplatform to assess and compare different models. This will enable meaningful\ncomparisons and help identify promising approaches for further research and\ndevelopment in the field.",
          "arxiv_id": "2412.07713v1"
        },
        {
          "title": "Citation Recommendation: Approaches and Datasets",
          "year": "2020-02",
          "abstract": "Citation recommendation describes the task of recommending citations for a\ngiven text. Due to the overload of published scientific works in recent years\non the one hand, and the need to cite the most appropriate publications when\nwriting scientific texts on the other hand, citation recommendation has emerged\nas an important research topic. In recent years, several approaches and\nevaluation data sets have been presented. However, to the best of our\nknowledge, no literature survey has been conducted explicitly on citation\nrecommendation. In this article, we give a thorough introduction into automatic\ncitation recommendation research. We then present an overview of the approaches\nand data sets for citation recommendation and identify differences and\ncommonalities using various dimensions. Last but not least, we shed light on\nthe evaluation methods, and outline general challenges in the evaluation and\nhow to meet them. We restrict ourselves to citation recommendation for\nscientific publications, as this document type has been studied the most in\nthis area. However, many of the observations and discussions included in this\nsurvey are also applicable to other types of text, such as news articles and\nencyclopedic articles.",
          "arxiv_id": "2002.06961v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-23T02:51:11Z",
    "dataVersion": "0.0.1",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}