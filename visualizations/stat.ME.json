{
  "topics": {
    "data": {
      "0": {
        "name": "0_data_model_models_method",
        "keywords": [
          [
            "data",
            0.04121035128541296
          ],
          [
            "model",
            0.03201231740798116
          ],
          [
            "models",
            0.023802243293653314
          ],
          [
            "method",
            0.022254349188252663
          ],
          [
            "methods",
            0.021493522203156944
          ],
          [
            "approach",
            0.018190753027366065
          ],
          [
            "time",
            0.017431800747194373
          ],
          [
            "estimation",
            0.016720073242702957
          ],
          [
            "analysis",
            0.016462988628653027
          ],
          [
            "Bayesian",
            0.014928793183914232
          ]
        ],
        "count": 19043
      },
      "1": {
        "name": "1_privacy_data_private_differential privacy",
        "keywords": [
          [
            "privacy",
            0.08526204317084957
          ],
          [
            "data",
            0.05533768201573299
          ],
          [
            "private",
            0.03850266699994205
          ],
          [
            "differential privacy",
            0.028510286580781613
          ],
          [
            "differential",
            0.023494273349235116
          ],
          [
            "DP",
            0.020287959207940236
          ],
          [
            "federated",
            0.017517694586742624
          ],
          [
            "statistical",
            0.016687567040487766
          ],
          [
            "Privacy",
            0.01397569849465792
          ],
          [
            "synthetic",
            0.013272478857729435
          ]
        ],
        "count": 231
      }
    },
    "correlations": [
      [
        1.0,
        -0.20955035069439537
      ],
      [
        -0.20955035069439537,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        134,
        15
      ],
      "2020-02": [
        175,
        43
      ],
      "2020-03": [
        176,
        24
      ],
      "2020-04": [
        204,
        25
      ],
      "2020-05": [
        214,
        37
      ],
      "2020-06": [
        245,
        44
      ],
      "2020-07": [
        249,
        37
      ],
      "2020-08": [
        197,
        29
      ],
      "2020-09": [
        172,
        34
      ],
      "2020-10": [
        220,
        34
      ],
      "2020-11": [
        222,
        39
      ],
      "2020-12": [
        220,
        28
      ],
      "2021-01": [
        179,
        30
      ],
      "2021-02": [
        191,
        37
      ],
      "2021-03": [
        241,
        33
      ],
      "2021-04": [
        208,
        40
      ],
      "2021-05": [
        218,
        41
      ],
      "2021-06": [
        247,
        48
      ],
      "2021-07": [
        222,
        42
      ],
      "2021-08": [
        177,
        24
      ],
      "2021-09": [
        195,
        46
      ],
      "2021-10": [
        237,
        52
      ],
      "2021-11": [
        204,
        34
      ],
      "2021-12": [
        218,
        42
      ],
      "2022-01": [
        186,
        36
      ],
      "2022-02": [
        224,
        34
      ],
      "2022-03": [
        247,
        48
      ],
      "2022-04": [
        173,
        35
      ],
      "2022-05": [
        202,
        60
      ],
      "2022-06": [
        272,
        54
      ],
      "2022-07": [
        211,
        44
      ],
      "2022-08": [
        239,
        47
      ],
      "2022-09": [
        237,
        37
      ],
      "2022-10": [
        255,
        56
      ],
      "2022-11": [
        234,
        55
      ],
      "2022-12": [
        205,
        44
      ],
      "2023-01": [
        209,
        49
      ],
      "2023-02": [
        231,
        56
      ],
      "2023-03": [
        228,
        44
      ],
      "2023-04": [
        216,
        28
      ],
      "2023-05": [
        272,
        41
      ],
      "2023-06": [
        305,
        53
      ],
      "2023-07": [
        226,
        40
      ],
      "2023-08": [
        190,
        39
      ],
      "2023-09": [
        255,
        40
      ],
      "2023-10": [
        259,
        65
      ],
      "2023-11": [
        259,
        55
      ],
      "2023-12": [
        265,
        50
      ],
      "2024-01": [
        284,
        58
      ],
      "2024-02": [
        281,
        46
      ],
      "2024-03": [
        264,
        49
      ],
      "2024-04": [
        247,
        47
      ],
      "2024-05": [
        285,
        57
      ],
      "2024-06": [
        276,
        58
      ],
      "2024-07": [
        280,
        39
      ],
      "2024-08": [
        213,
        42
      ],
      "2024-09": [
        244,
        54
      ],
      "2024-10": [
        350,
        69
      ],
      "2024-11": [
        276,
        36
      ],
      "2024-12": [
        251,
        45
      ],
      "2025-01": [
        257,
        45
      ],
      "2025-02": [
        288,
        58
      ],
      "2025-03": [
        277,
        62
      ],
      "2025-04": [
        292,
        45
      ],
      "2025-05": [
        321,
        61
      ],
      "2025-06": [
        310,
        64
      ],
      "2025-07": [
        321,
        78
      ],
      "2025-08": [
        262,
        55
      ],
      "2025-09": [
        181,
        21
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Random forests for binary geospatial data",
          "year": "2023-02",
          "abstract": "The manuscript develops new method and theory for non-linear regression for\nbinary dependent data using random forests. Existing implementations of random\nforests for binary data cannot explicitly account for data correlation common\nin geospatial and time-series settings. For continuous outcomes, recent work\nhas extended random forests (RF) to RF-GLS that incorporate spatial covariance\nusing the generalized least squares (GLS) loss. However, adoption of this idea\nfor binary data is challenging due to the use of the Gini impurity measure in\nclassification trees, which has no known extension to model dependence. We show\nthat for binary data, the GLS loss is also an extension of the Gini impurity\nmeasure, as the latter is exactly equivalent to the ordinary least squares\n(OLS) loss. This justifies using RF-GLS for non-parametric mean function\nestimation for binary dependent data. We then consider the special case of\ngeneralized mixed effects models, the traditional statistical model for binary\ngeospatial data, which models the spatial random effects as a Gaussian process\n(GP). We propose a novel link-inversion technique that embeds the RF-GLS\nestimate of the mean function from the first step within the generalized mixed\neffects model framework, enabling estimation of non-linear covariate effects\nand offering spatial predictions. We establish consistency of our method,\nRF-GP, for both mean function and covariate effect estimation. The theory holds\nfor a general class of stationary absolutely regular dependent processes that\nincludes common choices like Gaussian processes with Mat\\'ern or compactly\nsupported covariances and autoregressive processes. The theory relaxes the\ncommon assumption of additive mean functions and accounts for the non-linear\nlink. We demonstrate that RF-GP outperforms competing methods for estimation\nand prediction in both simulated and real-world data.",
          "arxiv_id": "2302.13828v2"
        },
        {
          "title": "Incorporating Subsampling into Bayesian Models for High-Dimensional Spatial Data",
          "year": "2023-05",
          "abstract": "Additive spatial statistical models with weakly stationary process\nassumptions have become standard in spatial statistics. However, one\ndisadvantage of such models is the computation time, which rapidly increases\nwith the number of data points. The goal of this article is to apply an\nexisting subsampling strategy to standard spatial additive models and to derive\nthe spatial statistical properties. We call this strategy the ''spatial data\nsubset model'' (SDSM) approach, which can be applied to big datasets in a\ncomputationally feasible way. Our approach has the advantage that one does not\nrequire any additional restrictive model assumptions. That is, computational\ngains increase as model assumptions are removed when using our model framework.\nThis provides one solution to the computational bottlenecks that occur when\napplying methods such as Kriging to ''big data''. We provide several properties\nof this new spatial data subset model approach in terms of moments, sill,\nnugget, and range under several sampling designs. An advantage of our approach\nis that it subsamples without throwing away data, and can be implemented using\ndatasets of any size that can be stored. We present the results of the spatial\ndata subset model approach on simulated datasets, and on a large dataset\nconsists of 150,000 observations of daytime land surface temperatures measured\nby the MODIS instrument onboard the Terra satellite.",
          "arxiv_id": "2305.13221v3"
        },
        {
          "title": "Goodness of Fit for Bayesian Generative Models with Applications in Population Genetics",
          "year": "2025-01",
          "abstract": "In population genetics and other application fields, models with intractable\nlikelihood are common. Approximate Bayesian Computation (ABC) or more generally\nSimulation-Based Inference (SBI) methods work by simulating instrumental data\nsets from the models under study and comparing them with the observed data set,\nusing advanced machine learning tools for tasks such as model selection and\nparameter inference. The present work focuses on model criticism, and more\nspecifically on Goodness of fit (GoF) tests, for intractable likelihood models.\nWe introduce two new GoF tests: the pre-inference \\gof tests whether the\nobserved dataset is distributed from the prior predictive distribution, while\nthe post-inference GoF tests whether there is a parameter value such that the\nobserved dataset is distributed from the likelihood with that value. The\npre-inference test can be used to prune a large set of models using a limited\namount of simulations, while the post-inference test is used to assess the fit\nof a selected model. Both tests are based on the Local Outlier Factor (LOF,\nBreunig et al., 2000). This indicator was initially defined for outlier and\nnovelty detection. It is able to quantify local density deviations, capturing\nsubtleties that a more traditional k-NN-based approach may miss. We evaluated\nthe performance of our two GoF tests on simulated datasets from three different\nmodel settings of varying complexity. We then illustrate the utility of these\napproaches on a dataset of single nucleotide polymorphism (SNP) markers for the\nevaluation of complex evolutionary scenarios of modern human populations. Our\ndual-test GoF approach highlights the flexibility of our method: the\npre-inference \\gof test provides insight into model validity from a Bayesian\nperspective, while the post-inference test provides a more general and\ntraditional view of assessing goodness of fit",
          "arxiv_id": "2501.17107v1"
        }
      ],
      "1": [
        {
          "title": "Optimal estimation in private distributed functional data analysis",
          "year": "2024-12",
          "abstract": "We systematically investigate the preservation of differential privacy in\nfunctional data analysis, beginning with functional mean estimation and\nextending to varying coefficient model estimation. Our work introduces a\ndistributed learning framework involving multiple servers, each responsible for\ncollecting several sparsely observed functions. This hierarchical setup\nintroduces a mixed notion of privacy. Within each function, user-level\ndifferential privacy is applied to $m$ discrete observations. At the server\nlevel, central differential privacy is deployed to account for the centralised\nnature of data collection. Across servers, only private information is\nexchanged, adhering to federated differential privacy constraints. To address\nthis complex hierarchy, we employ minimax theory to reveal several fundamental\nphenomena: from sparse to dense functional data analysis, from user-level to\ncentral and federated differential privacy costs, and the intricate interplay\nbetween different regimes of functional data analysis and privacy preservation.\n  To the best of our knowledge, this is the first study to rigorously examine\nfunctional data estimation under multiple privacy constraints. Our theoretical\nfindings are complemented by efficient private algorithms and extensive\nnumerical evidence, providing a comprehensive exploration of this challenging\nproblem.",
          "arxiv_id": "2412.06582v1"
        },
        {
          "title": "Identification and Formal Privacy Guarantees",
          "year": "2020-06",
          "abstract": "Empirical economic research crucially relies on highly sensitive individual\ndatasets. At the same time, increasing availability of public individual-level\ndata makes it possible for adversaries to potentially de-identify anonymized\nrecords in sensitive research datasets. Most commonly accepted formal\ndefinition of an individual non-disclosure guarantee is referred to as\ndifferential privacy. It restricts the interaction of researchers with the data\nby allowing them to issue queries to the data. The differential privacy\nmechanism then replaces the actual outcome of the query with a randomised\noutcome.\n  The impact of differential privacy on the identification of empirical\neconomic models and on the performance of estimators in nonlinear empirical\nEconometric models has not been sufficiently studied. Since privacy protection\nmechanisms are inherently finite-sample procedures, we define the notion of\nidentifiability of the parameter of interest under differential privacy as a\nproperty of the limit of experiments. It is naturally characterized by the\nconcepts from the random sets theory.\n  We show that particular instances of regression discontinuity design may be\nproblematic for inference with differential privacy as parameters turn out to\nbe neither point nor partially identified. The set of differentially private\nestimators converges weakly to a random set. Our analysis suggests that many\nother estimators that rely on nuisance parameters may have similar properties\nwith the requirement of differential privacy. We show that identification\nbecomes possible if the target parameter can be deterministically located\nwithin the random set. In that case, a full exploration of the random set of\nthe weak limits of differentially private estimators can allow the data curator\nto select a sequence of instances of differentially private estimators\nconverging to the target parameter in probability.",
          "arxiv_id": "2006.14732v2"
        },
        {
          "title": "Federated Transfer Learning with Differential Privacy",
          "year": "2024-03",
          "abstract": "Federated learning has emerged as a powerful framework for analysing\ndistributed data, yet two challenges remain pivotal: heterogeneity across sites\nand privacy of local data. In this paper, we address both challenges within a\nfederated transfer learning framework, aiming to enhance learning on a target\ndata set by leveraging information from multiple heterogeneous source data sets\nwhile adhering to privacy constraints. We rigorously formulate the notion of\nfederated differential privacy, which offers privacy guarantees for each data\nset without assuming a trusted central server. Under this privacy model, we\nstudy three classical statistical problems: univariate mean estimation,\nlow-dimensional linear regression, and high-dimensional linear regression. By\ninvestigating the minimax rates and quantifying the cost of privacy in each\nproblem, we show that federated differential privacy is an intermediate privacy\nmodel between the well-established local and central models of differential\nprivacy. Our analyses account for data heterogeneity and privacy, highlighting\nthe fundamental costs associated with each factor and the benefits of knowledge\ntransfer in federated learning.",
          "arxiv_id": "2403.11343v3"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T22:46:46Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}