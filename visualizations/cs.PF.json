{
  "topics": {
    "data": {
      "0": {
        "name": "0_performance_HPC_GPU_applications",
        "keywords": [
          [
            "performance",
            0.03124451865952752
          ],
          [
            "HPC",
            0.019639292876186515
          ],
          [
            "GPU",
            0.01877865321783699
          ],
          [
            "applications",
            0.01682414899569944
          ],
          [
            "GPUs",
            0.015794478762242537
          ],
          [
            "data",
            0.015723665045021852
          ],
          [
            "code",
            0.015096547238243161
          ],
          [
            "matrix",
            0.013731203026331917
          ],
          [
            "MPI",
            0.012902104601958618
          ],
          [
            "memory",
            0.012826403090155855
          ]
        ],
        "count": 350
      },
      "1": {
        "name": "1_job_jobs_time_service",
        "keywords": [
          [
            "job",
            0.03272605809516657
          ],
          [
            "jobs",
            0.03155618350791135
          ],
          [
            "time",
            0.029038436184609176
          ],
          [
            "service",
            0.025615232022462426
          ],
          [
            "policy",
            0.02480889100681542
          ],
          [
            "servers",
            0.022501243931618627
          ],
          [
            "queue",
            0.02208256898114666
          ],
          [
            "server",
            0.020605413407788927
          ],
          [
            "policies",
            0.01999849098900466
          ],
          [
            "systems",
            0.01851088133973147
          ]
        ],
        "count": 259
      },
      "2": {
        "name": "2_neural_training_DNN_accuracy",
        "keywords": [
          [
            "neural",
            0.01868881942647036
          ],
          [
            "training",
            0.018455506680816178
          ],
          [
            "DNN",
            0.01844884687262684
          ],
          [
            "accuracy",
            0.01824090595226369
          ],
          [
            "models",
            0.018028437659689495
          ],
          [
            "inference",
            0.0179963036158265
          ],
          [
            "learning",
            0.017061716287136947
          ],
          [
            "deep",
            0.016811111120568125
          ],
          [
            "performance",
            0.015176877708513968
          ],
          [
            "model",
            0.014298509772283752
          ]
        ],
        "count": 224
      },
      "3": {
        "name": "3_network_networks_performance_communication",
        "keywords": [
          [
            "network",
            0.035243366967279165
          ],
          [
            "networks",
            0.020150085258451706
          ],
          [
            "performance",
            0.018846178057951656
          ],
          [
            "communication",
            0.01864731651590774
          ],
          [
            "paper",
            0.016398540826685015
          ],
          [
            "traffic",
            0.01587830863111608
          ],
          [
            "results",
            0.014419444154234521
          ],
          [
            "wireless",
            0.014199400964353199
          ],
          [
            "analysis",
            0.011139894751128443
          ],
          [
            "rate",
            0.010983341605995416
          ]
        ],
        "count": 196
      },
      "4": {
        "name": "4_LLM_LLMs_inference_models",
        "keywords": [
          [
            "LLM",
            0.03022177189970414
          ],
          [
            "LLMs",
            0.02928388491673265
          ],
          [
            "inference",
            0.026852063711227378
          ],
          [
            "models",
            0.025686600221462078
          ],
          [
            "Language",
            0.019957114441532513
          ],
          [
            "memory",
            0.019085917487130077
          ],
          [
            "model",
            0.017616628664331658
          ],
          [
            "language",
            0.017533410039526777
          ],
          [
            "Large",
            0.017425962432533342
          ],
          [
            "GPU",
            0.016787277545063643
          ]
        ],
        "count": 162
      },
      "5": {
        "name": "5_performance_code_compiler_hardware",
        "keywords": [
          [
            "performance",
            0.027091829210306045
          ],
          [
            "code",
            0.026452009481915447
          ],
          [
            "compiler",
            0.021079206060713913
          ],
          [
            "hardware",
            0.015106318418144318
          ],
          [
            "level",
            0.014760202074224562
          ],
          [
            "optimization",
            0.014543168107677694
          ],
          [
            "LLVM",
            0.013106664031264512
          ],
          [
            "model",
            0.012873300045268413
          ],
          [
            "memory",
            0.012803783604932159
          ],
          [
            "program",
            0.012719326326917515
          ]
        ],
        "count": 119
      },
      "6": {
        "name": "6_cloud_performance_serverless_resource",
        "keywords": [
          [
            "cloud",
            0.03189716611849041
          ],
          [
            "performance",
            0.02442565552791991
          ],
          [
            "serverless",
            0.022192118785492352
          ],
          [
            "resource",
            0.021439001937612966
          ],
          [
            "microservices",
            0.01727862722158032
          ],
          [
            "FaaS",
            0.01644057445435605
          ],
          [
            "Cloud",
            0.016438421302983012
          ],
          [
            "Serverless",
            0.01626166724909539
          ],
          [
            "service",
            0.01623197723789699
          ],
          [
            "workloads",
            0.01616094080805742
          ]
        ],
        "count": 99
      },
      "7": {
        "name": "7_graph_graphs_data_processing",
        "keywords": [
          [
            "graph",
            0.056378338457186206
          ],
          [
            "graphs",
            0.023742562137295798
          ],
          [
            "data",
            0.02260367424746583
          ],
          [
            "processing",
            0.020845715531402336
          ],
          [
            "algorithms",
            0.020249939155518915
          ],
          [
            "Graph",
            0.01955118412786077
          ],
          [
            "performance",
            0.018732979331529623
          ],
          [
            "vertices",
            0.01691637258303004
          ],
          [
            "queries",
            0.015037846003905096
          ],
          [
            "datasets",
            0.01432275911485259
          ]
        ],
        "count": 84
      },
      "8": {
        "name": "8_memory_data_CXL_cache",
        "keywords": [
          [
            "memory",
            0.061584042028707854
          ],
          [
            "data",
            0.02870470830955602
          ],
          [
            "CXL",
            0.028525179303448958
          ],
          [
            "cache",
            0.02604558141767369
          ],
          [
            "storage",
            0.026038067316519992
          ],
          [
            "performance",
            0.02124572840531167
          ],
          [
            "SSD",
            0.019069999014072348
          ],
          [
            "systems",
            0.018114954282416492
          ],
          [
            "pages",
            0.017267123228485153
          ],
          [
            "Memory",
            0.016524372642078955
          ]
        ],
        "count": 80
      },
      "9": {
        "name": "9_algorithms_performance_AI_learning",
        "keywords": [
          [
            "algorithms",
            0.025166493908539082
          ],
          [
            "performance",
            0.021173199036068648
          ],
          [
            "AI",
            0.0191832563044325
          ],
          [
            "learning",
            0.01769842756018981
          ],
          [
            "data",
            0.015450435393403548
          ],
          [
            "model",
            0.015220378314278502
          ],
          [
            "evaluation",
            0.015166375824268542
          ],
          [
            "models",
            0.013865053237476197
          ],
          [
            "methods",
            0.013628747639213354
          ],
          [
            "scores",
            0.013092320037156085
          ]
        ],
        "count": 75
      },
      "10": {
        "name": "10_blockchain_consensus_Blockchain_transaction",
        "keywords": [
          [
            "blockchain",
            0.07869533105019588
          ],
          [
            "consensus",
            0.03692903547609911
          ],
          [
            "Blockchain",
            0.031079015102792786
          ],
          [
            "transaction",
            0.029728129639303387
          ],
          [
            "Fabric",
            0.028514041444149468
          ],
          [
            "Hyperledger",
            0.027794600978270308
          ],
          [
            "blockchains",
            0.025681377698581098
          ],
          [
            "transactions",
            0.025268910193407875
          ],
          [
            "performance",
            0.023386303764806313
          ],
          [
            "systems",
            0.021523426629382555
          ]
        ],
        "count": 56
      }
    },
    "correlations": [
      [
        1.0,
        -0.6995636635957942,
        -0.6878697815573672,
        -0.6477192546208471,
        -0.7057869025303904,
        -0.2600795619970466,
        -0.3639442491465572,
        -0.7152472204823676,
        -0.6344484968976977,
        -0.3662842616990908,
        -0.7490861744195807
      ],
      [
        -0.6995636635957942,
        1.0,
        -0.7159444705703744,
        -0.5986129642160078,
        -0.7069252596625444,
        -0.6963133756937048,
        -0.6738102426900374,
        -0.7085888371855276,
        -0.6742810323071035,
        -0.6863726710264192,
        -0.7460662346132886
      ],
      [
        -0.6878697815573672,
        -0.7159444705703744,
        1.0,
        -0.6729976642897176,
        -0.6754382206584268,
        -0.6901078666983106,
        -0.7112593893393584,
        -0.7181425318764618,
        -0.6932617251723732,
        -0.684731924220823,
        -0.7548721230729858
      ],
      [
        -0.6477192546208471,
        -0.5986129642160078,
        -0.6729976642897176,
        1.0,
        -0.7075893908730492,
        -0.6605920108224442,
        -0.6547779685665822,
        -0.7150585638488529,
        -0.6478901599041957,
        -0.6414679354268268,
        -0.7310343157528516
      ],
      [
        -0.7057869025303904,
        -0.7069252596625444,
        -0.6754382206584268,
        -0.7075893908730492,
        1.0,
        -0.7027881761862357,
        -0.7234149297506332,
        -0.735770831701684,
        -0.6713725896421266,
        -0.7041944062385991,
        -0.7618355681876352
      ],
      [
        -0.2600795619970466,
        -0.6963133756937048,
        -0.6901078666983106,
        -0.6605920108224442,
        -0.7027881761862357,
        1.0,
        -0.29536705910685085,
        -0.7250100584207535,
        -0.6399793590614334,
        -0.3131437479107006,
        -0.7471977172461237
      ],
      [
        -0.3639442491465572,
        -0.6738102426900374,
        -0.7112593893393584,
        -0.6547779685665822,
        -0.7234149297506332,
        -0.29536705910685085,
        1.0,
        -0.7180020542350846,
        -0.6613808162560592,
        -0.3746304341819595,
        -0.7452759549148147
      ],
      [
        -0.7152472204823676,
        -0.7085888371855276,
        -0.7181425318764618,
        -0.7150585638488529,
        -0.735770831701684,
        -0.7250100584207535,
        -0.7180020542350846,
        1.0,
        -0.6816260140669573,
        -0.7039779548869451,
        -0.7607515822724842
      ],
      [
        -0.6344484968976977,
        -0.6742810323071035,
        -0.6932617251723732,
        -0.6478901599041957,
        -0.6713725896421266,
        -0.6399793590614334,
        -0.6613808162560592,
        -0.6816260140669573,
        1.0,
        -0.6560790181410172,
        -0.7583882331594739
      ],
      [
        -0.3662842616990908,
        -0.6863726710264192,
        -0.684731924220823,
        -0.6414679354268268,
        -0.7041944062385991,
        -0.3131437479107006,
        -0.3746304341819595,
        -0.7039779548869451,
        -0.6560790181410172,
        1.0,
        -0.7429553213683668
      ],
      [
        -0.7490861744195807,
        -0.7460662346132886,
        -0.7548721230729858,
        -0.7310343157528516,
        -0.7618355681876352,
        -0.7471977172461237,
        -0.7452759549148147,
        -0.7607515822724842,
        -0.7583882331594739,
        -0.7429553213683668,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        8,
        7,
        3,
        1,
        1,
        1,
        2,
        6,
        6,
        0,
        0
      ],
      "2020-02": [
        10,
        6,
        7,
        16,
        1,
        2,
        0,
        0,
        4,
        2,
        1
      ],
      "2020-03": [
        15,
        5,
        1,
        8,
        2,
        2,
        1,
        1,
        1,
        2,
        2
      ],
      "2020-04": [
        9,
        12,
        4,
        9,
        0,
        0,
        1,
        1,
        2,
        1,
        3
      ],
      "2020-05": [
        11,
        7,
        2,
        5,
        0,
        1,
        3,
        2,
        4,
        0,
        0
      ],
      "2020-06": [
        4,
        6,
        2,
        3,
        1,
        1,
        1,
        1,
        3,
        0,
        0
      ],
      "2020-07": [
        6,
        7,
        2,
        6,
        2,
        0,
        1,
        1,
        4,
        3,
        2
      ],
      "2020-08": [
        14,
        6,
        2,
        6,
        1,
        0,
        3,
        4,
        3,
        0,
        0
      ],
      "2020-09": [
        8,
        4,
        2,
        8,
        0,
        0,
        1,
        6,
        3,
        1,
        0
      ],
      "2020-10": [
        10,
        5,
        6,
        9,
        0,
        3,
        1,
        5,
        4,
        0,
        0
      ],
      "2020-11": [
        11,
        7,
        3,
        10,
        1,
        0,
        1,
        3,
        4,
        2,
        1
      ],
      "2020-12": [
        7,
        6,
        2,
        7,
        1,
        1,
        0,
        2,
        3,
        0,
        1
      ],
      "2021-01": [
        13,
        6,
        2,
        8,
        0,
        0,
        3,
        1,
        6,
        0,
        2
      ],
      "2021-02": [
        8,
        6,
        2,
        8,
        2,
        1,
        0,
        0,
        4,
        1,
        3
      ],
      "2021-03": [
        6,
        2,
        2,
        4,
        0,
        0,
        1,
        2,
        4,
        2,
        1
      ],
      "2021-04": [
        15,
        6,
        5,
        8,
        1,
        3,
        2,
        4,
        6,
        2,
        1
      ],
      "2021-05": [
        11,
        2,
        3,
        8,
        2,
        0,
        2,
        1,
        4,
        0,
        0
      ],
      "2021-06": [
        3,
        5,
        2,
        6,
        0,
        0,
        0,
        1,
        7,
        2,
        0
      ],
      "2021-07": [
        8,
        5,
        2,
        5,
        0,
        2,
        2,
        2,
        0,
        0,
        2
      ],
      "2021-08": [
        10,
        5,
        2,
        4,
        0,
        2,
        1,
        0,
        3,
        3,
        0
      ],
      "2021-09": [
        14,
        8,
        4,
        14,
        3,
        1,
        0,
        1,
        6,
        1,
        1
      ],
      "2021-10": [
        3,
        8,
        4,
        5,
        1,
        0,
        2,
        2,
        4,
        2,
        0
      ],
      "2021-11": [
        2,
        5,
        0,
        3,
        0,
        1,
        1,
        1,
        1,
        3,
        0
      ],
      "2021-12": [
        9,
        4,
        6,
        5,
        0,
        1,
        0,
        1,
        8,
        1,
        2
      ],
      "2022-01": [
        2,
        4,
        4,
        2,
        1,
        0,
        1,
        4,
        5,
        1,
        1
      ],
      "2022-02": [
        5,
        8,
        3,
        5,
        0,
        0,
        2,
        0,
        2,
        4,
        1
      ],
      "2022-03": [
        8,
        6,
        0,
        1,
        1,
        1,
        2,
        3,
        3,
        0,
        2
      ],
      "2022-04": [
        9,
        6,
        2,
        3,
        0,
        1,
        1,
        0,
        3,
        0,
        0
      ],
      "2022-05": [
        6,
        4,
        7,
        4,
        3,
        2,
        0,
        1,
        8,
        0,
        2
      ],
      "2022-06": [
        16,
        5,
        1,
        5,
        1,
        1,
        1,
        1,
        3,
        0,
        0
      ],
      "2022-07": [
        7,
        4,
        2,
        6,
        0,
        2,
        0,
        2,
        2,
        0,
        2
      ],
      "2022-08": [
        9,
        4,
        3,
        1,
        1,
        2,
        1,
        1,
        0,
        0,
        1
      ],
      "2022-09": [
        10,
        4,
        5,
        7,
        0,
        1,
        1,
        1,
        5,
        2,
        1
      ],
      "2022-10": [
        5,
        5,
        1,
        6,
        2,
        1,
        3,
        1,
        1,
        0,
        2
      ],
      "2022-11": [
        10,
        5,
        4,
        3,
        1,
        0,
        0,
        2,
        5,
        0,
        1
      ],
      "2022-12": [
        5,
        1,
        3,
        6,
        1,
        1,
        1,
        2,
        5,
        2,
        0
      ],
      "2023-01": [
        5,
        4,
        3,
        5,
        0,
        0,
        1,
        4,
        3,
        0,
        0
      ],
      "2023-02": [
        10,
        0,
        1,
        3,
        1,
        1,
        0,
        0,
        4,
        0,
        1
      ],
      "2023-03": [
        8,
        5,
        4,
        3,
        4,
        0,
        2,
        2,
        9,
        0,
        1
      ],
      "2023-04": [
        9,
        6,
        5,
        5,
        2,
        4,
        2,
        1,
        6,
        1,
        1
      ],
      "2023-05": [
        17,
        3,
        3,
        1,
        2,
        0,
        2,
        2,
        2,
        3,
        0
      ],
      "2023-06": [
        10,
        2,
        4,
        6,
        2,
        2,
        2,
        2,
        3,
        1,
        1
      ],
      "2023-07": [
        9,
        2,
        3,
        7,
        3,
        0,
        2,
        0,
        2,
        1,
        0
      ],
      "2023-08": [
        15,
        3,
        4,
        6,
        0,
        0,
        3,
        5,
        5,
        1,
        0
      ],
      "2023-09": [
        10,
        6,
        2,
        9,
        5,
        0,
        0,
        3,
        6,
        1,
        2
      ],
      "2023-10": [
        13,
        3,
        5,
        9,
        3,
        1,
        1,
        3,
        3,
        0,
        1
      ],
      "2023-11": [
        9,
        3,
        6,
        5,
        3,
        3,
        0,
        4,
        7,
        3,
        1
      ],
      "2023-12": [
        12,
        6,
        2,
        4,
        7,
        0,
        3,
        6,
        3,
        2,
        1
      ],
      "2024-01": [
        6,
        7,
        3,
        5,
        3,
        3,
        2,
        5,
        6,
        2,
        0
      ],
      "2024-02": [
        10,
        4,
        2,
        4,
        3,
        0,
        1,
        1,
        5,
        2,
        1
      ],
      "2024-03": [
        10,
        3,
        1,
        6,
        6,
        0,
        0,
        2,
        2,
        1,
        0
      ],
      "2024-04": [
        12,
        4,
        5,
        2,
        5,
        0,
        0,
        1,
        2,
        1,
        0
      ],
      "2024-05": [
        14,
        5,
        1,
        6,
        4,
        0,
        1,
        5,
        5,
        1,
        0
      ],
      "2024-06": [
        8,
        4,
        2,
        4,
        8,
        2,
        2,
        1,
        2,
        0,
        0
      ],
      "2024-07": [
        11,
        2,
        4,
        6,
        2,
        0,
        1,
        2,
        6,
        1,
        0
      ],
      "2024-08": [
        13,
        6,
        1,
        3,
        0,
        1,
        2,
        2,
        3,
        1,
        2
      ],
      "2024-09": [
        13,
        5,
        2,
        4,
        7,
        0,
        2,
        3,
        5,
        1,
        1
      ],
      "2024-10": [
        14,
        1,
        2,
        4,
        10,
        2,
        1,
        3,
        7,
        1,
        0
      ],
      "2024-11": [
        11,
        3,
        2,
        4,
        8,
        0,
        3,
        3,
        8,
        2,
        1
      ],
      "2024-12": [
        16,
        1,
        2,
        3,
        8,
        1,
        3,
        2,
        8,
        3,
        1
      ],
      "2025-01": [
        19,
        1,
        3,
        2,
        10,
        4,
        0,
        4,
        5,
        0,
        0
      ],
      "2025-02": [
        13,
        3,
        0,
        4,
        14,
        2,
        3,
        5,
        3,
        3,
        0
      ],
      "2025-03": [
        15,
        3,
        5,
        5,
        15,
        3,
        3,
        1,
        9,
        1,
        0
      ],
      "2025-04": [
        17,
        5,
        1,
        3,
        9,
        0,
        2,
        0,
        7,
        1,
        1
      ],
      "2025-05": [
        22,
        7,
        6,
        2,
        14,
        0,
        2,
        2,
        10,
        1,
        1
      ],
      "2025-06": [
        23,
        7,
        5,
        6,
        16,
        0,
        0,
        1,
        3,
        2,
        2
      ],
      "2025-07": [
        18,
        3,
        1,
        7,
        13,
        1,
        0,
        1,
        5,
        2,
        1
      ],
      "2025-08": [
        21,
        2,
        3,
        5,
        18,
        3,
        4,
        3,
        9,
        2,
        0
      ],
      "2025-09": [
        11,
        2,
        2,
        2,
        4,
        1,
        4,
        2,
        5,
        2,
        1
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Performance portable ice-sheet modeling with MALI",
          "year": "2022-04",
          "abstract": "High resolution simulations of polar ice-sheets play a crucial role in the\nongoing effort to develop more accurate and reliable Earth-system models for\nprobabilistic sea-level projections. These simulations often require a massive\namount of memory and computation from large supercomputing clusters to provide\nsufficient accuracy and resolution. The latest exascale machines poised to come\nonline contain a diverse set of computing architectures. In an effort to avoid\narchitecture specific programming and maintain productivity across platforms,\nthe ice-sheet modeling code known as MALI uses high level abstractions to\nintegrate Trilinos libraries and the Kokkos programming model for performance\nportable code across a variety of different architectures. In this paper, we\nanalyze the performance portable features of MALI via a performance analysis on\ncurrent CPU-based and GPU-based supercomputers. The analysis highlights\nperformance portable improvements made in finite element assembly and multigrid\npreconditioning within MALI with speedups between 1.26-1.82x across CPU and GPU\narchitectures but also identifies the need to further improve performance in\nsoftware coupling and preconditioning on GPUs. We also perform a weak\nscalability study and show that simulations on GPU-based machines perform\n1.24-1.92x faster when utilizing the GPUs. The best performance is found in\nfinite element assembly which achieved a speedup of up to 8.65x and a weak\nscaling efficiency of 82.9% with GPUs. We additionally describe an automated\nperformance testing framework developed for this code base using a changepoint\ndetection method. The framework is used to make actionable decisions about\nperformance within MALI. We provide several concrete examples of scenarios in\nwhich the framework has identified performance regressions, improvements, and\nalgorithm differences over the course of two years of development.",
          "arxiv_id": "2204.04321v1"
        },
        {
          "title": "A Study of Performance Portability in Plasma Physics Simulations",
          "year": "2024-10",
          "abstract": "The high-performance computing (HPC) community has recently seen a\nsubstantial diversification of hardware platforms and their associated\nprogramming models. From traditional multicore processors to highly specialized\naccelerators, vendors and tool developers back up the relentless progress of\nthose architectures. In the context of scientific programming, it is\nfundamental to consider performance portability frameworks, i.e., software\ntools that allow programmers to write code once and run it on different\ncomputer architectures without sacrificing performance. We report here on the\nbenefits and challenges of performance portability using a field-line tracing\nsimulation and a particle-in-cell code, two relevant applications in\ncomputational plasma physics with applications to magnetically-confined\nnuclear-fusion energy research. For these applications we report performance\nresults obtained on four HPC platforms with server-class CPUs from Intel (Xeon)\nand AMD (EPYC), and high-end GPUs from Nvidia and AMD, including the latest\nNvidia H100 GPU and the novel AMD Instinct MI300A APU. Our results show that\nboth Kokkos and OpenMP are powerful tools to achieve performance portability\nand decent \"out-of-the-box\" performance, even for the very latest hardware\nplatforms. For our applications, Kokkos provided performance portability to the\nbroadest range of hardware architectures from different vendors.",
          "arxiv_id": "2411.05009v1"
        },
        {
          "title": "GROMACS on AMD GPU-Based HPC Platforms: Using SYCL for Performance and Portability",
          "year": "2024-05",
          "abstract": "GROMACS is a widely-used molecular dynamics software package with a focus on\nperformance, portability, and maintainability across a broad range of\nplatforms. Thanks to its early algorithmic redesign and flexible heterogeneous\nparallelization, GROMACS has successfully harnessed GPU accelerators for more\nthan a decade. With the diversification of accelerator platforms in HPC and no\nobvious choice for a multi-vendor programming model, the GROMACS project found\nitself at a crossroads. The performance and portability requirements, and a\nstrong preference for a standards-based solution, motivated our choice to use\nSYCL on both new HPC GPU platforms: AMD and Intel. Since the GROMACS 2022\nrelease, the SYCL backend has been the primary means to target AMD GPUs in\npreparation for exascale HPC architectures like LUMI and Frontier. SYCL is a\ncross-platform, royalty-free, C++17-based standard for programming hardware\naccelerators. It allows using the same code to target GPUs from all three major\nvendors with minimal specialization. While SYCL implementations build on native\ntoolchains, performance of such an approach is not immediately evident.\nBiomolecular simulations have challenging performance characteristics: latency\nsensitivity, the need for strong scaling, and typical iteration times as short\nas hundreds of microseconds. Hence, obtaining good performance across the range\nof problem sizes and scaling regimes is particularly challenging. Here, we\nshare the results of our work on readying GROMACS for AMD GPU platforms using\nSYCL, and demonstrate performance on Cray EX235a machines with MI250X\naccelerators. Our findings illustrate that portability is possible without\nmajor performance compromises. We provide a detailed analysis of node-level\nkernel and runtime performance with the aim of sharing best practices with the\nHPC community on using SYCL as a performance-portable GPU framework.",
          "arxiv_id": "2405.01420v1"
        }
      ],
      "1": [
        {
          "title": "Zero Queueing for Multi-Server Jobs",
          "year": "2020-11",
          "abstract": "Cloud computing today is dominated by multi-server jobs. These are jobs that\nrequest multiple servers simultaneously and hold onto all of these servers for\nthe duration of the job. Multi-server jobs add a lot of complexity to the\ntraditional one-job-per-server model: an arrival might not \"fit\" into the\navailable servers and might have to queue, blocking later arrivals and leaving\nservers idle. From a queueing perspective, almost nothing is understood about\nmulti-server job queueing systems; even understanding the exact stability\nregion is a very hard problem.\n  In this paper, we investigate a multi-server job queueing model under scaling\nregimes where the number of servers in the system grows. Specifically, we\nconsider a system with multiple classes of jobs, where jobs from different\nclasses can request different numbers of servers and have different service\ntime distributions, and jobs are served in first-come-first-served order. The\nmulti-server job model opens up new scaling regimes where both the number of\nservers that a job needs and the system load scale with the total number of\nservers. Within these scaling regimes, we derive the first results on\nstability, queueing probability, and the transient analysis of the number of\njobs in the system for each class. In particular we derive sufficient\nconditions for zero queueing. Our analysis introduces a novel way of extracting\ninformation from the Lyapunov drift, which can be applicable to a broader scope\nof problems in queueing systems.",
          "arxiv_id": "2011.10521v2"
        },
        {
          "title": "Improving Multiresource Job Scheduling with Markovian Service Rate Policies",
          "year": "2025-04",
          "abstract": "Modern cloud computing workloads are composed of multiresource jobs that\nrequire a variety of computational resources in order to run, such as CPU\ncores, memory, disk space, or hardware accelerators. A single cloud server can\ntypically run many multiresource jobs in parallel, but only if the server has\nsufficient resources to satisfy the demands of every job. A scheduling policy\nmust therefore select sets of multiresource jobs to run in parallel in order to\nminimize the mean response time across jobs -- the average time from when a job\narrives to the system until it is completed. Unfortunately, achieving low\nresponse times by selecting sets of jobs that fully utilize the available\nserver resources has proven to be a difficult problem.\n  In this paper, we develop and analyze a new class of policies for scheduling\nmultiresource jobs, called Markovian Service Rate (MSR) policies. While prior\nscheduling policies for multiresource jobs are either highly complex to analyze\nor hard to implement, our MSR policies are simple to implement and are amenable\nto response time analysis. We show that the class of MSR policies is\nthroughput-optimal in that we can use an MSR policy to stabilize the system\nwhenever it is possible to do so. We also derive bounds on the mean response\ntime under an MSR algorithm that are tight up to an additive constant. These\nbounds can be applied to systems with different preemption behaviors, such as\nfully preemptive systems, non-preemptive systems, and systems that allow\npreemption with setup times. We show how our theoretical results can be used to\nselect a good MSR policy as a function of the system arrival rates, job service\nrequirements, the server's resource capacities, and the resource demands of the\njobs.",
          "arxiv_id": "2504.08094v3"
        },
        {
          "title": "Improving Multiresource Job Scheduling with Markovian Service Rate Policies",
          "year": "2025-04",
          "abstract": "Modern cloud computing workloads are composed of multiresource jobs that\nrequire a variety of computational resources in order to run, such as CPU\ncores, memory, disk space, or hardware accelerators. A single cloud server can\ntypically run many multiresource jobs in parallel, but only if the server has\nsufficient resources to satisfy the demands of every job. A scheduling policy\nmust therefore select sets of multiresource jobs to run in parallel in order to\nminimize the mean response time across jobs -- the average time from when a job\narrives to the system until it is completed. Unfortunately, achieving low\nresponse times by selecting sets of jobs that fully utilize the available\nserver resources has proven to be a difficult problem.\n  In this paper, we develop and analyze a new class of policies for scheduling\nmultiresource jobs, called Markovian Service Rate (MSR) policies. While prior\nscheduling policies for multiresource jobs are either highly complex to analyze\nor hard to implement, our MSR policies are simple to implement and are amenable\nto response time analysis. We show that the class of MSR policies is\nthroughput-optimal in that we can use an MSR policy to stabilize the system\nwhenever it is possible to do so. We also derive bounds on the mean response\ntime under an MSR algorithm that are tight up to an additive constant. These\nbounds can be applied to systems with different preemption behaviors, such as\nfully preemptive systems, non-preemptive systems, and systems that allow\npreemption with setup times. We show how our theoretical results can be used to\nselect a good MSR policy as a function of the system arrival rates, job service\nrequirements, the server's resource capacities, and the resource demands of the\njobs.",
          "arxiv_id": "2504.08094v3"
        }
      ],
      "2": [
        {
          "title": "DLAS: An Exploration and Assessment of the Deep Learning Acceleration Stack",
          "year": "2023-11",
          "abstract": "Deep Neural Networks (DNNs) are extremely computationally demanding, which\npresents a large barrier to their deployment on resource-constrained devices.\nSince such devices are where many emerging deep learning applications lie\n(e.g., drones, vision-based medical technology), significant bodies of work\nfrom both the machine learning and systems communities have attempted to\nprovide optimizations to accelerate DNNs. To help unify these two perspectives,\nin this paper we combine machine learning and systems techniques within the\nDeep Learning Acceleration Stack (DLAS), and demonstrate how these layers can\nbe tightly dependent on each other with an across-stack perturbation study. We\nevaluate the impact on accuracy and inference time when varying different\nparameters of DLAS across two datasets, seven popular DNN architectures, four\nDNN compression techniques, three algorithmic primitives with sparse and dense\nvariants, untuned and auto-scheduled code generation, and four hardware\nplatforms. Our evaluation highlights how perturbations across DLAS parameters\ncan cause significant variation and across-stack interactions. The highest\nlevel observation from our evaluation is that the model size, accuracy, and\ninference time are not guaranteed to be correlated. Overall we make 13 key\nobservations, including that speedups provided by compression techniques are\nvery hardware dependent, and that compiler auto-tuning can significantly alter\nwhat the best algorithm to use for a given configuration is. With DLAS, we aim\nto provide a reference framework to aid machine learning and systems\npractitioners in reasoning about the context in which their respective DNN\nacceleration solutions exist in. With our evaluation strongly motivating the\nneed for co-design, we believe that DLAS can be a valuable concept for\nexploring the next generation of co-designed accelerated deep learning\nsolutions.",
          "arxiv_id": "2311.08909v1"
        },
        {
          "title": "Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction",
          "year": "2021-12",
          "abstract": "This work is focused on the pruning of some convolutional neural networks\n(CNNs) and improving theirs efficiency on graphic processing units (GPU) by\nusing a direct sparse algorithm. The Nvidia deep neural network (cuDnn) library\nis the most effective implementations of deep learning (DL) algorithms for\nGPUs. GPUs are the most commonly used accelerators for deep learning\ncomputations. One of the most common techniques for improving the efficiency of\nCNN models is weight pruning and quantization. There are two main types of\npruning: structural and non-structural. The first enables much easier\nacceleration on many type of accelerators, but with this type it is difficult\nto achieve a sparsity level and accuracy as high as that obtained with the\nsecond type. Non-structural pruning with retraining can generate a weight\ntensors up to 90% or more of sparsity in some deep CNN models. In this article\nthe pruning algorithm is presented which makes it possible to achieve high\nsparsity levels without accuracy drop. In the next stage the linear and\nnon-linear quantization is adapted for further time and footprint reduction.\nThis paper is an extended of previously published paper concerning effective\npruning techniques and present real models pruned with high sparsities and\nreduced precision which can achieve better performance than the CuDnn library.",
          "arxiv_id": "2112.15445v2"
        },
        {
          "title": "Forecasting GPU Performance for Deep Learning Training and Inference",
          "year": "2024-07",
          "abstract": "Deep learning kernels exhibit predictable memory accesses and compute\npatterns, making GPUs' parallel architecture well-suited for their execution.\nSoftware and runtime systems for GPUs are optimized to better utilize the\nstream multiprocessors, on-chip cache, and off-chip high-bandwidth memory. As\ndeep learning models and GPUs evolve, access to newer GPUs is often limited,\nraising questions about the performance of new model architectures on existing\nGPUs, existing models on new GPUs, and new model architectures on new GPUs. To\naddress these questions, we introduce NeuSight, a framework to predict the\nperformance of various deep learning models, for both training and inference,\non unseen GPUs without requiring actual execution. The framework leverages both\nGPU hardware behavior and software library optimizations to estimate end-to-end\nperformance. Previous work uses regression models that capture linear trends or\nmultilayer perceptrons to predict the overall latency of deep learning kernels\non GPUs. These approaches suffer from higher error percentages when forecasting\nperformance on unseen models and new GPUs. Instead, NeuSight decomposes the\nprediction problem into smaller problems, bounding the prediction through\nfundamental performance laws. NeuSight decomposes a single deep learning kernel\nprediction into smaller working sets called tiles, which are executed\nindependently on the GPU. Tile-granularity predictions are determined using a\nmachine learning approach and aggregated to estimate end-to-end latency.\nNeuSight outperforms prior work across various deep learning workloads and the\nlatest GPUs. It reduces the percentage error from 121.4% and 30.8% to 2.3% in\npredicting the latency of GPT3 model for training and inference on H100,\ncompared to state-of-the-art prior work, where both GPT3 and H100 were not used\nto train the framework.",
          "arxiv_id": "2407.13853v3"
        }
      ],
      "3": [
        {
          "title": "A Novel Hybrid Optical and STAR IRS System for NTN Communications",
          "year": "2025-08",
          "abstract": "This paper proposes a novel non-terrestrial networks (NTNs) system that\nintegrates optical intelligent reflecting surfaces (OIRS) and simultaneous\ntransmitting and reflecting Intelligent reflecting surfaces (STAR-IRS) to\naddress critical challenges in next-generation communication networks. The\nproposed system model features a signal transmitted from the optical ground\nstation (OGS) to the earth station (ES) via an OIRS mounted horizontally on a\nhigh altitude platform (HAP). The ES uses an amplify-and-forward (AF) relay\nwith fixed gain for signal relaying, which is then transmitted through a\nSTAR-IRS vertically installed on a building to facilitate communication with\nboth indoor and outdoor users. The FSO link incorporates (multiple-input\nmultiple-output) MIMO technology, and this paper develops a channel model\nspecifically designed for scenarios where the number of OIRS units exceeds one.\nFor the radio-frequency (RF) link, a novel and highly precise approximation\nmethod is introduced, offering superior accuracy compared to traditional\napproaches based on the central limit theorem (CLT). Closed-form analytical\nexpressions for key performance metrics, including outage probability (OP),\nergodic capacity and average bit error rate (BER) are derived in terms of the\nbivariate Fox-H function for this novel five hops system. Asymptotic\nexpressions at high SNR are also presented, providing insights into system\ndiversity order.",
          "arxiv_id": "2508.03147v1"
        },
        {
          "title": "On the Performance of RIS-Assisted Dual-Hop Mixed RF-UWOC Systems",
          "year": "2020-11",
          "abstract": "In this paper, we investigate the performance of a reconfigurable intelligent\nsurface (RIS)-assisted dual-hop mixed radio-frequency underwater wireless\noptical communication (RF-UWOC) system. An RIS is an emerging and low-cost\ntechnology that aims to enhance the strength of the received signal, thus\nimproving the system performance. In the considered system setup, a ground\nsource does not have a reliable direct link to a given marine buoy and\ncommunicates with it through an RIS installed on a building. In particular, the\nbuoy acts as a relay that sends the signal to an underwater destination. In\nthis context, analytical expressions for the outage probability (OP), average\nbit error rate (ABER), and average channel capacity (ACC) are derived assuming\nfixed-gain amplify-and-forward (AF) and decode-and-forward (DF) relaying\nprotocols at the marine buoy. Moreover, asymptotic analyses of the OP and ABER\nare carried out in order to gain further insights from the analytical\nframeworks. In particular, the system diversity order is derived and it is\nshown to depend on the RF link parameters and on the detection schemes of the\nUWOC link. Finally, it is demonstrated that RIS-assisted systems can\neffectively improve the performance of mixed dual-hop RF-UWOC systems.",
          "arxiv_id": "2011.09060v1"
        },
        {
          "title": "Proactive Service Assurance in 5G and B5G Networks: A Closed-Loop Algorithm for End-to-End Network Slicing",
          "year": "2024-04",
          "abstract": "The customization of services in Fifth-generation (5G) and Beyond 5G (B5G)\nnetworks relies heavily on network slicing, which creates multiple virtual\nnetworks on a shared physical infrastructure, tailored to meet specific\nrequirements of distinct applications, using Software Defined Networking (SDN)\nand Network Function Virtualization (NFV). It is imperative to ensure that\nnetwork services meet the performance and reliability requirements of various\napplications and users, thus, service assurance is one of the critical\ncomponents in network slicing. One of the key functionalities of network\nslicing is the ability to scale Virtualized Network Functions (VNFs) in\nresponse to changing resource demand and to meet Customer Service Level\nagreements (SLAs). In this paper, we introduce a proactive closed-loop\nalgorithm for end-to-end network orchestration, designed to provide service\nassurance in 5G and B5G networks. We focus on dynamically scaling resources to\nmeet key performance indicators (KPIs) specific to each network slice and\noperate in parallel across multiple slices, making it scalable and capable of\nmanaging completely automatically real-time service assurance. Through our\nexperiments, we demonstrate that the proposed algorithm effectively fulfills\nservice assurance requirements for different network slice types, thereby\nminimizing network resource utilization and reducing the over-provisioning of\nspare resources.",
          "arxiv_id": "2404.01523v3"
        }
      ],
      "4": [
        {
          "title": "FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU",
          "year": "2023-03",
          "abstract": "The high computational and memory requirements of large language model (LLM)\ninference make it feasible only with multiple high-end accelerators. Motivated\nby the emerging demand for latency-insensitive tasks with batched processing,\nthis paper initiates the study of high-throughput LLM inference using limited\nresources, such as a single commodity GPU. We present FlexGen, a\nhigh-throughput generation engine for running LLMs with limited GPU memory.\nFlexGen can be flexibly configured under various hardware resource constraints\nby aggregating memory and computation from the GPU, CPU, and disk. By solving a\nlinear programming problem, it searches for efficient patterns to store and\naccess tensors. FlexGen further compresses the weights and the attention cache\nto 4 bits with negligible accuracy loss. These techniques enable FlexGen to\nhave a larger space of batch size choices and thus significantly increase\nmaximum throughput. As a result, when running OPT-175B on a single 16GB GPU,\nFlexGen achieves significantly higher throughput compared to state-of-the-art\noffloading systems, reaching a generation throughput of 1 token/s for the first\ntime with an effective batch size of 144. On the HELM benchmark, FlexGen can\nbenchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21\nhours. The code is available at https://github.com/FMInference/FlexGen",
          "arxiv_id": "2303.06865v2"
        },
        {
          "title": "KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation",
          "year": "2024-11",
          "abstract": "Inference for Large Language Models (LLMs) is computationally demanding. To\nreduce the cost of auto-regressive decoding, Key-Value (KV) cache is used to\nstore intermediate activations, which significantly lowers the computational\noverhead for token generation. However, the memory required for the KV cache\ngrows rapidly, often exceeding the capacity of GPU memory. A cost-effective\nalternative is to offload KV cache to CPU memory, which alleviates GPU memory\npressure, but shifts the bottleneck to the limited bandwidth of the PCIe\nconnection between the CPU and GPU. Existing methods attempt to address these\nissues by overlapping GPU computation with I/O or employing CPU-GPU\nheterogeneous execution, but they are hindered by excessive data movement and\ndependence on CPU capabilities. Fully overlapping PCIe communication latency\ngets challenging as the size of the KV cache grows and/or the GPU compute\ncapabilities increase. In this paper, we introduce KVPR, an efficient I/O-aware\nLLM inference method where the CPU first transfers a partial set of\nactivations, from which the GPU can start recomputing the KV cache values.\nWhile the GPU recomputes the partial KV cache, the remaining portion of the KV\ncache is transferred concurrently from the CPU. This approach overlaps GPU\nrecomputation with KV cache transfer to minimize idle GPU time and maximize\ninference performance. KVPR is fully automated by integrating a profiler module\nthat utilizes input characteristics and system hardware information, a\nscheduler module to optimize the distribution of computation and communication\nworkloads, and a runtime module to efficiently execute the derived execution\nplan. Experimental results show that KVPR achieves up to 35.8% lower latency\nand 46.2% higher throughput during decoding compared to state-of-the-art\napproaches. The code is available at https://github.com/chaoyij/KVPR.",
          "arxiv_id": "2411.17089v2"
        },
        {
          "title": "ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching",
          "year": "2024-03",
          "abstract": "The Transformer architecture has significantly advanced natural language\nprocessing (NLP) and has been foundational in developing large language models\n(LLMs) such as LLaMA and OPT, which have come to dominate a broad range of NLP\ntasks. Despite their superior accuracy, LLMs present unique challenges in\npractical inference, concerning the compute and memory-intensive nature. Thanks\nto the autoregressive characteristic of LLM inference, KV caching for the\nattention layers in Transformers can effectively accelerate LLM inference by\nsubstituting quadratic-complexity computation with linear-complexity memory\naccesses. Yet, this approach requires increasing memory as demand grows for\nprocessing longer sequences. The overhead leads to reduced throughput due to\nI/O bottlenecks and even out-of-memory errors, particularly on\nresource-constrained systems like a single commodity GPU. In this paper, we\npropose ALISA, a novel algorithm-system co-design solution to address the\nchallenges imposed by KV caching. On the algorithm level, ALISA prioritizes\ntokens that are most important in generating a new token via a Sparse Window\nAttention (SWA) algorithm. SWA introduces high sparsity in attention layers and\nreduces the memory footprint of KV caching at negligible accuracy loss. On the\nsystem level, ALISA employs three-phase token-level dynamical scheduling and\noptimizes the trade-off between caching and recomputation, thus maximizing the\noverall performance in resource-constrained systems. In a single GPU-CPU\nsystem, we demonstrate that under varying workloads, ALISA improves the\nthroughput of baseline systems such as FlexGen and vLLM by up to 3X and 1.9X,\nrespectively.",
          "arxiv_id": "2403.17312v1"
        }
      ],
      "5": [
        {
          "title": "Enhancing Performance Monitoring in C/C++ Programs with EDPM: A Domain-Specific Language for Performance Monitoring",
          "year": "2023-11",
          "abstract": "The utilization of performance monitoring probes is a valuable tool for\nprogrammers to gather performance data. However, the manual insertion of these\nprobes can result in an increase in code size, code obfuscation, and an added\nburden of learning different APIs associated with performance monitoring tools.\nTo mitigate these issues, EDPM, an embedded domain-specific language, was\ndeveloped to provide a higher level of abstraction for annotating regions of\ncode that require instrumentation in C and C++ programs. This paper presents\nthe design and implementation of EDPM and compares it to the well-known tool\nPAPI, in terms of required lines of code, flexibility in configuring regions,\nand performance overhead. The results of this study demonstrate that EDPM is a\nlow-resolution profiling tool that offers a reduction in required lines of code\nand enables programmers to express various configurations of regions.\nFurthermore, the design of EDPM is such that its pragmas are ignored by the\nstandard compiler, allowing for seamless integration into existing software\nprocesses without disrupting build systems or increasing the size of the\nexecutable. Additionally, the design of the EDPM pre-compiler allows for the\nextension of available performance counters while maintaining a high level of\nabstraction for programmers. Therefore, EDPM offers a promising solution to\nsimplify and optimize performance monitoring in C and C++ programs.",
          "arxiv_id": "2311.03535v1"
        },
        {
          "title": "Autotuning PolyBench Benchmarks with LLVM Clang/Polly Loop Optimization Pragmas Using Bayesian Optimization",
          "year": "2020-10",
          "abstract": "An autotuning is an approach that explores a search space of possible\nimplementations/configurations of a kernel or an application by selecting and\nevaluating a subset of implementations/configurations on a target platform\nand/or use models to identify a high performance implementation/configuration.\nIn this paper, we develop an autotuning framework that leverages Bayesian\noptimization to explore the parameter space search. We select six of the most\ncomplex benchmarks from the application domains of the PolyBench benchmarks\n(syr2k, 3mm, heat-3d, lu, covariance, and Floyd-Warshall) and apply the newly\ndeveloped LLVM Clang/Polly loop optimization pragmas to the benchmarks to\noptimize them. We then use the autotuning framework to optimize the pragma\nparameters to improve their performance. The experimental results show that our\nautotuning approach outperforms the other compiling methods to provide the\nsmallest execution time for the benchmarks syr2k, 3mm, heat-3d, lu, and\ncovariance with two large datasets in 200 code evaluations for effectively\nsearching the parameter spaces with up to 170,368 different configurations. We\ncompare four different supervised learning methods within Bayesian optimization\nand evaluate their effectiveness. We find that the Floyd-Warshall benchmark did\nnot benefit from autotuning because Polly uses heuristics to optimize the\nbenchmark to make it run much slower. To cope with this issue, we provide some\ncompiler option solutions to improve the performance.",
          "arxiv_id": "2010.08040v1"
        },
        {
          "title": "ProGraML: Graph-based Deep Learning for Program Optimization and Analysis",
          "year": "2020-03",
          "abstract": "The increasing complexity of computing systems places a tremendous burden on\noptimizing compilers, requiring ever more accurate and aggressive\noptimizations. Machine learning offers significant benefits for constructing\noptimization heuristics but there remains a gap between what state-of-the-art\nmethods achieve and the performance of an optimal heuristic. Closing this gap\nrequires improvements in two key areas: a representation that accurately\ncaptures the semantics of programs, and a model architecture with sufficient\nexpressiveness to reason about this representation.\n  We introduce ProGraML - Program Graphs for Machine Learning - a novel\ngraph-based program representation using a low level, language agnostic, and\nportable format; and machine learning models capable of performing complex\ndownstream tasks over these graphs. The ProGraML representation is a directed\nattributed multigraph that captures control, data, and call relations, and\nsummarizes instruction and operand types and ordering. Message Passing Neural\nNetworks propagate information through this structured representation, enabling\nwhole-program or per-vertex classification tasks.\n  ProGraML provides a general-purpose program representation that equips\nlearnable models to perform the types of program analysis that are fundamental\nto optimization. To this end, we evaluate the performance of our approach first\non a suite of traditional compiler analysis tasks: control flow reachability,\ndominator trees, data dependencies, variable liveness, and common subexpression\ndetection. On a benchmark dataset of 250k LLVM-IR files covering six source\nprogramming languages, ProGraML achieves an average 94.0 F1 score,\nsignificantly outperforming the state-of-the-art approaches. We then apply our\napproach to two high-level tasks - heterogeneous device mapping and program\nclassification - setting new state-of-the-art performance in both.",
          "arxiv_id": "2003.10536v1"
        }
      ],
      "6": [
        {
          "title": "AI-Driven Resource Allocation Framework for Microservices in Hybrid Cloud Platforms",
          "year": "2024-12",
          "abstract": "The increasing demand for scalable, efficient resource management in hybrid\ncloud environments has led to the exploration of AI-driven approaches for\ndynamic resource allocation. This paper presents an AI-driven framework for\nresource allocation among microservices in hybrid cloud platforms. The\nframework employs reinforcement learning (RL)-based resource utilization\noptimization to reduce costs and improve performance. The framework integrates\nAI models with cloud management tools to respond to challenges of dynamic\nscaling and cost-efficient low-latency service delivery. The reinforcement\nlearning model continuously adjusts provisioned resources as required by the\nmicroservices and predicts the future consumption trends to minimize both\nunder- and over-provisioning of resources. Preliminary simulation results\nindicate that using AI in the provision of resources related to costs can\nreduce expenditure by up to 30-40% compared to manual provisioning and\nthreshold-based auto-scaling approaches. It is also estimated that the\nefficiency in resource utilization is expected to improve by 20%-30% with a\ncorresponding latency cut of 15%-20% during the peak demand periods. This study\ncompares the AI-driven approach with existing static and rule-based resource\nallocation methods, demonstrating the capability of this new model to\noutperform them in terms of flexibility and real-time interests. The results\nindicate that reinforcement learning can make optimization of hybrid cloud\nplatforms even better, offering a 25-35% improvement in cost efficiency and the\npower of scaling for microservice-based applications. The proposed framework is\na strong and scalable solution to managing cloud resources in dynamic and\nperformance-critical environments.",
          "arxiv_id": "2412.02610v1"
        },
        {
          "title": "Resource Management Schemes for Cloud-Native Platforms with Computing Containers of Docker and Kubernetes",
          "year": "2020-10",
          "abstract": "Businesses have made increasing adoption and incorporation of cloud\ntechnology into internal processes in the last decade. The cloud-based\ndeployment provides on-demand availability without active management. More\nrecently, the concept of cloud-native application has been proposed and\nrepresents an invaluable step toward helping organizations develop software\nfaster and update it more frequently to achieve dramatic business outcomes.\nCloud-native is an approach to build and run applications that exploit the\ncloud computing delivery model's advantages. It is more about how applications\nare created and deployed than where. The container-based virtualization\ntechnology, such as Docker and Kubernetes, serves as the foundation for\ncloud-native applications. This paper investigates the performance of two\npopular computational-intensive applications, big data, and deep learning, in a\ncloud-native environment. We analyze the system overhead and resource usage for\nthese applications. Through extensive experiments, we show that the completion\ntime reduces by up to 79.4% by changing the default setting and increases by up\nto 96.7% due to different resource management schemes on two platforms.\nAdditionally, the resource release is delayed by up to 116.7% across different\nsystems. Our work can guide developers, administrators, and researchers to\nbetter design and deploy their applications by selecting and configuring a\nhosting platform.",
          "arxiv_id": "2010.10350v1"
        },
        {
          "title": "Managing Cold-start in The Serverless Cloud with Temporal Convolutional Networks",
          "year": "2023-04",
          "abstract": "Serverless cloud is an innovative cloud service model that frees customers\nfrom most cloud management duties. It also offers the same advantages as other\ncloud models but at much lower costs. As a result, the serverless cloud has\nbeen increasingly employed in high-impact areas such as system security,\nbanking, and health care. A big threat to the serverless cloud's performance is\ncold-start, which is when the time of provisioning the needed cloud resource to\nserve customers' requests incurs unacceptable costs to the service providers\nand/or the customers. This paper proposes a novel low-coupling, high-cohesion\nensemble policy that addresses the cold-start problem at infrastructure- and\nfunction-levels of the serverless cloud stack, while the state of the art\npolicies have a more narrowed focus. This ensemble policy anchors on the\nprediction of function instance arrivals, 10 to 15 minutes into the future. It\nis achievable by using the temporal convolutional network (TCN) deep-learning\nmethod. Bench-marking results on a real-world dataset from a large-scale\nserverless cloud provider show that TCN out-performs other popular machine\nlearning algorithms for time series. Going beyond cold-start management, the\nproposed policy and publicly available codes can be adopted in solving other\ncloud problems such as optimizing the provisioning of virtual software-defined\nnetwork assets.",
          "arxiv_id": "2304.00396v1"
        }
      ],
      "7": [
        {
          "title": "Rule-Based Graph Programs Matching the Time Complexity of Imperative Algorithms",
          "year": "2025-01",
          "abstract": "We report on recent advances in rule-based graph programming, which allow us\nto match the time complexity of some fundamental imperative graph algorithms.\nIn general, achieving the time complexity of graph algorithms implemented in\nconventional languages using a rule-based graph-transformation language is\nchallenging due to the cost of graph matching. Previous work demonstrated that\nwith rooted rules, certain algorithms can be implemented in the graph\nprogramming language GP 2 such that their runtime matches the time complexity\nof imperative implementations. However, this required input graphs to have a\nbounded node degree and (for some algorithms) to be connected. In this paper,\nwe overcome these limitations by enhancing the graph data structure generated\nby the GP 2 compiler and exploiting the new structure in programs. We present\nthree case studies: the first program checks whether input graphs are\nconnected, the second program checks whether input graphs are acyclic, and the\nthird program solves the single-source shortest-paths problem for graphs with\ninteger edge-weights. The first two programs run in linear time on (possibly\ndisconnected) input graphs with arbitrary node degrees. The third program runs\nin time $O(nm)$ on arbitrary input graphs, matching the time complexity of\nimperative implementations of the Bellman-Ford algorithm. For each program, we\nformally prove its correctness and time complexity, and provide runtime\nexperiments on various graph classes.",
          "arxiv_id": "2501.09144v2"
        },
        {
          "title": "Kairos: Efficient Temporal Graph Analytics on a Single Machine",
          "year": "2024-01",
          "abstract": "Many important societal problems are naturally modeled as algorithms over\ntemporal graphs. To date, however, most graph processing systems remain\ninefficient as they rely on distributed processing even for graphs that fit\nwell within a commodity server's available storage. In this paper, we introduce\nKairos, a temporal graph analytics system that provides application developers\na framework for efficiently implementing and executing algorithms over temporal\ngraphs on a single machine. Specifically, Kairos relies on fork-join\nparallelism and a highly optimized parallel data structure as core primitives\nto maximize performance of graph processing tasks needed for temporal graph\nanalytics. Furthermore, we introduce the notion of selective indexing and show\nhow it can be used with an efficient index to speedup temporal queries. Our\nexperiments on a 24-core server show that our algorithms obtain good parallel\nspeedups, and are significantly faster than equivalent algorithms in existing\ntemporal graph processing systems: up to 60x against a shared-memory approach,\nand several orders of magnitude when compared with distributed processing of\ngraphs that fit within a single server.",
          "arxiv_id": "2401.02563v1"
        },
        {
          "title": "GraphChallenge.org Triangle Counting Performance",
          "year": "2020-03",
          "abstract": "The rise of graph analytic systems has created a need for new ways to measure\nand compare the capabilities of graph processing systems. The MIT/Amazon/IEEE\nGraph Challenge has been developed to provide a well-defined community venue\nfor stimulating research and highlighting innovations in graph analysis\nsoftware, hardware, algorithms, and systems. GraphChallenge.org provides a wide\nrange of pre-parsed graph data sets, graph generators, mathematically defined\ngraph algorithms, example serial implementations in a variety of languages, and\nspecific metrics for measuring performance. The triangle counting component of\nGraphChallenge.org tests the performance of graph processing systems to count\nall the triangles in a graph and exercises key graph operations found in many\ngraph algorithms. In 2017, 2018, and 2019 many triangle counting submissions\nwere received from a wide range of authors and organizations. This paper\npresents a performance analysis of the best performers of these submissions.\nThese submissions show that their state-of-the-art triangle counting execution\ntime, $T_{\\rm tri}$, is a strong function of the number of edges in the graph,\n$N_e$, which improved significantly from 2017 ($T_{\\rm tri} \\approx\n(N_e/10^8)^{4/3}$) to 2018 ($T_{\\rm tri} \\approx N_e/10^9$) and remained\ncomparable from 2018 to 2019. Graph Challenge provides a clear picture of\ncurrent graph analysis systems and underscores the need for new innovations to\nachieve high performance on very large graphs.",
          "arxiv_id": "2003.09269v1"
        }
      ],
      "8": [
        {
          "title": "A Cycle-level Unified DRAM Cache Controller Model for 3DXPoint Memory Systems in gem5",
          "year": "2023-03",
          "abstract": "To accommodate the growing memory footprints of today's applications, CPU\nvendors have employed large DRAM caches, backed by large non-volatile memories\nlike Intel Optane (e.g., Intel's Cascade Lake). The existing computer\narchitecture simulators do not provide support to model and evaluate systems\nwhich use DRAM devices as a cache to the non-volatile main memory. In this\nwork, we present a cycle-level DRAM cache model which is integrated with gem5.\nThis model leverages the flexibility of gem5's memory devices models and full\nsystem support to enable exploration of many different DRAM cache designs. We\ndemonstrate the usefulness of this new tool by exploring the design space of a\nDRAM cache controller through several case studies including the impact of\nscheduling policies, required buffering, combining different memory\ntechnologies (e.g., HBM, DDR3/4/5, 3DXPoint, High latency) as the cache and\nmain memory, and the effect of wear-leveling when DRAM cache is backed by NVM\nmain memory. We also perform experiments with real workloads in full-system\nsimulations to validate the proposed model and show the sensitivity of these\nworkloads to the DRAM cache sizes.",
          "arxiv_id": "2303.13026v1"
        },
        {
          "title": "CXLMemSim: A pure software simulated CXL.mem for performance characterization",
          "year": "2023-03",
          "abstract": "CXLMemSim is a fast, lightweight simulation framework that enables\nperformance characterization of memory systems based on Compute Express Link\n(CXL) .mem technology. CXL.mem allows disaggregation and pooling of memory to\nmitigate memory stranding (underutilized memory trapped on fully loaded\nservers) in cloud and datacenter environments. However, CXL-attached memory\nintroduces additional latency and bandwidth constraints compared to local DRAM,\nand real CXL .mem hardware is not yet widely available for empirical\nevaluation. CXLMemSim addresses this gap by attaching to unmodified\napplications and simulating CXL-based memory pools in software. It operates by\ntracing memory allocations and accesses using efficient kernel probes and\nhardware performance counters, dividing execution into epochs, and injecting\ntiming delays to emulate various CXL .mem latency/bandwidth characteristics.\nThis approach incurs modest runtime overhead while preserving realistic\nload/store memory access patterns. We implement CXLMemSim on commodity hardware\nwithout special devices, and our evaluation shows that it runs orders of\nmagnitude faster than cycle-accurate simulators (e.g., Gem5) for real-world\nworkloads, while accurately modeling the performance impact of CXL .mem. We\ndemonstrate use cases where CXLMemSim enables experimentation with memory\npooling configurations, scheduling policies, data migration strategies, and\ncaching techniques that were previously infeasible to evaluate at scale. Key\nfindings include the viability of software-based CXL .mem emulation with low\noverhead, insights into latency and congestion effects in memory pools, and\nguidance for system designers to optimize memory disaggregation. Overall,\nCXLMemSim provides a practical and extensible platform for researchers and\npractitioners to explore CXL.mem innovations before real hardware becomes\ncommonplace.",
          "arxiv_id": "2303.06153v2"
        },
        {
          "title": "Demystifying CXL Memory with Genuine CXL-Ready Systems and Devices",
          "year": "2023-03",
          "abstract": "The ever-growing demands for memory with larger capacity and higher bandwidth\nhave driven recent innovations on memory expansion and disaggregation\ntechnologies based on Compute eXpress Link (CXL). Especially, CXL-based memory\nexpansion technology has recently gained notable attention for its ability not\nonly to economically expand memory capacity and bandwidth but also to decouple\nmemory technologies from a specific memory interface of the CPU. However, since\nCXL memory devices have not been widely available, they have been emulated\nusing DDR memory in a remote NUMA node. In this paper, for the first time, we\ncomprehensively evaluate a true CXL-ready system based on the latest\n4th-generation Intel Xeon CPU with three CXL memory devices from different\nmanufacturers. Specifically, we run a set of microbenchmarks not only to\ncompare the performance of true CXL memory with that of emulated CXL memory but\nalso to analyze the complex interplay between the CPU and CXL memory in depth.\nThis reveals important differences between emulated CXL memory and true CXL\nmemory, some of which will compel researchers to revisit the analyses and\nproposals from recent work. Next, we identify opportunities for\nmemory-bandwidth-intensive applications to benefit from the use of CXL memory.\nLastly, we propose a CXL-memory-aware dynamic page allocation policy, Caption\nto more efficiently use CXL memory as a bandwidth expander. We demonstrate that\nCaption can automatically converge to an empirically favorable percentage of\npages allocated to CXL memory, which improves the performance of\nmemory-bandwidth-intensive applications by up to 24% when compared to the\ndefault page allocation policy designed for traditional NUMA systems.",
          "arxiv_id": "2303.15375v4"
        }
      ],
      "9": [
        {
          "title": "HRA: A Multi-Criteria Framework for Ranking Metaheuristic Optimization Algorithms",
          "year": "2024-09",
          "abstract": "Metaheuristic algorithms are essential for solving complex optimization\nproblems in different fields. However, the difficulty in comparing and rating\nthese algorithms remains due to the wide range of performance metrics and\nproblem dimensions usually involved. On the other hand, nonparametric\nstatistical methods and post hoc tests are time-consuming, especially when we\nonly need to identify the top performers among many algorithms. The\nHierarchical Rank Aggregation (HRA) algorithm aims to efficiently rank\nmetaheuristic algorithms based on their performance across many criteria and\ndimensions. The HRA employs a hierarchical framework that begins with\ncollecting performance metrics on various benchmark functions and dimensions.\nRank-based normalization is employed for each performance measure to ensure\ncomparability and the robust TOPSIS aggregation is applied to combine these\nrankings at several hierarchical levels, resulting in a comprehensive ranking\nof the algorithms. Our study uses data from the CEC 2017 competition to\ndemonstrate the robustness and efficacy of the HRA framework. It examines 30\nbenchmark functions and evaluates the performance of 13 metaheuristic\nalgorithms across five performance indicators in four distinct dimensions. This\npresentation highlights the potential of the HRA to enhance the interpretation\nof the comparative advantages and disadvantages of various algorithms by\nsimplifying practitioners' choices of the most appropriate algorithm for\ncertain optimization problems.",
          "arxiv_id": "2409.11617v1"
        },
        {
          "title": "Prasatul Matrix: A Direct Comparison Approach for Analyzing Evolutionary Optimization Algorithms",
          "year": "2022-12",
          "abstract": "The performance of individual evolutionary optimization algorithms is mostly\nmeasured in terms of statistics such as mean, median and standard deviation\netc., computed over the best solutions obtained with few trails of the\nalgorithm. To compare the performance of two algorithms, the values of these\nstatistics are compared instead of comparing the solutions directly. This kind\nof comparison lacks direct comparison of solutions obtained with different\nalgorithms. For instance, the comparison of best solutions (or worst solution)\nof two algorithms simply not possible. Moreover, ranking of algorithms is\nmostly done in terms of solution quality only, despite the fact that the\nconvergence of algorithm is also an important factor. In this paper, a direct\ncomparison approach is proposed to analyze the performance of evolutionary\noptimization algorithms. A direct comparison matrix called \\emph{Prasatul\nMatrix} is prepared, which accounts direct comparison outcome of best solutions\nobtained with two algorithms for a specific number of trials. Five different\nperformance measures are designed based on the prasatul matrix to evaluate the\nperformance of algorithms in terms of Optimality and Comparability of\nsolutions. These scores are utilized to develop a score-driven approach for\ncomparing performance of multiple algorithms as well as for ranking both in the\ngrounds of solution quality and convergence analysis. Proposed approach is\nanalyzed with six evolutionary optimization algorithms on 25 benchmark\nfunctions. A non-parametric statistical analysis, namely Wilcoxon paired\nsum-rank test is also performed to verify the outcomes of proposed direct\ncomparison approach.",
          "arxiv_id": "2212.00671v1"
        },
        {
          "title": "Efficient human-in-loop deep learning model training with iterative refinement and statistical result validation",
          "year": "2023-04",
          "abstract": "Annotation and labeling of images are some of the biggest challenges in\napplying deep learning to medical data. Current processes are time and\ncost-intensive and, therefore, a limiting factor for the wide adoption of the\ntechnology. Additionally validating that measured performance improvements are\nsignificant is important to select the best model. In this paper, we\ndemonstrate a method for creating segmentations, a necessary part of a data\ncleaning for ultrasound imaging machine learning pipelines. We propose a\nfour-step method to leverage automatically generated training data and fast\nhuman visual checks to improve model accuracy while keeping the time/effort and\ncost low. We also showcase running experiments multiple times to allow the\nusage of statistical analysis. Poor quality automated ground truth data and\nquick visual inspections efficiently train an initial base model, which is\nrefined using a small set of more expensive human-generated ground truth data.\nThe method is demonstrated on a cardiac ultrasound segmentation task, removing\nbackground data, including static PHI. Significance is shown by running the\nexperiments multiple times and using the student's t-test on the performance\ndistributions. The initial segmentation accuracy of a simple thresholding\nalgorithm of 92% was improved to 98%. The performance of models trained on\ncomplicated algorithms can be matched or beaten by pre-training with the poorer\nperforming algorithms and a small quantity of high-quality data. The\nintroduction of statistic significance analysis for deep learning models helps\nto validate the performance improvements measured. The method offers a\ncost-effective and fast approach to achieving high-accuracy models while\nminimizing the cost and effort of acquiring high-quality training data.",
          "arxiv_id": "2304.00990v1"
        }
      ],
      "10": [
        {
          "title": "Gromit: Benchmarking the Performance and Scalability of Blockchain Systems",
          "year": "2022-08",
          "abstract": "The growing number of implementations of blockchain systems stands in stark\ncontrast with still limited research on a systematic comparison of performance\ncharacteristics of these solutions. Such research is crucial for evaluating\nfundamental trade-offs introduced by novel consensus protocols and their\nimplementations. These performance limitations are commonly analyzed with\nad-hoc benchmarking frameworks focused on the consensus algorithm of blockchain\nsystems. However, comparative evaluations of design choices require\nmacro-benchmarks for uniform and comprehensive performance evaluations of\nblockchains at the system level rather than performance metrics of isolated\ncomponents. To address this research gap, we implement Gromit, a generic\nframework for analyzing blockchain systems. Gromit treats each system under\ntest as a transaction fabric where clients issue transactions to validators. We\nuse Gromit to conduct the largest blockchain study to date, involving seven\nrepresentative systems with varying consensus models. We determine the peak\nperformance of these systems with a synthetic workload in terms of transaction\nthroughput and scalability and show that transaction throughput does not scale\nwith the number of validators. We explore how robust the subjected systems are\nagainst network delays and reveal that the performance of permissoned\nblockchain is highly sensitive to network conditions.",
          "arxiv_id": "2208.11254v1"
        },
        {
          "title": "Dynamic Practical Byzantine Fault Tolerance and Its Blockchain System: A Large-Scale Markov Modeling",
          "year": "2022-10",
          "abstract": "In a practical Byzantine fault tolerance (PBFT) blockchain network, the\nvoting nodes may always leave the network while some new nodes can also enter\nthe network, thus the number of voting nodes is constantly changing. Such a new\nPBFT with dynamic nodes is called a dynamic PBFT. Clearly, the dynamic PBFT can\nmore strongly support the decentralization and distributed structure of\nblockchain. However, analyzing dynamic PBFT blockchain systems will become more\ninteresting and challenging.\n  In this paper, we propose a large-scale Markov modeling technique to analyze\nthe dynamic PBFT voting processes and its dynamic PBFT blockchain system. To\nthis end, we set up a large-scale Markov process (and further a\nmulti-dimensional Quasi-Birth-and-Death (QBD) process) and provide performance\nanalysis for both the dynamic PBFT voting processes and the dynamic PBFT\nblockchain system. In particular, we obtain an effective computational method\nfor the throughput of the complicated dynamic PBFT blockchain system. Finally,\nwe use numerical examples to check the validity of our theoretical results and\nindicate how some key system parameters influence the performance measures of\nthe dynamic PBFT voting processes and of the dynamic PBFT blockchain system.\nTherefore, by using the theory of multi-dimensional QBD processes and the\nRG-factorization technique, we hope that the methodology and results developed\nin this paper shed light on the study of dynamic PBFT blockchain systems such\nthat a series of promising research can be developed potentially.",
          "arxiv_id": "2210.14003v1"
        },
        {
          "title": "Performance and Reliability Analysis for Practical Byzantine Fault Tolerance with Repairable Voting Nodes",
          "year": "2023-06",
          "abstract": "The practical Byzantine fault tolerant (PBFT) consensus protocol is one of\nthe basic consensus protocols in the development of blockchain technology. At\nthe same time, the PBFT consensus protocol forms a basis for some other\nimportant BFT consensus protocols, such as Tendermint, Streamlet, HotStuff, and\nLibraBFT. In general, the voting nodes may always fail so that they can leave\nthe PBFT-based blockchain system in a random time interval, making the number\nof timely available voting nodes uncertain. Thus, this uncertainty leads to the\nanalysis of the PBFT-based blockchain systems with repairable voting nodes\nbeing more challenging. In this paper, we develop a novel PBFT consensus\nprotocol with repairable voting nodes and study such a new blockchain system\nusing a multi-dimensional Markov process and the first passage time method.\nBased on this, we provide performance and reliability analysis, including\nthroughput, availability, and reliability, for the new PBFT-based blockchain\nsystem with repairable voting nodes. Furthermore, we provide an approximate\nalgorithm for computing the throughput of the new PBFT-based blockchain system.\nWe employ numerical examples to demonstrate the validity of our theoretical\nresults and illustrate how the key system parameters influence performance\nmeasures of the PBFT-based blockchain system with repairable voting nodes. We\nhope the methodology and results developed in this paper will stimulate future\nresearch endeavors and open up new research trajectories in this field.",
          "arxiv_id": "2306.10960v1"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-24T22:20:01Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}